{"file_path": "open-assistant\\package\\setup.py", "code_chunk": "UploadCommand.@staticmethod\ndef status(s):\n    \"\"\"Prints things in bold.\"\"\"\n    print('\\x1b[1m{0}\\x1b[0m'.format(s))", "hash": "2ab41b3b0bd45865c2eb57a58f1d556990e52da587df5fb4029d1cef5069a001"}
{"file_path": "open-assistant\\package\\setup.py", "code_chunk": "UploadCommand.def initialize_options(self):\n    pass", "hash": "c898309af5bbc8a53553ea47bb85144da990d78cd2d372a9eaa6b842b801103b"}
{"file_path": "open-assistant\\package\\setup.py", "code_chunk": "UploadCommand.def finalize_options(self):\n    pass", "hash": "917a07a09f303825fcdb95e902210c9438c414ce8858743415a1b58bb8c63338"}
{"file_path": "open-assistant\\package\\setup.py", "code_chunk": "UploadCommand.def run(self):\n    try:\n        self.status('Removing previous builds\u2026')\n        rmtree(os.path.join(here, 'dist'))\n    except OSError:\n        pass\n    self.status('Building Source and Wheel (universal) distribution\u2026')\n    os.system('{0} setup.py sdist bdist_wheel --universal'.format(sys.executable))\n    self.status('Uploading the package to PyPI via Twine\u2026')\n    os.system('twine upload dist/*')\n    self.status('Pushing git tags\u2026')\n    os.system('git tag v{0}'.format(about['__version__']))\n    os.system('git push --tags')\n    sys.exit()", "hash": "f3a2685faf712a0099f2fb905efb96b0219e563f02690a6b2fb58d3c192caa2d"}
{"file_path": "open-assistant\\package\\setup.py", "code_chunk": "UploadCommand.Command\n'Support setup.py upload.'\ndescription = 'Build and publish the package.'\nuser_options = []", "hash": "f5b8f7bbb456ced1e7c3af0d1fc5d604603625a9a587664c9d17e0ecf471f549"}
{"file_path": "open-assistant\\package\\setup.py", "code_chunk": "UploadCommand.@staticmethod\ndef status(s):\n    \"\"\"Prints things in bold.\"\"\"\n    print('\\x1b[1m{0}\\x1b[0m'.format(s))", "hash": "2ab41b3b0bd45865c2eb57a58f1d556990e52da587df5fb4029d1cef5069a001"}
{"file_path": "open-assistant\\package\\setup.py", "code_chunk": "UploadCommand.def initialize_options(self):\n    pass", "hash": "c898309af5bbc8a53553ea47bb85144da990d78cd2d372a9eaa6b842b801103b"}
{"file_path": "open-assistant\\package\\setup.py", "code_chunk": "UploadCommand.def finalize_options(self):\n    pass", "hash": "917a07a09f303825fcdb95e902210c9438c414ce8858743415a1b58bb8c63338"}
{"file_path": "open-assistant\\package\\setup.py", "code_chunk": "UploadCommand.def run(self):\n    try:\n        self.status('Removing previous builds\u2026')\n        rmtree(os.path.join(here, 'dist'))\n    except OSError:\n        pass\n    self.status('Building Source and Wheel (universal) distribution\u2026')\n    os.system('{0} setup.py sdist bdist_wheel --universal'.format(sys.executable))\n    self.status('Uploading the package to PyPI via Twine\u2026')\n    os.system('twine upload dist/*')\n    self.status('Pushing git tags\u2026')\n    os.system('git tag v{0}'.format(about['__version__']))\n    os.system('git push --tags')\n    sys.exit()", "hash": "f3a2685faf712a0099f2fb905efb96b0219e563f02690a6b2fb58d3c192caa2d"}
{"file_path": "open-assistant\\package\\setup.py", "code_chunk": "import io\nimport os\nimport sys\nfrom shutil import rmtree\nfrom setuptools import find_packages, setup, Command\nNAME = 'yorgassistant'\nDESCRIPTION = 'assistant package for yorg'\nURL = 'https://github.com/YORG-AI/Open-Assistant'\nEMAIL = 'zhongxingyuemail@gmail.com'\nAUTHOR = 'XingYu-Zhong'\nREQUIRES_PYTHON = '>=3.8.0'\nVERSION = '0.0.21'\nREQUIRED = []\nEXTRAS = {}\nhere = os.path.abspath(os.path.dirname(__file__))\nwith io.open(os.path.join(here, 'requirements.txt'), encoding='utf-8') as f:\n    REQUIRED = [line.strip() for line in f.readlines() if not line.startswith('#') and line.strip()]\ntry:\n    with io.open(os.path.join(here, 'README.md'), encoding='utf-8') as f:\n        long_description = '\\n' + f.read()\nexcept FileNotFoundError:\n    long_description = DESCRIPTION\nabout = {}\nif not VERSION:\n    project_slug = NAME.lower().replace('-', '_').replace(' ', '_')\n    with open(os.path.join(here, project_slug, '__version__.py')) as f:\n        exec(f.read(), about)\nelse:\n    about['__version__'] = VERSION", "hash": "f9e4e7ca1a4a531c8a27950b6d98a9de910750c30141d2109e07aeeab4e5caee"}
{"file_path": "open-assistant\\package\\setup.py", "code_chunk": "setup(name=NAME, version=about['__version__'], description=DESCRIPTION, long_description=long_description, long_description_content_type='text/markdown', author=AUTHOR, author_email=EMAIL, python_requires=REQUIRES_PYTHON, url=URL, packages=find_packages(where='src'), package_dir={'': 'src'}, install_requires=REQUIRED, extras_require=EXTRAS, include_package_data=True, license='MIT', classifiers=['License :: OSI Approved :: MIT License', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.6', 'Programming Language :: Python :: Implementation :: CPython', 'Programming Language :: Python :: Implementation :: PyPy'], cmdclass={'upload': UploadCommand})", "hash": "708047cd259f1320ac0e535c1c362d1c129a6d644d267aab53d42ed2c684b280"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\__init__.py", "code_chunk": "from .core.assistant import *\n__all__ = ['AsyncThreads', 'Threads', 'Assistants', 'Tools']", "hash": "864e16d7f7c4e3c9db18a10770c893e609abe0a75ddc0a1b111f3a79ba033df5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\common_models.py", "code_chunk": "RedisKeyType.Enum\n'\\n    An enumeration for Redis key types.\\n    '\nDOCUMENTS = 'documents'\nVECTORSTORE = 'vectorstore'", "hash": "ad818ffbe1f6a5ded938af6e2a5dd33537f446b069ccfd82d8482dd26659211c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\common_models.py", "code_chunk": "UserProperties.def generate_redis_key_with_type(self, key_type: RedisKeyType):\n    return f'{self.user_id}:{self.session_id}:{key_type.value}'", "hash": "9b7677d626aa0e4dfe06d6304de2e905c857aec53f331d2885d16efc791f8267"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\common_models.py", "code_chunk": "UserProperties.@classmethod\ndef __get_validators__(cls):\n    yield cls.validate_to_json", "hash": "87bda01a5087997d81a702d5d9b2e38f83ebd14020175a292c6f4c34e2452433"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\common_models.py", "code_chunk": "UserProperties.@classmethod\ndef validate_to_json(cls, value):\n    if isinstance(value, str):\n        return cls(**json.loads(value))\n    return value", "hash": "f7829fc8401caefa22cf4c81af9d56d7e07cfcac8ec9866c9e691783b6fa818d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\common_models.py", "code_chunk": "UserProperties.BaseModel\nuser_id: Optional[str] = DEFAULT_USER_ID\nsession_id: Optional[str] = DEFAULT_SESSION_ID", "hash": "46c217d95178ef5586a677f441a51d113c42fb739bf6e79af4db92a3bdb11d08"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\common_models.py", "code_chunk": "UserProperties.def generate_redis_key_with_type(self, key_type: RedisKeyType):\n    return f'{self.user_id}:{self.session_id}:{key_type.value}'", "hash": "9b7677d626aa0e4dfe06d6304de2e905c857aec53f331d2885d16efc791f8267"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\common_models.py", "code_chunk": "UserProperties.@classmethod\ndef __get_validators__(cls):\n    yield cls.validate_to_json", "hash": "87bda01a5087997d81a702d5d9b2e38f83ebd14020175a292c6f4c34e2452433"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\common_models.py", "code_chunk": "UserProperties.@classmethod\ndef validate_to_json(cls, value):\n    if isinstance(value, str):\n        return cls(**json.loads(value))\n    return value", "hash": "f7829fc8401caefa22cf4c81af9d56d7e07cfcac8ec9866c9e691783b6fa818d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\common_models.py", "code_chunk": "from pydantic import BaseModel\nfrom pathlib import Path\nfrom typing import Optional\nfrom enum import Enum\nimport json\nDEFAULT_DOCUMENTS_FOLDER = Path('src/data/documents/')\nDEFAULT_GIT_FOLDER = Path('src/data/git/')\nDEFAULT_DATA_ANALYSIS_FOLDER = Path('src/data/data_analysis/')\nDEFAULT_USER_ID = 'admin'\nDEFAULT_SESSION_ID = 'admin_session'\nTIME_STRING_FORMAT = '%Y-%m-%d-%H:%M:%S'", "hash": "8c967ef200b19c11773021ff10324b80fd19ab4e9f12cc502e5d666e13802f23"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\base_agent.py", "code_chunk": "AgentConfig.BaseModel\nname: str = Field(description='Agent \u540d\u79f0')", "hash": "e599dc80c520252cffdbffdb15f4fb11b63c62f2b86a408bd33feab775ed537b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\base_agent.py", "code_chunk": "BaseAgent.ABC\nAgentConfig: AgentConfig", "hash": "92fc7d8322240bcea17081696b98c2b80a9ff3c21b92432979cf18d24372b2e2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\base_agent.py", "code_chunk": "from abc import ABC, abstractmethod\nfrom pydantic import BaseModel, Field", "hash": "94b7a8986681b6184305f55d3c64421cea63f797a2c81a2beb1be35cf679a845"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\__init__.py", "code_chunk": "from .software_engineer.software_engineer import *\nfrom .data_scientist.data_scientist import *\nfrom .data_analysis.data_analysis import *", "hash": "bab2d734d99042058fd118de54340c79e61fb32a29e8f58707df2555ea37aecd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "StepPlan.BaseModel\ncode: str = Field(description='Step execution code.')\nresult: str = Field(description='code result.')", "hash": "3ac1c4b4ae52c40075fa2d300b7388e037c414a852d627340aff41e34e9a25e5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def __init__(self):\n    self.LLMmodel = 'gpt-4-1106-preview'\n    self.maximum_steps = 100\n    self.openai_node = None\n    self.code_runner_node = CodeRunnerNode()\n    self.file_path_list = []\n    self.data_schema_dict = {}\n    self.project_type = None\n    self.project_requirement = None\n    self.step_plan = []\n    self.step_report = []\n    self.step_code = []\n    self.step_result = []\n    self.step_numbers = 0\n    self.base_dir = ''\n    self.conversation = []", "hash": "d95fecc598194042794bce6dfcd6c017f254eb8e9e7fd121e06f9ad00cdf8445"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def _init_openai_node(self):\n    \"\"\"\n        Initialize OpenAI node.\n        \"\"\"\n    self.openai_node = OpenAINode()\n    self.openai_node.add_single_message(Message(role='system', content=DA_PROMPT))", "hash": "3707f0029a63cb5b3f1df7b195b579a88e99c528681796bdccecd70b714dc1f1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def set_project_name(self, project_name: str):\n    self.project_name = project_name\n    if not self.base_dir.exists():\n        self.base_dir.mkdir(parents=True)", "hash": "f339e382173b7b14f20f46075cb4301df7879c4f26570b74ad314c6bdc343a46"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def add_file(self, file_name: str):\n    prompt = f'Add new file.'\n    file_type = file_name.split('.')[-1]\n    file_path = os.path.join(self.base_dir, file_name)\n    prompt += FILE_INFOMATION_PROMPT.format(file_name=file_name, file_type=file_type, file_path=file_path)\n    if file_type == 'csv' or file_type == 'json' or file_type == 'xlsx':\n        self.data_schema_dict['file_name'] = self.get_data_schema(file_path)\n    self.conversation.append({'role': 'system', 'content': f'Add new {file_type} file {file_name} at {file_path}.'})\n    self.file_path_list.append(file_path)", "hash": "343c210ca533fc5c98330ca8ed91b96720c58a93a676c27dcc39f3cea2d9106e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def add_file_path(self, file_path: str):\n    prompt = f'Add new file.'\n    file_type = file_path.split('.')[-1]\n    file_name = file_path.split('/')[-1]\n    prompt += FILE_INFOMATION_PROMPT.format(file_name=file_name, file_type=file_type, file_path=file_path)\n    if file_type == 'csv' or file_type == 'json' or file_type == 'xlsx':\n        self.data_schema_dict['file_name'] = self.get_data_schema(file_path)\n    self.conversation.append({'role': 'system', 'content': f'Add new {file_type} file {file_name} at {file_path}.'})\n    self.file_path_list.append(file_path)", "hash": "3a8cf1891e0f748893ba39b1b7b4d399a4cf2ed20d29082e8517d95696a581e8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def set_project_requirement(self, requirement: str):\n    self.project_requirement = requirement", "hash": "0b965b8b6d9d115ea69e676a498a7d2b7e673786d698ca3d36a6c5a2bccca7b4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def get_data_schema(self, file_path):\n    file_name = os.path.basename(file_path)\n    file_type = file_name.split('.')[-1]\n    if file_type == 'csv':\n        df = pd.read_csv(file_path)\n    elif file_type == 'json':\n        df = pd.read_json(file_path)\n    elif file_type == 'xlsx':\n        df = pd.read_excel(file_path)\n    schema = {}\n    for column in df.columns:\n        dtype = str(df[column].dtype)\n        if dtype == 'object':\n            dtype_detail = 'string'\n        elif 'int' in dtype or 'float' in dtype:\n            dtype_detail = {'type': dtype, 'min': df[column].min(), 'max': df[column].max()}\n        else:\n            dtype_detail = dtype\n    schema[column] = dtype_detail\n    schema_str = str(schema)\n    data_schema = DATA_SCHEMA.format(data_schema=schema_str, data_sample=df.head(3))\n    return data_schema", "hash": "a9477e325c88c3eb7b603f9c0d71356096affc464b3995179f4ef968cb21684f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def plan_project_type(self):\n    self._init_openai_node()\n    resp = self.openai_node.chat(input=ChatInput(model=self.LLMmodel, message_text=PROJECT_TYPE_SELECTOR_PROMPT.format(project_requirement=self.project_requirement)))\n    resp_content = resp.message.content\n    return resp_content", "hash": "a82157dc03e2bceb2a8d06118c9f63cc38d3affcd92f10953e5d4c42e5bf498a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def set_project_type(self, project_type: str):\n    self.project_type = project_type", "hash": "575f227ad3fe65855573b02602e0d5515e95cae609c4e1b8ad9f7e8074fc1ed2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def extract_plan(self, planner_output):\n    steps = re.split('\\\\n\\\\n---\\\\n\\\\n', planner_output.strip())\n    steps = [element for element in steps if element.startswith('# Step') or element.startswith('---\\n\\n# Step')]\n    self.step_plan = [step.strip() for step in steps]\n    self.step_numbers = len(self.step_plan)", "hash": "19c7a4a4f2a54bf640eb71c5379f0e8b6cd8dca9dd12313b182458285a1857df"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def obtain_step_plan(self):\n    planner_prompt = PLANNER_PROMPT[self.project_type].format(project_requirement=self.project_requirement, data_schema=str(self.data_schema_dict))\n    self._init_openai_node()\n    resp = self.openai_node.chat(input=ChatInput(model=self.LLMmodel, message_text=planner_prompt))\n    resp_content = resp.message.content\n    self.extract_plan(resp_content)\n    self.step_report = [0 for i in range(self.maximum_steps)]\n    self.step_code = [0 for i in range(self.maximum_steps)]\n    self.step_result = [0 for i in range(self.maximum_steps)]", "hash": "195d8624666e45c9ed8c110cdd0420f0f5bd864772f98e8c127ead4701090b20"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def step_code_generator(self, step_number):\n    if step_number == 0:\n        step_code_prompt = CODE_INTERPRETER_PREFIX + STEP_FILLER_BODY_STEP1.format(project_requirement=self.project_requirement, file_info=str(self.file_path_list), data_schema=str(self.data_schema_dict), step_plan=self.step_plan[step_number]) + CODE_INTERPRETER_SUFFIX\n    else:\n        step_code_prompt = CODE_INTERPRETER_PREFIX + STEP_FILLER_BODY_STEP_NOT1.format(project_requirement=self.project_requirement, file_info=str(self.file_path_list), data_schema=str(self.data_schema_dict), step_number_p=step_number, step_number=step_number + 1, step_code=self.step_code[step_number - 1], step_result=self.step_result[step_number - 1], step_plan=self.step_plan[step_number]) + CODE_INTERPRETER_SUFFIX\n    self._init_openai_node()\n    resp = self.openai_node.chat(input=ChatInput(model=self.LLMmodel, message_text=step_code_prompt))\n    resp_content = resp.message.content\n    match = re.search('```python\\\\n(.*?)```', resp_content, re.DOTALL)\n    if match:\n        python_code = match.group(1)\n    else:\n        python_code = 'no code generated'\n    if python_code.startswith('```python'):\n        python_code = python_code[10:]\n    if python_code.endswith('```'):\n        python_code = python_code[:-3]\n    self.step_code[step_number] = python_code\n    return python_code", "hash": "f0c8bb85f6bc53bf28578f475cff3ae843d8de4c86b4d04d388f56df0b66a7d9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def do_code_revise(self, code, requirement, step_number):\n    self._init_openai_node()\n    resp = self.openai_node.chat(input=ChatInput(model=self.LLMmodel, message_text=CODE_REVISE_PROMPT.format(file_info=str(self.file_path_list), data_schema=str(self.data_schema_dict), code=code, requirement=requirement)))\n    resp_content = resp.message.content\n    match = re.search('```python\\\\n(.*?)```', resp_content, re.DOTALL)\n    if match:\n        python_code = match.group(1)\n    else:\n        python_code = 'no code generated'\n    if python_code.startswith('```python'):\n        python_code = python_code[10:]\n    if python_code.endswith('```'):\n        python_code = python_code[:-3]\n    self.step_code[step_number] = python_code\n    return python_code", "hash": "81458d5ed00760897a2075455a7a4fc54610ed9d061216e002d685d23a249c29"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def step_result_filler(self, result, step_number):\n    self.step_result[step_number] = result", "hash": "6dc9d2717dd8cd749ea3de6ddeb3866774c23ceb1be46af423cdbb9e8e69e1c0"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def step_report_generator(self, step_number):\n    if step_number < self.step_numbers - 1:\n        step_report_prompt = STEP_PARAGRAPH_PROMPT.format(project_requirement=self.project_requirement, step_number=step_number + 1, step_plan=self.step_plan[step_number], step_code=self.step_code[step_number], step_result=self.step_result[step_number])\n    elif step_number == self.step_numbers - 1:\n        step_report_prompt = STEP_FILLER_BODY_STEP_CONCLUSION.format(project_requirement=self.project_requirement, previous_report=self.step_report[step_number - 1], step_plan=self.step_plan[step_number])\n    self._init_openai_node()\n    resp = self.openai_node.chat(input=ChatInput(model=self.LLMmodel, message_text=step_report_prompt))\n    resp_content = resp.message.content\n    self.step_report[step_number] = resp_content", "hash": "6a89f8ea95573b83f565e7bba2c3a045a77b71d06ea8d7219cb46c537c22a21f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def add_focus_file(self, file_path):\n    \"\"\"\n        Add file to repo.\n        \"\"\"\n    self.repo_manager.add_focus_file(file_path)", "hash": "2bfa97dcec8abe77e6f06e624132a1bcd8b8f7f86868a4b5d9b1e2db15a213bd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.BaseAgent\nconfig: AgentConfig = AgentConfig(**data_analysis_config)", "hash": "86f3d72d0d60431b24f4af094169bd24491057ecbfadbca482e335690f0ee077"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def __init__(self):\n    self.LLMmodel = 'gpt-4-1106-preview'\n    self.maximum_steps = 100\n    self.openai_node = None\n    self.code_runner_node = CodeRunnerNode()\n    self.file_path_list = []\n    self.data_schema_dict = {}\n    self.project_type = None\n    self.project_requirement = None\n    self.step_plan = []\n    self.step_report = []\n    self.step_code = []\n    self.step_result = []\n    self.step_numbers = 0\n    self.base_dir = ''\n    self.conversation = []", "hash": "d95fecc598194042794bce6dfcd6c017f254eb8e9e7fd121e06f9ad00cdf8445"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def _init_openai_node(self):\n    \"\"\"\n        Initialize OpenAI node.\n        \"\"\"\n    self.openai_node = OpenAINode()\n    self.openai_node.add_single_message(Message(role='system', content=DA_PROMPT))", "hash": "3707f0029a63cb5b3f1df7b195b579a88e99c528681796bdccecd70b714dc1f1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def set_project_name(self, project_name: str):\n    self.project_name = project_name\n    if not self.base_dir.exists():\n        self.base_dir.mkdir(parents=True)", "hash": "f339e382173b7b14f20f46075cb4301df7879c4f26570b74ad314c6bdc343a46"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def add_file(self, file_name: str):\n    prompt = f'Add new file.'\n    file_type = file_name.split('.')[-1]\n    file_path = os.path.join(self.base_dir, file_name)\n    prompt += FILE_INFOMATION_PROMPT.format(file_name=file_name, file_type=file_type, file_path=file_path)\n    if file_type == 'csv' or file_type == 'json' or file_type == 'xlsx':\n        self.data_schema_dict['file_name'] = self.get_data_schema(file_path)\n    self.conversation.append({'role': 'system', 'content': f'Add new {file_type} file {file_name} at {file_path}.'})\n    self.file_path_list.append(file_path)", "hash": "343c210ca533fc5c98330ca8ed91b96720c58a93a676c27dcc39f3cea2d9106e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def add_file_path(self, file_path: str):\n    prompt = f'Add new file.'\n    file_type = file_path.split('.')[-1]\n    file_name = file_path.split('/')[-1]\n    prompt += FILE_INFOMATION_PROMPT.format(file_name=file_name, file_type=file_type, file_path=file_path)\n    if file_type == 'csv' or file_type == 'json' or file_type == 'xlsx':\n        self.data_schema_dict['file_name'] = self.get_data_schema(file_path)\n    self.conversation.append({'role': 'system', 'content': f'Add new {file_type} file {file_name} at {file_path}.'})\n    self.file_path_list.append(file_path)", "hash": "3a8cf1891e0f748893ba39b1b7b4d399a4cf2ed20d29082e8517d95696a581e8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def set_project_requirement(self, requirement: str):\n    self.project_requirement = requirement", "hash": "0b965b8b6d9d115ea69e676a498a7d2b7e673786d698ca3d36a6c5a2bccca7b4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def get_data_schema(self, file_path):\n    file_name = os.path.basename(file_path)\n    file_type = file_name.split('.')[-1]\n    if file_type == 'csv':\n        df = pd.read_csv(file_path)\n    elif file_type == 'json':\n        df = pd.read_json(file_path)\n    elif file_type == 'xlsx':\n        df = pd.read_excel(file_path)\n    schema = {}\n    for column in df.columns:\n        dtype = str(df[column].dtype)\n        if dtype == 'object':\n            dtype_detail = 'string'\n        elif 'int' in dtype or 'float' in dtype:\n            dtype_detail = {'type': dtype, 'min': df[column].min(), 'max': df[column].max()}\n        else:\n            dtype_detail = dtype\n    schema[column] = dtype_detail\n    schema_str = str(schema)\n    data_schema = DATA_SCHEMA.format(data_schema=schema_str, data_sample=df.head(3))\n    return data_schema", "hash": "a9477e325c88c3eb7b603f9c0d71356096affc464b3995179f4ef968cb21684f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def plan_project_type(self):\n    self._init_openai_node()\n    resp = self.openai_node.chat(input=ChatInput(model=self.LLMmodel, message_text=PROJECT_TYPE_SELECTOR_PROMPT.format(project_requirement=self.project_requirement)))\n    resp_content = resp.message.content\n    return resp_content", "hash": "a82157dc03e2bceb2a8d06118c9f63cc38d3affcd92f10953e5d4c42e5bf498a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def set_project_type(self, project_type: str):\n    self.project_type = project_type", "hash": "575f227ad3fe65855573b02602e0d5515e95cae609c4e1b8ad9f7e8074fc1ed2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def extract_plan(self, planner_output):\n    steps = re.split('\\\\n\\\\n---\\\\n\\\\n', planner_output.strip())\n    steps = [element for element in steps if element.startswith('# Step') or element.startswith('---\\n\\n# Step')]\n    self.step_plan = [step.strip() for step in steps]\n    self.step_numbers = len(self.step_plan)", "hash": "19c7a4a4f2a54bf640eb71c5379f0e8b6cd8dca9dd12313b182458285a1857df"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def obtain_step_plan(self):\n    planner_prompt = PLANNER_PROMPT[self.project_type].format(project_requirement=self.project_requirement, data_schema=str(self.data_schema_dict))\n    self._init_openai_node()\n    resp = self.openai_node.chat(input=ChatInput(model=self.LLMmodel, message_text=planner_prompt))\n    resp_content = resp.message.content\n    self.extract_plan(resp_content)\n    self.step_report = [0 for i in range(self.maximum_steps)]\n    self.step_code = [0 for i in range(self.maximum_steps)]\n    self.step_result = [0 for i in range(self.maximum_steps)]", "hash": "195d8624666e45c9ed8c110cdd0420f0f5bd864772f98e8c127ead4701090b20"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def step_code_generator(self, step_number):\n    if step_number == 0:\n        step_code_prompt = CODE_INTERPRETER_PREFIX + STEP_FILLER_BODY_STEP1.format(project_requirement=self.project_requirement, file_info=str(self.file_path_list), data_schema=str(self.data_schema_dict), step_plan=self.step_plan[step_number]) + CODE_INTERPRETER_SUFFIX\n    else:\n        step_code_prompt = CODE_INTERPRETER_PREFIX + STEP_FILLER_BODY_STEP_NOT1.format(project_requirement=self.project_requirement, file_info=str(self.file_path_list), data_schema=str(self.data_schema_dict), step_number_p=step_number, step_number=step_number + 1, step_code=self.step_code[step_number - 1], step_result=self.step_result[step_number - 1], step_plan=self.step_plan[step_number]) + CODE_INTERPRETER_SUFFIX\n    self._init_openai_node()\n    resp = self.openai_node.chat(input=ChatInput(model=self.LLMmodel, message_text=step_code_prompt))\n    resp_content = resp.message.content\n    match = re.search('```python\\\\n(.*?)```', resp_content, re.DOTALL)\n    if match:\n        python_code = match.group(1)\n    else:\n        python_code = 'no code generated'\n    if python_code.startswith('```python'):\n        python_code = python_code[10:]\n    if python_code.endswith('```'):\n        python_code = python_code[:-3]\n    self.step_code[step_number] = python_code\n    return python_code", "hash": "f0c8bb85f6bc53bf28578f475cff3ae843d8de4c86b4d04d388f56df0b66a7d9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def do_code_revise(self, code, requirement, step_number):\n    self._init_openai_node()\n    resp = self.openai_node.chat(input=ChatInput(model=self.LLMmodel, message_text=CODE_REVISE_PROMPT.format(file_info=str(self.file_path_list), data_schema=str(self.data_schema_dict), code=code, requirement=requirement)))\n    resp_content = resp.message.content\n    match = re.search('```python\\\\n(.*?)```', resp_content, re.DOTALL)\n    if match:\n        python_code = match.group(1)\n    else:\n        python_code = 'no code generated'\n    if python_code.startswith('```python'):\n        python_code = python_code[10:]\n    if python_code.endswith('```'):\n        python_code = python_code[:-3]\n    self.step_code[step_number] = python_code\n    return python_code", "hash": "81458d5ed00760897a2075455a7a4fc54610ed9d061216e002d685d23a249c29"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def step_result_filler(self, result, step_number):\n    self.step_result[step_number] = result", "hash": "6dc9d2717dd8cd749ea3de6ddeb3866774c23ceb1be46af423cdbb9e8e69e1c0"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def step_report_generator(self, step_number):\n    if step_number < self.step_numbers - 1:\n        step_report_prompt = STEP_PARAGRAPH_PROMPT.format(project_requirement=self.project_requirement, step_number=step_number + 1, step_plan=self.step_plan[step_number], step_code=self.step_code[step_number], step_result=self.step_result[step_number])\n    elif step_number == self.step_numbers - 1:\n        step_report_prompt = STEP_FILLER_BODY_STEP_CONCLUSION.format(project_requirement=self.project_requirement, previous_report=self.step_report[step_number - 1], step_plan=self.step_plan[step_number])\n    self._init_openai_node()\n    resp = self.openai_node.chat(input=ChatInput(model=self.LLMmodel, message_text=step_report_prompt))\n    resp_content = resp.message.content\n    self.step_report[step_number] = resp_content", "hash": "6a89f8ea95573b83f565e7bba2c3a045a77b71d06ea8d7219cb46c537c22a21f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisAgent.def add_focus_file(self, file_path):\n    \"\"\"\n        Add file to repo.\n        \"\"\"\n    self.repo_manager.add_focus_file(file_path)", "hash": "2bfa97dcec8abe77e6f06e624132a1bcd8b8f7f86868a4b5d9b1e2db15a213bd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis.py", "code_chunk": "import os\nfrom pydantic import BaseModel, Field\nfrom pathlib import Path\nimport pandas as pd\nimport re\nfrom ..base_agent import BaseAgent, AgentConfig\nfrom .data_analysis_prompt import *\nfrom ...nodes import OpenAINode, ChatConfig, OpenAIResp, CodeRunnerNode, Message, RunCodeInput, FunctionDefinition, DataAnalysisNode, LoadDataInput, ChatInput\ndata_analysis_config = {'name': 'data_analysis', 'description': 'A agent for data analysis.'}\nfrom ....utils.output_parser import LLMOutputParser\nPROJ_PATH = Path('src/data/documents')", "hash": "fc7418b751696e8d4dcb2bfe5d26aa994e9d756a117e9b638ee8ec3369fd017d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\data_analysis_prompt.py", "code_chunk": "from .planner_prompt import PLANNER_PROMPT\nDA_PROMPT = '\\nYou are a data scientist working on a project. You are working on a statistic modeling task.\\n'\nSINGLE_DF = '\\nYou are working with a pandas dataframe in Python. The name of the dataframe is df.\\n\\nThe header rows of the dataframe are as follows:\\n{df_header}\\n\\n'\nMULTIPLE_DF = '\\nYou are working with {num_dfs} pandas dataframes in Python named df1, df2, etc. You\\n\\nThe header rows of the dataframe are as follows:\\n{df_headers}\\n\\n'\nFILE_INFO = 'system: Add a filename at {file_path}'\nFILE_INFOMATION_PROMPT = '\\n[File Name] {file_name}\\n[File Type] {file_type}\\n[File Path] {file_path}\\n'\nDATA_SCHEMA = \"\\nThe schema dictionary uses DataFrame column names as keys. For numeric columns, the value is another dictionary detailing its type, min, and max values; for string columns, the value is simply string; and for others, it's the datatype as a string.\\n\\n{data_schema}\\n\\nThe sample of the data:\\n\\n{data_sample}\\n\\n\"\nCODE_INTERPRETER_PREFIX = \"\\nYou are an AI code interpreter.\\nYour goal is to help users do a variety of jobs by executing Python code.\\n\\nYou should comprehend the user's requirements carefully & to the letter.\\nThen write python code to solve the problem.\\nAll of the files path will be listed in a list followed by (file info):\\nAll of the files schema will be listed in a dict followed by (data schema):\\nThe question is as below:\\n\\n------\\n\\n\"\nCODE_INTERPRETER_SUFFIX = '\\n\\n------\\n\\n***Your code should output answer to STDOUT. (i.e. use python `print` function)***\\nYou need to put the code you generated inside the [] and surround it with triple backticks.\\nThe example output is as follows:\\n\\n------\\n## code_result\\n```python\\npython code you generated as a string'\nSUPPORT_PROJECT_TYPE = ['Regression', 'Classification', 'ANOVA', 'Clustering', 'Time Series', 'Association Rules', 'NLP', 'Recommender System', 'Dimension Reduction', 'Survival Analysis', 'Longitudinal Analysis', 'Causal Inference', 'Non-Parametric', 'Basic t-test', 'Basic Chi-Square test', 'Linear Regression', 'Logistic Regression', 'Time Series ARIMA', 'Time Series SARIMA', 'One-Way ANOVA', 'Two-Way ANOVA', 'Other']\nPROJECT_TYPE_SELECTOR_PROMPT = 'Here is my project requirement: {project_requirement}\\n\\nPlease tell me what type of project it is, and only output the project type.\\n\\nIf the type is other, please output \"other: xxx\" where xxx is the type.\\n\\nYou can choose from the following options: ' + ', '.join(SUPPORT_PROJECT_TYPE)\nREVISE_PLAN_PROMPT = 'Here is my project context: {project_requirement}\\n\\nWe are at step {step_number}. Here is the previous step report result: {previous_result}\\n\\nNow please revise the plan of following steps. Here is the plan:\\n\\n{step_plans}\\n\\nIf no need to revise, please output \"no need to revise\" only.\\n\\n'\nSTEP_FILLER_BODY_STEP1 = 'Here is my project context:\\n\\n{project_requirement}\\n\\nHere is my project data (in a list):\\n\\n(file info):\\n\\n{file_info}\\n\\nThe data schema will be a dictionary that use file path as keys. For each file path key, the value is\\nanother dictionary detailing its column names, data types, and other information.\\nHere is the data schema (in a dictionary):\\n\\n{data_schema}\\n\\nYou should write code base on the provided data schema and file info. Now we start step 1. Here is the step 1 plan:\\n\\n{step_plan}\\n\\n'\nSTEP_FILLER_BODY_STEP_NOT1 = 'Here is my project context: {project_requirement}\\n\\nHere is my project data (in a list):\\n\\n{file_info}\\n\\nThe data schema will be a dictionary that use file path as keys. For each file path key, the value is\\nanother dictionary detailing its column names, data types, and other information.\\nHere is the data schema (in a dictionary):\\n\\n{data_schema}\\n\\nHere is the previous code for step {step_number_p}:\\n\\n{step_code}\\n\\nHere is the step {step_number_p} result:\\n\\n{step_result}\\n\\nYou should write code base on the provided data schema and file info, and previous code, result. Now we start step {step_number}. Here is the step {step_number} plan:\\n\\n{step_plan}\\n\\n'\nSTEP_FILLER_BODY_STEP_CONCLUSION = 'Here is my project context: {project_requirement}\\n\\nHere is the previous step report result: {previous_report}\\n\\nNow we start step Conclusion. Here is the plan:\\n\\n{step_plan}\\n\\nYou need to provide the report of the conclusion part. Please give suggestions of the previous steps report if needed.\\n\\n'\nSTEP_PARAGRAPH_PROMPT = \"Here is my project context: {project_requirement}\\n\\nHere is the step {step_number} plan:\\n\\n{step_plan}\\n\\nHere is the step {step_number} code:\\n\\n{step_code}\\n\\nHere is the step {step_number} result:\\n\\n{step_result}\\n\\nNow please convert the result into this part of the report.\\nYou need to carefully analysis the result and organize it into a report with markdown syntax accorading to the step plan.\\ninclude table, plot, and text if neccessary.\\nThe plot indicated in result with [plot i] will be inserted in the report with [plot i] only. This [] does not apply to tables.\\nDon't include any markdown when indicating the plot. Only use [plot i] to indicate the location.\\nIf there is no [plot i] in the result, please do not include any plot in the report.\\n\\n\"\nSAMPLE_REQUIREMENT = 'In this project we want to analysis the dataset containing information on 76 people who undertook one of three diets (referred to as diet A, B and C). The main question of the project is to determine which diet was best for losing weight. It is important because the analysis result can help the company select the best product to invest. In this project we will use the one factor ANOVA method to carry out the conclusion, and obtain the pairwise confidence interval for all three diets.\\n'\nSAMPLE_REVISE_REQUIREMENT = 'Fix the following code and make it executable\\n'\nCODE_REVISE_PROMPT = \"Here is my project data (in a list):\\n\\n{file_info}\\n\\nThe data schema will be a dictionary that use file path as keys. For each file path key, the value is\\nanother dictionary detailing its column names, data types, and other information.\\nHere is the data schema (in a dictionary):\\n\\n{data_schema}\\n\\nHere is my existing code:\\n\\n{code}\\n\\nNow I need you revise the code to make it executable. The information to fix it is as follows:\\n{requirement}. Please provide the all of the revised code, not only the modified part.\\nPlease don't change the data loading path.\\n\\n```python\\npython code you generated\"", "hash": "68da9d1826b06612ce724a7b2a275c71e0e2d480a0bbb0c3e2ce67701eb5d67d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_analysis\\planner_prompt.py", "code_chunk": "PLANNER_PROMPT = {}\nPLANNER_PROMPT['ANOVA'] = \"\\nHere is my project requirement: {project_requirement}\\n\\nHere is my data schema:\\n{data_schema}\\n\\nMy project will have several parts:\\n\\nHere is the sample project plan if we want to do the ANOVA modeling on a sample dataset:\\n\\n---\\n\\n# Step 1: Data Cleaning and Summary\\n\\n- Detail the data cleaning process, identifying missing values, outliers, and any anomalies in the dataset.\\n- Outline the generation of a data summary that includes descriptive statistics to understand the central tendency and dispersion.\\n- Plan to conduct exploratory data analysis (EDA), such as plotting distributions of variables and discovering patterns or relationships.\\n\\n---\\n\\n# Step 2: Checking ANOVA Assumptions\\n\\n- Establish a checklist for the three main assumptions required for ANOVA: normality, homogeneity of variance, and independence.\\n- Describe the methods to test each assumption, such as Shapiro-Wilk test for normality, Levene's test for equal variances, and design or data collection techniques for independence.\\n- Plan for potential remedial actions if assumptions are not met, such as data transformation or using non-parametric tests.\\n\\n---\\n\\n# Step 3: ANOVA Model Fitting\\n\\n- Define the process of fitting an ANOVA model to the dataset, including the selection of factors and levels to be tested.\\n- Describe the criteria for interpreting the ANOVA table results, focusing on F-statistic and p-values.\\n- Ensure the plan includes the determination of between-group and within-group variabilities.\\n\\n---\\n\\n# Step 4: Post Hoc Analysis\\n\\n- Prepare a scheme for performing post hoc tests in case of a significant ANOVA result, to find out which groups differ.\\n- Decide on which post hoc test to use (e.g., Tukey, Bonferroni, Scheff\u00e9) depending on the study design and the data characteristics.\\n- Plan for the interpretation of the post hoc tests, understanding the pairwise comparisons and the adjustment for multiple comparisons.\\n\\n---\\n\\nNow you need to help me plan what's the specific plan of each part of the project. Please don't include any code, just the plan in text. Your output should be this format:\\n\\n---\\n\\n# Step i\\n\\nplan for step i\\n\\n---\\n\\nPlease only output the plan of each step.\\n\\n\"\nPLANNER_PROMPT['Time Series'] = \"\\nHere is my project requirement: {project_requirement}\\n\\nHere is my data schema: {data_schema}\\n\\nMy project will have several steps, and it will be a time series analysis.\\n\\nHere is the sample project plan if we want to use SARIMA model to model the a sample data:\\n\\n---\\n\\n# Step 1: Exploratory Analysis\\n\\n- Plot the train data.\\n- Note observations like increasing trend, seasonality, and variance.\\n- Use Box-Cox transformation to stabilize variance.\\n\\n---\\n\\n# Step 2: Model Preparation\\n\\n- Analysis the seasonal effect and trend effect.\\n- Ensure time series is stationary by making lag 1 and lag 12 differences.\\n- Confirm stationarity with Augmented Dickey-Fuller Test.\\n\\n---\\n\\n# Step 3: Model Selection\\n\\n- Examine sample ACF and PACF plots to determine model parameters.\\n- Use the determined parameters to select a range of candidate models.\\n- Calculate AICc for each candidate model.\\n- Choose the model with the smallest AICc as the best model.\\n\\n---\\n\\n# Step 4: Model Diagnostic:\\n\\n- Check residuals of the model to ensure they resemble white noise.\\n- Validate normality using histogram, qqplot, and Shapiro-Wilks test.\\n- Confirm model residuals' independence using Box-Pierce, Ljung-Box, and McLeod-Li tests.\\n- Verify model is stationary and invertible by checking characteristic roots.\\n\\n---\\n\\n# Step 5: Forecasting\\n\\n- Forecast electricity production for the years 1991 to 1995 using the selected SARIMA model.\\n- Plot the forecasts along with a 95 percentage confidence interval.\\n- Compare forecasted values with actual test data.\\n\\n---\\n\\nNow you need to help me plan what's the specific plan of each part of the project. Please don't include any code, just the plan in text. Your output should be this format:\\n\\n---\\n\\n# Step i\\n\\nplan for step i\\n\\n---\\n\\nPlease only output the plan of each step.\\n\\n\"\nPLANNER_PROMPT['Regression'] = \"\\nHere is my project requirement: {project_requirement}\\n\\nHere is my data schema: {data_schema}\\n\\nMy project will have several steps, and it will be a regression analysis.\\n\\nNow you need to help me plan what's the specific plan of each part of the project. Please don't include any code, just the plan in text. Your output should be this format:\\n\\n---\\n\\n# Step i\\n\\nplan for step i\\n\\n---\\n\\nPlease only output the plan of each step.\\n\\n\"\nPLANNER_PROMPT['Causal Inference'] = \"\\nHere is my project requirement: {project_requirement}\\n\\nHere is my data schema:\\n{data_schema}\\n\\nMy project will have several parts:\\n\\nHere is the sample project plan if we want to test the causality of a variable:\\n\\n---\\n\\n# Step 1: Identification of Variables\\n\\n- Examine the data schema and project requirements to discern treatment and outcome variables.\\n- Define each identified variable clearly in the context of the study.\\n- Ensure variables are in line with the project's causal framework.\\n\\n---\\n\\n# Step 2: Control for Confounders\\n\\n- Identify potential confounders that may influence both the treatment and outcome variables.\\n- Develop a plan to control for these confounders through statistical methods or study design.\\n- Justify the choice of methods for confounder control.\\n\\n---\\n\\n# Step 3: Selection of Causal Inference Method\\n\\n- Review causal inference methods that align with the project's data and objectives.\\n- Choose a method and delineate the process for its implementation, ensuring adherence to its assumptions.\\n- Prepare to detail each step within the chosen method without the use of code.\\n\\n---\\n\\n# Step 4: Sensitivity Analysis\\n\\n- Plan a sensitivity analysis to test the stability of the causal estimates against assumptions.\\n- Determine the range of variations for the analysis and the approach to interpret these results.\\n- Ensure the analysis can identify the conditions under which the causal estimate is valid.\\n\\n---\\n\\n# Step 5: Interpretation and Communication\\n\\n- Layout the procedure for interpreting the calculated causal effect, considering its size, direction, and statistical significance.\\n- Craft a plan for the effective communication of these findings to both technical and non-technical stakeholders.\\n- Avoid technical jargon and focus on the implications of the causal relationship.\\n\\n---\\n\\n# Step i\\n\\nplan for step i\\n\\n---\\n\\nPlease only output the plan of each step.\\n\\n\"\nPLANNER_PROMPT['Non-Parametric'] = '\\nHere is my project requirement: {project_requirement}\\n\\nHere is my data schema:\\n{data_schema}\\n\\nMy project will be structured into several parts\\n\\nHere is the sample project plan if we want do a non parametric test for a dataset:\\n\\n---\\n\\n# Step 1: Test Selection\\n\\n- Review the types of data and their distributions to determine the most suitable non-parametric test.\\n- Consider the sample size, number of samples, and whether the data are paired or independent.\\n- Document the decision process and justify the selection of the non-parametric test [e.g., data type, distribution].\\n\\n---\\n\\n# Step 2: Data Preparation\\n\\n- Devise a plan for dealing with missing values, such as imputation or exclusion, and justify the chosen method.\\n- Outline procedures for identifying and handling outliers.\\n- Confirm that the data meets the assumptions for the chosen non-parametric test [e.g., independence of observations].\\n\\n---\\n\\n# Step 3: Test Execution\\n\\n- Detail the steps to perform the selected non-parametric test without the use of statistical software code.\\n- Mention the specific test to be used [e.g., Mann-Whitney U test, Wilcoxon signed-rank test, Kruskal-Wallis H test] depending on the data configuration.\\n- Ensure the execution plan includes all necessary comparisons and groupings as per the project requirements.\\n\\n---\\n\\n# Step 4: Results Assessment\\n\\n- Define the approach to assess the test results, with emphasis on significance levels and p-values.\\n- Include considerations for interpreting the rank sums or test statistics provided by the non-parametric test.\\n- Plan to evaluate the strength and direction of the observed effects.\\n\\n---\\n\\n# Step 5: Reporting Findings\\n\\n- Create a blueprint for reporting the results that outlines how findings will be presented.\\n- Discuss the implications of the test outcomes in the context of the project requirement.\\n- Ensure the report is understandable and includes all relevant statistical terminology [e.g., significance level, test statistic].\\n\\n---\\n\\n# Step i\\n\\nplan for step i\\n\\n---\\n\\nPlease only output the plan of each step.\\n\\n'\nPLANNER_PROMPT['Dimension Reduction'] = \"\\nHere is my project requirement: {project_requirement}\\n\\nHere is my data schema:\\n{data_schema}\\n\\nMy project will be structured into several parts\\n\\nHere is the sample project plan if we want do a dimension reduction for a dataset:\\n\\n---\\n\\n# Step 1\\n\\n[Preparation for Dimension Reduction]\\n- Assess data types across the dataset to determine preprocessing needs.\\n- Develop a strategy for handling missing values with methods such as imputation or exclusion.\\n- Standardize or normalize features to ensure uniform scale, essential for many dimension reduction techniques.\\n- Identify potential issues like multicollinearity or high-dimensionality that could influence the reduction process and plan for ways to address them.\\n\\n---\\n\\n# Step 2\\n\\n[Selection of Dimension Reduction Method]\\n- Evaluate different dimension reduction methods like PCA or t-SNE against the project requirements, considering the characteristics of the data.\\n- Determine the project's goals\u2014whether to visualize data, improve computational efficiency, or reduce noise\u2014and select the method that best aligns with these objectives.\\n- Balance the computational efficiency and the ability to maintain the quality of the information from the original dataset when choosing the method.\\n\\n---\\n\\n# Step 3\\n\\n[Implementation of Dimension Reduction Technique]\\n- Plan the application of the selected technique to the preprocessed dataset.\\n- Describe the process to determine the optimal number of dimensions to retain, using methods such as explained variance or model performance.\\n- Ensure that the dimension reduction technique captures the significant structure of the data while minimizing information loss.\\n\\n---\\n\\n# Step 4\\n\\n[Evaluation of Reduced Data]\\n- Establish metrics for evaluating the performance of the dimension reduction, such as the proportion of variance retained or reconstruction error.\\n- Interpret the reduced dimensions in terms of their contribution to variance and the insights they provide into the data structure.\\n- Formulate a plan for how to utilize the reduced data in future stages of the project, considering any adjustments that may be necessary based on the evaluation.\\n\\n---\\n\\nNow you need to help me plan what's the specific plan of each part of the project. Please don't include any code, just the plan in text. Your output should be this format:\\n\\n---\\n\\n# Step i\\n\\nplan for step i\\n\\n---\\n\\nPlease only output the plan of each step.\\n\\n\"\nPLANNER_PROMPT['Linear Regression'] = '\\nHere is my project requirement: {project_requirement}\\n\\nHere is my data schema: {data_schema}\\n\\nMy project will have several steps, and it will be a linear regression analysis.\\n\\nHere is the linear regression project plan if we want to use Multiple or Single Linear Regression model to model the a sample data:\\n\\n---\\n\\n# Step 1: Data Understanding and Preparation\\n\\n- Load and explore the dataset to identify preliminary trends and relationships.\\n- Display the scatter plot between the response variable and the regressor. Also show the distribution of each variable. And use boxplot to check the outliers.\\n- Address missing values and prepare the data for modeling, ensuring it meets the requirements for a robust linear regression analysis.\\n\\n---\\n\\n# Step 2: Building the Linear Regression Model\\n\\n- Establish an initial model, selecting appropriate predictor(s) and the response variable based on your topic.\\n- Assess the model\\'s initial performance, identifying significant predictors and their corresponding coefficients.\\n\\n---\\n\\n# Step 3: Model Validation and Assumption Checking\\n\\n- If applicable, refine the model using methods like stepwise regression or criterion-based selection for a multivariate approach.\\n- Usually use QQ plot, \"residuals vs fitted value\" plot and \"residuals vs. leverage\" plot to check of linear regression assumptions, ensuring linearity, independence, homoscedasticity, and normality of residuals.  Apply remedial measures if any violations are detected.\\n\\n---\\n\\n# Step 4: Diagnostics and Influential Observations\\n\\n- Examine the model for issues like multicollinearity (in a multivariate context) and influential outliers that could skew results, using diagnostic measures and plots.\\n- Adjust the model as necessary to mitigate issues identified during diagnostics, enhancing its reliability and accuracy.\\n- Do not do any prediction\\n\\n---\\n\\n# Step 5: Model Interpretation and Predictions\\n\\n- Clearly interpret the final model outcomes, explaining what the coefficients imply in a real-world context related to your topic.\\n- Discuss the model\\'s predictive capabilities and how they can be practically applied in decision-making scenarios.\\n- Make sure use the press statistic to show the validate the predictive ability of the model.\\n\\n---\\n\\nNow you need to help me plan what\\'s the specific plan of each part of the project. Please don\\'t include any code, just the plan in text. Your output should be this format:\\n\\n---\\n\\n# Step i\\n\\nplan for step i\\n\\n---\\n\\nPlease only output the plan of each step.\\n\\n'\nPLANNER_PROMPT['Basic Chi-Square test'] = \"\\nHere is my project requirement: {project_requirement}\\n\\nHere is my data schema: {data_schema}\\n\\nMy project will have several steps, and it will do basic chi-square test.\\n\\nHere is the basic chi-square test if we want to use do basic chi-square test base on the data:\\n\\n---\\n\\n# Step 1: Data Understanding and Preparation\\n\\n- Load and explore the dataset to identify preliminary trends and relationships.\\n- Display the scatter plot between the response variable and the regressor. Also show the distribution of each variable. And use boxplot to check the outliers.\\n- Address missing values and prepare the data for modeling, ensuring it meets the requirements for a robust linear regression analysis.\\n\\n---\\n\\n# Step 2: Formulate Hypotheses\\n\\n- Define your null hypothesis (H0) and alternative hypothesis (Ha) specific to your t-test analysis:H0: There is no association between the two categorical variables (independence).Ha: There is an association between the two categorical variables.\\n\\n---\\n\\n# Step 3: Perform the Chi-Square Test (Do it by coding)\\n\\n- Construct a contingency table of frequencies from your data.\\n- Calculate the expected frequencies for each cell of the table.\\n- Choose the appropriate chi-square test based on your data and assumptions (e.g., chi-square test of independence).\\n- Calculate the chi-square statistic, degrees of freedom, and the p-value.\\n- Discuss the practical implications of the observed association (or lack thereof) between the categories.\\n- Offer evidence-based recommendations or insights based on the chi-square results, especially concerning any potential causal relationships or predictive insights.\\n\\n---\\n\\nNow you need to help me plan what's the specific plan of each part of the project. Please don't include any code, just the plan in text. Your output should be this format:\\n\\n---\\n\\n# Step i\\n\\nplan for step i\\n\\n---\\n\\nPlease only output the plan of each step.\\n\\n\"\nPLANNER_PROMPT['Basic t-test'] = \"\\nHere is my project requirement: {project_requirement}\\n\\nHere is my data schema: {data_schema}\\n\\nMy project will have several steps, and it will be a basic t-test.\\n\\nHere is the basic t-test project plan if we want to use basic t-test base on the sample data:\\n\\n---\\n\\n# Step 1: Data Understanding and Preparation\\n\\n- Load and explore the dataset to identify preliminary trends and relationships.\\n- Display the scatter plot between the response variable and the regressor. Also show the distribution of each variable. And use boxplot to check the outliers.\\n- Address missing values and prepare the data for modeling, ensuring it meets the requirements for a robust linear regression analysis.\\n\\n---\\n\\n# Step 2: Formulate Hypotheses\\n\\n- Define your null hypothesis (H0) and alternative hypothesis (Ha) specific to your t-test analysis:H0: There is no significant difference between the means of Group A and Group B.Ha: There is a significant difference between the means of Group A and Group B.\\n\\n---\\n\\n# Step 3: Perform the T-Test\\n\\n- Choose the appropriate type of t-test based on your data and assumptions (e.g., independent samples t-test for comparing two separate groups).\\n- Calculate the t-statistic and degrees of freedom.\\n- Determine the critical t-value based on your chosen significance level (e.g., \u03b1 = 0.05).\\n- Calculate the p-value associated with the t-statistic.\\n- Discuss the practical implications of the observed differences (or lack thereof) between the two groups.\\n- Offer evidence-based recommendations or insights based on the t-test results.\\n\\n---\\n\\nNow you need to help me plan what's the specific plan of each part of the project. Please don't include any code, just the plan in text. Your output should be this format:\\n\\n---\\n\\n# Step i\\n\\nplan for step i\\n\\n---\\n\\nPlease only output the plan of each step.\\n\\n\"\nPLANNER_PROMPT['Logistic Regression'] = \"\\nHere is my project requirement: {project_requirement}\\n\\nHere is my data schema:\\n{data_schema}\\n\\n---\\n\\n# Step 1: Data Understanding and Preparation\\n\\n- Descriptive Statistics: Obtain measures such as mean, median, standard deviation, minimum, and maximum to provide insights into each variable's central tendency and variability. Remember, distincation continous variables and categorical variables. They should use different appropriate method.\\n- Categorical Data Handling:: Identify categorical variables in the dataset.Convert categorical variables into dummy variables or use other appropriate encoding methods. Ensure to avoid the dummy variable trap by dropping one level if necessary.Merge the encoded columns back into the dataset and drop the original categorical columns.\\n- Data Visualization: Utilize histograms to understand the distributions for all variables, scatter plots to observe bivariate relationships for continous variables, and boxplots for quartile analysis and outlier detection for continous variables.\\n- Missing Data Analysis: Address any missing values, considering techniques from simple listwise deletion to more advanced methods like multiple imputation.\\n\\n---\\n\\n# Step 2: Diagnostic\\n\\n- Multicollinearity Check: Employ VIF or correlation matrices. If VIFs exceed 10, consider strategies to mitigate multicollinearity, such as removing variables or applying ridge regression.\\n- Logistic regression does not require a linear relationship between the dependent and independent variables.  Second, the error terms (residuals) do not need to be normally distributed.  Third, homoscedasticity is not required.  Finally, the dependent variable in logistic regression is not measured on an interval or ratio scale.\\n\\n---\\n\\n# Step 3: Model Fitting\\n\\n- Logistic Regression Modeling: Apply logistic regression, specifying the response variable and predictors. Rely on maximum likelihood estimation (MLE) for coefficient predictions.\\n- Model Specification: Consider including interaction terms if hypothesized and ensure all first-order terms are present. Utilize likelihood ratio tests to compare models.\\n- Statistical Significance: Examine p-values and confidence intervals of each coefficient. Typically, a p-value below 0.05 suggests a significant relationship.\\n\\n---\\n\\nStep 4: Model Refinement and Validation\\n- Stepwise Regression: Balance model fit and complexity. Use AIC and BIC as guiding metrics. AIC & BIC Interpretation: Align with study objectives. If predictive accuracy is essential, lean towards AIC; for explanatory power, consider BIC.\\n- Model Diagnostics: Use the Hosmer-Lemeshow Test aiming for a p-value above 0.05.\\n- Residual Analysis: Examine residuals for randomness. Patterns could suggest model inadequacies or omitted variables.\\n- Influential Points: Identify observations with significant influence using DFBETAS and Cook's distance metrics.\\n---\\n\\n# Step 5: Model Interpretation and Predictions\\n\\n- Odds Ratio: Convert logistic regression coefficients to odds ratios, interpreting them within the data's context.\\n- Predictive Accuracy: Review the model's ability to forecast outcomes holistically.\\n- Model Performance Metrics: Evaluate using the ROC Curve, ensuring a balance between sensitivity and specificity.\\n\\n---\\n\\nNow you need to help me plan what's the specific plan of each part of the project. Please don't include any code, just the plan in text. Your output should be this format:\\n\\n---\\n\\n# Step i\\n\\nplan for step i\\n\\n---\\n\\nPlease only output the plan of each step.\\n\\n\"\nPLANNER_PROMPT['Time Series ARIMA'] = \"\\nHere is my project requirement: {project_requirement}\\n\\nHere is my data schema: {data_schema}\\n\\nMy project will have several steps, and it will be a time series.\\n\\nHere is the linear regression project plan if we want to use timeseries arima model to do analysis\\n\\n---\\n\\n# Step 1: Exploratory Analysis\\n\\n- Plot the original time series data of petroleum consumption.\\n- Observe the trends, seasonality, and variance in the data.\\n- Highlight the importance of making the data stationary for time series modeling.\\n- Apply various transformations like log, inverse, square root, inverse square root, and Box-Cox to stabilize the variance.\\n- Determine which transformation makes the data most stationary; in the provided report, the log transformation was found to be effective.\\n\\n\\n---\\n\\n# Step 2: Model Preparation\\n\\n- Analyze the seasonal and trend effects present in the data.\\n- Make the time series stationary by implementing transformations such as lag 1 and lag 12 differencing.\\n- Verify the stationarity of the time series using the Augmented Dickey-Fuller Test.\\n\\n\\n---\\n\\n# Step 3:  Model Selection\\n\\n- Analyze the Auto-Correlation Function (ACF) and Partial Auto-Correlation Function (PACF) plots to deduce potential model parameters.\\n- Based on the observed parameters, propose a set of candidate ARIMA models.\\n- Calculate the Akaike Information Criterion (AIC) for each model.\\n- Select the model with the smallest AIC as the best model for further analysis.\\n\\n\\n---\\n\\n# Step 4:  Model Diagnostic\\n\\n- Evaluate the residuals of the selected model to ensure they appear as white noise.\\n- Validate the normality of residuals using tools like histograms, Q-Q plots, and the Shapiro-Wilks test.\\n- Confirm the independence of the model residuals using tests such as Box-Pierce, Ljung-Box, and McLeod-Li.\\n- Ensure the model is both stationary and invertible by checking its characteristic roots.\\n\\n\\n---\\n\\n#Step 5: Forecasting\\n\\n- Use the finalized ARIMA model to forecast petroleum consumption for the desired future period.\\n- Visualize the forecasts and include a 95% confidence interval to understand the uncertainty associated with predictions.\\n- Compare the forecasted data with the actual data (if available) to gauge the model's accuracy.\\n\\n\\n---\\n\\nNow you need to help me plan what's the specific plan of each part of the project. Please don't include any code, just the plan in text. Your output should be this format:\\n\\n---\\n\\n# Step i\\n\\nplan for step i\\n\\n---\\n\\nPlease only output the plan of each step.\\n\\n\"\nPLANNER_PROMPT['Time Series SARIMA'] = \"\\nHere is my project requirement: {project_requirement}\\n\\nHere is my data schema: {data_schema}\\n\\nMy project will have several steps, and it will be a time series.\\n\\nHere is the linear regression project plan if we want to use timeseries arima model to do analysis\\n\\n---\\n\\n# Step 1: Exploratory Analysis\\n\\n- Plot the original time series data of petroleum consumption.\\n- Observe the trends, seasonality, and variance in the data.\\n- Highlight the importance of making the data stationary for time series modeling.\\n- Apply various transformations like log, inverse, square root, inverse square root, and Box-Cox to stabilize the variance.\\n- Determine which transformation makes the data most stationary; in the provided report, the log transformation was found to be effective.\\n\\n\\n---\\n\\n# Step 2: Model Preparation\\n\\n- Analyze the seasonal and trend effects present in the data.\\n- Make the time series stationary by implementing transformations such as lag 1 and lag 12 differencing.\\n- Verify the stationarity of the time series using the Augmented Dickey-Fuller Test.\\n\\n\\n---\\n\\n# Step 3:  Model Selection\\n\\n- Analyze the Auto-Correlation Function (ACF) and Partial Auto-Correlation Function (PACF) plots to deduce potential model parameters.\\n- Based on the observed parameters, propose a set of candidate ARIMA models.\\n- Calculate the Akaike Information Criterion (AIC) for each model.\\n- Select the model with the smallest AIC as the best model for further analysis.\\n\\n\\n---\\n\\n# Step 4:  Model Diagnostic\\n\\n- Evaluate the residuals of the selected model to ensure they appear as white noise.\\n- Validate the normality of residuals using tools like histograms, Q-Q plots, and the Shapiro-Wilks test.\\n- Confirm the independence of the model residuals using tests such as Box-Pierce, Ljung-Box, and McLeod-Li.\\n- Ensure the model is both stationary and invertible by checking its characteristic roots.\\n\\n\\n---\\n\\n#Step 5: Forecasting\\n\\n- Use the finalized ARIMA model to forecast petroleum consumption for the desired future period.\\n- Visualize the forecasts and include a 95% confidence interval to understand the uncertainty associated with predictions.\\n- Compare the forecasted data with the actual data (if available) to gauge the model's accuracy.\\n\\n\\n---\\n\\nNow you need to help me plan what's the specific plan of each part of the project. Please don't include any code, just the plan in text. Your output should be this format:\\n\\n---\\n\\n# Step i\\n\\nplan for step i\\n\\n---\\n\\nPlease only output the plan of each step.\\n\\n\"\nPLANNER_PROMPT['One-Way ANOVA'] = \"\\nHere is my project requirement: {project_requirement}\\n\\nHere is my data schema:\\n{data_schema}\\n\\nMy project will have several steps.\\n\\nHere is the sample one-way ANOVA project plan\\n\\n---\\n\\n# Step 1\\n\\n[Data Preparation and Exploration]\\n- Inspect the data to ensure it fits the criteria for a One-Way ANOVA, focusing on one categorical independent variable and one continuous dependent variable.\\n- Handle any missing or outlier data points that could affect the ANOVA results, considering methods like imputation or removal.\\n- Perform exploratory data analysis to understand the distribution of the dependent variable within each group defined by the independent variable.\\n\\n---\\n\\n# Step 2\\n\\n[Assumption Verification]\\n- Verify the assumptions of One-Way ANOVA, which are the independence of observations, homogeneity of variances (assessed by Levene's test or similar), and normality within groups (checked by Q-Q plots or normality tests).\\n- Plan remedial actions if any of the assumptions are not met, such as data transformation or the use of a non-parametric equivalent if the normality assumption is violated.\\n\\n---\\n\\n# Step 3\\n\\n[ANOVA Model Fitting]\\n- Detail the process of fitting the ANOVA model, defining the null and alternative hypotheses.\\n- Include steps for calculating the F-statistic and corresponding p-value to assess the main effect of the categorical variable on the dependent variable.\\n- Ensure the documentation of the between-group and within-group variability for a thorough analysis.\\n\\n---\\n\\n# Step 4\\n\\n[Post Hoc Testing and Interpretation]\\n- If the ANOVA indicates significant differences, plan for post hoc testing to determine which specific groups differ from each other.\\n- Choose appropriate post hoc tests (e.g., Tukey's HSD, Bonferroni correction) depending on the data and project requirements.\\n- Interpret the results, providing a clear understanding of the differences between group means and their relevance to the project objectives.\\n\\n---\\n\\nNow you need to help me plan what's the specific plan of each part of the project. Please don't include any code, just the plan in text. Your output should be this format:\\n\\n---\\n\\n# Step i\\n\\nplan for step i\\n\\n---\\n\\nPlease only output the plan of each step.\\n\\n\"\nPLANNER_PROMPT['Two-Way ANOVA'] = \"\\nHere is my project requirement: {project_requirement}\\n\\nHere is my data schema:\\n{data_schema}\\n\\nMy project will have several steps.\\n\\nHere is a sample plan for two-way ANOVA analysis on a sample dataset\\n\\n---\\n\\n# Step 1\\n\\n[Data Preparation and Exploration]\\n- Validate that the dataset contains at least two categorical independent variables (factors) and one continuous dependent variable, suitable for Two-Way ANOVA.\\n- Tackle any missing values or outliers that may influence the analysis, choosing appropriate strategies to manage these data issues.\\n- Conduct exploratory data analysis to discern the distribution of the dependent variable across the levels of each factor and their interaction.\\n\\n---\\n\\n# Step 2\\n\\n[Assumption Verification]\\n- Confirm the assumptions of Two-Way ANOVA, emphasizing the independence of observations, homogeneity of variances (which can be checked by Hartley's test), and the normality of the data within the groups (which can be assessed using Q-Q plots or statistical tests for normality).\\n- Plan for alternative approaches or data transformations if the assumptions are violated, which might include rank transformations or the adoption of a non-parametric approach.\\n\\n---\\n\\n# Step 3\\n\\n[Model Fitting and Interaction Assessment]\\n- Elaborate on the procedure for fitting the Two-Way ANOVA model, including formulating the null hypotheses for main effects and interaction effects.\\n- Describe the process for computing the F-statistics for both the main and interaction effects and the interpretation of the resulting p-values.\\n- Emphasize the need to partition the variability into components attributable to each factor and their interaction.\\n\\n---\\n\\n# Step 4\\n\\n[Post Hoc Analysis and Results Interpretation]\\n- Prepare for post hoc comparisons in case of significant main or interaction effects, selecting suitable multiple comparison procedures that adjust for familywise error rate, such as Tukey's test.\\n- Lay out the steps for interpreting the interaction plots and the main effects to understand the nature of the relationships between the variables.\\n- Contextualize the ANOVA findings within the project's framework, explaining the practical significance of the observed statistical effects.\\n\\n---\\n\\nNow you need to help me plan what's the specific plan of each part of the project. Please don't include any code, just the plan in text. Your output should be this format:\\n\\n---\\n\\n# Step i\\n\\nplan for step i\\n\\n---\\n\\nPlease only output the plan of each step.\\n\\n\"", "hash": "9d1cf0ee55fee061b657dfac03a28f634bac565667505d68fcfd1403d85e679a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_scientist\\data_scientist.py", "code_chunk": "DataScientistAgent.def __init__(self):\n    self.openai_node = OpenAINode()\n    self.data_analysis_node = DataAnalysisNode()\n    self._init_openai_node()", "hash": "59b86315571c700b0f13d641648fa72b7fed967eec503fbf49b983132a012e2d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_scientist\\data_scientist.py", "code_chunk": "DataScientistAgent.def add_data_file(self, file_path: Path):\n    file_name = file_path.name\n    file_type = file_path.suffix[1:]\n    self.data_analysis_node.load_data(input=LoadDataInput(name=file_name, source_type=file_type, source_path=str(file_path)))\n    logging.warning(f'{file_name} loaded as {file_type}.')\n    logging.warning(file_type == 'csv' or file_type == 'json')\n    logging.warning(DATA_FILE_PROMPT.format(file_name=file_name, file_path=file_path, n=5, content=self.get_data_file_summary(file_name, 5)))\n    if file_type == 'csv' or file_type == 'json':\n        self.openai_node.add_system_message(DATA_FILE_PROMPT.format(file_name=file_name, file_path=file_path, n=5, content=self.get_data_file_summary(file_name, 5, 'markdown')))\n        logging.warning(f'openai_history')\n        logging.warning(self.openai_node.history)\n    else:\n        self.openai_node.add_system_message(COMMON_FILE_PROMPT.format(file_name=file_name, file_path=file_path))", "hash": "b4ceff9869aba42fdade8afe0873d7b135d3c8e59e484de2b882069ad076cfd2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_scientist\\data_scientist.py", "code_chunk": "DataScientistAgent.def get_data_file_summary(self, file_name: str, head_n: int=5, output_type: str='html'):\n    if self.data_analysis_node.data.get(file_name) is None:\n        return 'Data file not found.'\n    if isinstance(self.data_analysis_node.data[file_name], pd.DataFrame):\n        if output_type == 'html':\n            return self.data_analysis_node.data[file_name].head(head_n).to_html()\n        elif output_type == 'markdown':\n            return self.data_analysis_node.data[file_name].head(head_n).to_markdown()\n        else:\n            return self.data_analysis_node.data[file_name].head(head_n).to_string()\n    with open(self.data_analysis_node.data[file_name], 'r') as f:\n        content = f.read(300)\n        if f.read(1) != '':\n            content += '...'\n    return content", "hash": "c2165ee0e63d92d40d0d12bcfb9c265f94872218e0d8f5ff1fb4b158f26f408b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_scientist\\data_scientist.py", "code_chunk": "DataScientistAgent.def query(self, query: str) -> str:\n    resp = self.openai_node.chat(input=ChatInput(model='gpt-4', message_text=QUERY_PROMPT.format(query=query), append_history=True))\n    code = resp.message.content\n    if code.startswith('```python'):\n        code = code[10:]\n    if code.endswith('```'):\n        code = code[:-3]\n    return code", "hash": "7c46723392fd680c0f47145ca3603459e03baff1dd242ae9e035e71116a9cdd8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_scientist\\data_scientist.py", "code_chunk": "DataScientistAgent.def _init_openai_node(self):\n    self.openai_node.add_system_message(DS_PROMPT)", "hash": "d019a873bc7eeeee0c61dccfd06b9d41c4b3e52391910a55a18843a82a8e9f7e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_scientist\\data_scientist.py", "code_chunk": "DataScientistAgent.BaseAgent\nconfig: AgentConfig = AgentConfig(**data_scientist_config)", "hash": "e6e888c634efa4d48738176eb9a373275625aac5e7912cc79b5564fb0a4b1ea3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_scientist\\data_scientist.py", "code_chunk": "DataScientistAgent.def __init__(self):\n    self.openai_node = OpenAINode()\n    self.data_analysis_node = DataAnalysisNode()\n    self._init_openai_node()", "hash": "59b86315571c700b0f13d641648fa72b7fed967eec503fbf49b983132a012e2d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_scientist\\data_scientist.py", "code_chunk": "DataScientistAgent.def add_data_file(self, file_path: Path):\n    file_name = file_path.name\n    file_type = file_path.suffix[1:]\n    self.data_analysis_node.load_data(input=LoadDataInput(name=file_name, source_type=file_type, source_path=str(file_path)))\n    logging.warning(f'{file_name} loaded as {file_type}.')\n    logging.warning(file_type == 'csv' or file_type == 'json')\n    logging.warning(DATA_FILE_PROMPT.format(file_name=file_name, file_path=file_path, n=5, content=self.get_data_file_summary(file_name, 5)))\n    if file_type == 'csv' or file_type == 'json':\n        self.openai_node.add_system_message(DATA_FILE_PROMPT.format(file_name=file_name, file_path=file_path, n=5, content=self.get_data_file_summary(file_name, 5, 'markdown')))\n        logging.warning(f'openai_history')\n        logging.warning(self.openai_node.history)\n    else:\n        self.openai_node.add_system_message(COMMON_FILE_PROMPT.format(file_name=file_name, file_path=file_path))", "hash": "b4ceff9869aba42fdade8afe0873d7b135d3c8e59e484de2b882069ad076cfd2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_scientist\\data_scientist.py", "code_chunk": "DataScientistAgent.def get_data_file_summary(self, file_name: str, head_n: int=5, output_type: str='html'):\n    if self.data_analysis_node.data.get(file_name) is None:\n        return 'Data file not found.'\n    if isinstance(self.data_analysis_node.data[file_name], pd.DataFrame):\n        if output_type == 'html':\n            return self.data_analysis_node.data[file_name].head(head_n).to_html()\n        elif output_type == 'markdown':\n            return self.data_analysis_node.data[file_name].head(head_n).to_markdown()\n        else:\n            return self.data_analysis_node.data[file_name].head(head_n).to_string()\n    with open(self.data_analysis_node.data[file_name], 'r') as f:\n        content = f.read(300)\n        if f.read(1) != '':\n            content += '...'\n    return content", "hash": "c2165ee0e63d92d40d0d12bcfb9c265f94872218e0d8f5ff1fb4b158f26f408b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_scientist\\data_scientist.py", "code_chunk": "DataScientistAgent.def query(self, query: str) -> str:\n    resp = self.openai_node.chat(input=ChatInput(model='gpt-4', message_text=QUERY_PROMPT.format(query=query), append_history=True))\n    code = resp.message.content\n    if code.startswith('```python'):\n        code = code[10:]\n    if code.endswith('```'):\n        code = code[:-3]\n    return code", "hash": "7c46723392fd680c0f47145ca3603459e03baff1dd242ae9e035e71116a9cdd8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_scientist\\data_scientist.py", "code_chunk": "DataScientistAgent.def _init_openai_node(self):\n    self.openai_node.add_system_message(DS_PROMPT)", "hash": "d019a873bc7eeeee0c61dccfd06b9d41c4b3e52391910a55a18843a82a8e9f7e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_scientist\\data_scientist.py", "code_chunk": "from pathlib import Path\nimport pandas as pd\nimport logging\nfrom .data_scientist_prompt import *\nfrom ..base_agent import BaseAgent, AgentConfig\nfrom ...nodes import OpenAINode, ChatInput, DataAnalysisNode, LoadDataInput\ndata_scientist_config = {'name': 'data_scientist', 'description': 'A agent for data scientist.'}", "hash": "6d5f1457d427763382b648f3acbad19b39ddc0df91a93f97eb13051fb98040dc"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\data_scientist\\data_scientist_prompt.py", "code_chunk": "DS_PROMPT = '\\nYou are a data scientist working on a series of data files. \\nYou will be asked to write code to process the data in the files and answer questions about the data.\\n\\nYou should:\\n1.  Comprehend the user\\'s requirements carefully & to the letter.\\n2.  When user ask a question, write a python code to answer the query. Your code should output answer to STDOUT. \\n    Your output should only contain the python code content, do not add any other information in your output.\\n    Do not contain quotation marks (\", \"\"\", \\', etc.) at the beginning and the end of the file content.\\n    Do not contain markdown code block syntax (```, ~~~, etc.) at the beginning and the end of the file content.\\n'\nDATA_FILE_PROMPT = '\\nUser add a data file {file_name} at {file_path}.\\nThe header {n} rows of the file (dataframe) is as follow:\\n\\n{content}\\n\\nPlease take care of the data schema and the data type of each column.\\n'\nCOMMON_FILE_PROMPT = '\\nUser add a data file {file_name} at {file_path}.\\n'\nQUERY_PROMPT = '\\nUser ask a query: {query}.\\n\\nPlease write the code to answer the query.\\n\\nPlease write a python code for me. The output should only contain file content.\\n\\n\\n[NOTE]\\n***Your code should output answer to STDOUT. (IMPORTANT: always use python `print` function)***\\nDO NOT CONTAIN QUOTATION MARKS (\", \"\"\", \\', etc.) AT THE BEGINNING AND THE END OF THE FILE CONTENT.\\nYOUR OUTPUT SHOULD JUST USE `\\n` FOR LINE BREAK, DO NOT USE `\\\\n`.\\nDO NOT INCLUDE ANY OTHER INFORMATION EXCEPT FOR THE FILE CONTENT IN YOUR OUTPUT.\\n'", "hash": "e34e276cb8011609598d90616518121cf16d0884d5818dc967d4667e1299b06a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "FileAction.def __str__(self):\n    output = f'\\n# {self.file_path}\\n\\n'\n    if self.content is not None:\n        if self.content.startswith('```'):\n            output += f'\\n{self.content}\\n\\n'\n        else:\n            output += f'\\n```python\\n{self.content}\\n```\\n\\n'\n    else:\n        output += f'\\n**Remove this file.**\\n\\n'\n    return output", "hash": "00500a23886b2ed4eac8d8129d499a21becefcae3afd85e8cebbf2c5f8e57074"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "FileAction.BaseModel\naction: str = Field(description='Plan action.')\nfile_path: str = Field(description='File path for action.')\ncontent: Optional[str] = Field(description='Content for action.')", "hash": "1fca39847778c1755014abef9a77eee6e839b677719dce1fa667e5750b24800a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def __init__(self, repo_path: Path):\n    self.root_path = repo_path\n    self.focus_files = set()\n    self.file_tree_str = self._generate_file_tree_str()\n    self.readme_content = self._load_readme()", "hash": "73437355fc3331079fa225f0950a97d886fd1c3e970416f905e8d73dc1dfa98c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def add_focus_file(self, file_path):\n    \"\"\"\n        Add a file to the interest file set.\n        \"\"\"\n    full_path = self.root_path / file_path\n    if os.path.exists(full_path):\n        if file_path in self.focus_files:\n            logging.warning(f'Try to add existing file {file_path}.')\n        self.focus_files.add(file_path)\n    else:\n        raise FileNotFoundError(f'File {full_path} does not exist.')", "hash": "2bd4b220d99409d8c3986b6f002043d3520afc8a32f2e43ff99100f59a8aa1c1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def remove_focus_file(self, file_path):\n    \"\"\"\n        Remove a file from the interest file set.\n        \"\"\"\n    if file_path in self.focus_files:\n        self.focus_files.remove(file_path)\n    else:\n        logging.warning(f'Try to remove unexisting file {file_path}.')", "hash": "e02c05dc1480c3244931241e832f3afb4b12104c94e26003fb91aac9b475296d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def set_focus_file(self, focus_files: list[str]):\n    \"\"\"\n        Set the focus file.\n        \"\"\"\n    self.focus_files.clear()\n    for file in focus_files:\n        self.add_focus_file(file)", "hash": "bc9bcbf9f3cf51af2d4bdabf683b65a8ef50407ca62556c639a3cd95a45a9f1a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def get_focus_files_content(self, limit_files: int=5):\n    \"\"\"\n        Get the content of the focus files (only output first 5 files).\n        \"\"\"\n    return {file_path: file_content for file_path, file_content in islice(zip(self.focus_files, map(self.get_file_content, self.focus_files)), limit_files)}", "hash": "5e27095c51657a976a49cdd279e649c0e4db586b0ab158e8a9c4d6f85c7c41f2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def get_file_content(self, file_path: str, limit_lines: int=200):\n    \"\"\"\n        Get the content of a file.\n        \"\"\"\n    full_path = self.root_path / file_path\n    if os.path.exists(full_path):\n        with open(full_path, 'r') as f:\n            lines = []\n            line = f.readline()\n            while line:\n                lines.append(line)\n                line = f.readline()\n                if len(lines) > limit_lines:\n                    lines.append('... (too many lines)')\n                    break\n            return '\\n'.join(lines)\n    else:\n        raise FileNotFoundError(f'File {full_path} does not exist.')", "hash": "27145e1fa77159c62f3f69b641152af3dc229ee19fbef1e4d795b3cdfe856138"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def apply_file_actions(self, file_actions: list[FileAction]):\n    \"\"\"\n        Apply the file actions to the files.\n        \"\"\"\n    for file_action in file_actions:\n        match file_action.action:\n            case 'add':\n                self._add_file(file_action.file_path, file_action.content)\n            case 'remove':\n                self._remove_file(file_action.file_path)\n            case 'modify':\n                self._modify_file(file_action.file_path, file_action.content)\n            case _:\n                raise ValueError(f'Unknown action {file_action.action}.')\n    self.file_tree_str = self._generate_file_tree_str()", "hash": "ef3297aaaeea2e8ae575d42b98bcde7f0ecb4084353352d2b17235770a991834"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def _add_file(self, file_path: str, content: str):\n    \"\"\"\n        Add a file to the repo.\n        \"\"\"\n    full_path = self.root_path / file_path\n    if os.path.exists(full_path):\n        raise FileExistsError(f'File {full_path} already exists.')\n    else:\n        with open(full_path, 'w') as f:\n            f.write(content)", "hash": "7ed5f0d7e3155f5eb7587e16a88cc827cccf56694fcd404d038f3b2c8bb54c60"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def _remove_file(self, file_path: str):\n    \"\"\"\n        Remove a file from the repo.\n        \"\"\"\n    full_path = self.root_path / file_path\n    if os.path.exists(full_path):\n        os.remove(full_path)\n    else:\n        raise FileNotFoundError(f'File {full_path} does not exist.')", "hash": "fae8515313638fc4eabce59ce243f5ad36af15db7c50b4dfa79514ae79a15c62"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def _modify_file(self, file_path: str, content: str):\n    \"\"\"\n        Modify a file in the repo.\n        \"\"\"\n    full_path = self.root_path / file_path\n    if os.path.exists(full_path):\n        with open(full_path, 'w') as f:\n            f.write(content)\n    else:\n        raise FileNotFoundError(f'File {full_path} does not exist.')", "hash": "e37639b3fa577335986b9ef08d944874f1b48fedb1cf558ed92b3042e20e15fb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def _generate_file_tree_str(self):\n    space = '    '\n    branch = '\u2502   '\n    tee = '\u251c\u2500\u2500 '\n    last = '\u2514\u2500\u2500 '\n\n    def _tree_iter(dir_path: Path, prefix: str=''):\n        \"\"\"A recursive generator, given a directory Path object\n            will yield a visual tree structure line by line\n            with each line prefixed by the same characters\n            \"\"\"\n        contents = list(dir_path.iterdir())\n        pointers = [tee] * (len(contents) - 1) + [last]\n        for pointer, path in zip(pointers, contents):\n            yield (prefix + pointer + path.name)\n            if path.is_dir():\n                extension = branch if pointer == tee else space\n                yield from _tree_iter(path, prefix=prefix + extension)\n    res = ''\n    for line in _tree_iter(self.root_path):\n        res += line + '\\n'\n    return res", "hash": "54a1b20d8a6f9dc58eb5a6f4ec869209cc2a0579a18c8293a96c78673910cf39"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def _load_readme(self):\n    readme_file_names = ['README.md', 'README', 'README.txt']\n    for readme_file_name in readme_file_names:\n        readme_path = self.root_path / readme_file_name\n        if os.path.exists(readme_path):\n            with open(readme_path, 'r') as f:\n                return f.read()\n    return ''", "hash": "bdbe29c42ec9abc8f3d7cb4115915693a7c0ae4fc68a1d1a634453131def541b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.'\\n    This class is responsible for managing the files of the software engineer.\\n    It will manage all the file from a single git repo.\\n    '\nroot_path: Optional[Path]\nfocus_files: set[str]\nfile_tree_str: str\nreadme_content: str", "hash": "9b7d331ecddc3c8615159dc179125e22a42b7739664b7eb56b4697ddbe9d41e8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def __str__(self):\n    output = f'\\n# {self.file_path}\\n\\n'\n    if self.content is not None:\n        if self.content.startswith('```'):\n            output += f'\\n{self.content}\\n\\n'\n        else:\n            output += f'\\n```python\\n{self.content}\\n```\\n\\n'\n    else:\n        output += f'\\n**Remove this file.**\\n\\n'\n    return output", "hash": "85daa1315b8aa867e77f8e7fee3cff97f73721a02ae5a4b37273a30fabd4ed44"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def __init__(self, repo_path: Path):\n    self.root_path = repo_path\n    self.focus_files = set()\n    self.file_tree_str = self._generate_file_tree_str()\n    self.readme_content = self._load_readme()", "hash": "73437355fc3331079fa225f0950a97d886fd1c3e970416f905e8d73dc1dfa98c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def add_focus_file(self, file_path):\n    \"\"\"\n        Add a file to the interest file set.\n        \"\"\"\n    full_path = self.root_path / file_path\n    if os.path.exists(full_path):\n        if file_path in self.focus_files:\n            logging.warning(f'Try to add existing file {file_path}.')\n        self.focus_files.add(file_path)\n    else:\n        raise FileNotFoundError(f'File {full_path} does not exist.')", "hash": "2bd4b220d99409d8c3986b6f002043d3520afc8a32f2e43ff99100f59a8aa1c1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def remove_focus_file(self, file_path):\n    \"\"\"\n        Remove a file from the interest file set.\n        \"\"\"\n    if file_path in self.focus_files:\n        self.focus_files.remove(file_path)\n    else:\n        logging.warning(f'Try to remove unexisting file {file_path}.')", "hash": "e02c05dc1480c3244931241e832f3afb4b12104c94e26003fb91aac9b475296d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def set_focus_file(self, focus_files: list[str]):\n    \"\"\"\n        Set the focus file.\n        \"\"\"\n    self.focus_files.clear()\n    for file in focus_files:\n        self.add_focus_file(file)", "hash": "bc9bcbf9f3cf51af2d4bdabf683b65a8ef50407ca62556c639a3cd95a45a9f1a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def get_focus_files_content(self, limit_files: int=5):\n    \"\"\"\n        Get the content of the focus files (only output first 5 files).\n        \"\"\"\n    return {file_path: file_content for file_path, file_content in islice(zip(self.focus_files, map(self.get_file_content, self.focus_files)), limit_files)}", "hash": "5e27095c51657a976a49cdd279e649c0e4db586b0ab158e8a9c4d6f85c7c41f2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def get_file_content(self, file_path: str, limit_lines: int=200):\n    \"\"\"\n        Get the content of a file.\n        \"\"\"\n    full_path = self.root_path / file_path\n    if os.path.exists(full_path):\n        with open(full_path, 'r') as f:\n            lines = []\n            line = f.readline()\n            while line:\n                lines.append(line)\n                line = f.readline()\n                if len(lines) > limit_lines:\n                    lines.append('... (too many lines)')\n                    break\n            return '\\n'.join(lines)\n    else:\n        raise FileNotFoundError(f'File {full_path} does not exist.')", "hash": "27145e1fa77159c62f3f69b641152af3dc229ee19fbef1e4d795b3cdfe856138"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def apply_file_actions(self, file_actions: list[FileAction]):\n    \"\"\"\n        Apply the file actions to the files.\n        \"\"\"\n    for file_action in file_actions:\n        match file_action.action:\n            case 'add':\n                self._add_file(file_action.file_path, file_action.content)\n            case 'remove':\n                self._remove_file(file_action.file_path)\n            case 'modify':\n                self._modify_file(file_action.file_path, file_action.content)\n            case _:\n                raise ValueError(f'Unknown action {file_action.action}.')\n    self.file_tree_str = self._generate_file_tree_str()", "hash": "ef3297aaaeea2e8ae575d42b98bcde7f0ecb4084353352d2b17235770a991834"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def _add_file(self, file_path: str, content: str):\n    \"\"\"\n        Add a file to the repo.\n        \"\"\"\n    full_path = self.root_path / file_path\n    if os.path.exists(full_path):\n        raise FileExistsError(f'File {full_path} already exists.')\n    else:\n        with open(full_path, 'w') as f:\n            f.write(content)", "hash": "7ed5f0d7e3155f5eb7587e16a88cc827cccf56694fcd404d038f3b2c8bb54c60"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def _remove_file(self, file_path: str):\n    \"\"\"\n        Remove a file from the repo.\n        \"\"\"\n    full_path = self.root_path / file_path\n    if os.path.exists(full_path):\n        os.remove(full_path)\n    else:\n        raise FileNotFoundError(f'File {full_path} does not exist.')", "hash": "fae8515313638fc4eabce59ce243f5ad36af15db7c50b4dfa79514ae79a15c62"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def _modify_file(self, file_path: str, content: str):\n    \"\"\"\n        Modify a file in the repo.\n        \"\"\"\n    full_path = self.root_path / file_path\n    if os.path.exists(full_path):\n        with open(full_path, 'w') as f:\n            f.write(content)\n    else:\n        raise FileNotFoundError(f'File {full_path} does not exist.')", "hash": "e37639b3fa577335986b9ef08d944874f1b48fedb1cf558ed92b3042e20e15fb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def _generate_file_tree_str(self):\n    space = '    '\n    branch = '\u2502   '\n    tee = '\u251c\u2500\u2500 '\n    last = '\u2514\u2500\u2500 '\n\n    def _tree_iter(dir_path: Path, prefix: str=''):\n        \"\"\"A recursive generator, given a directory Path object\n            will yield a visual tree structure line by line\n            with each line prefixed by the same characters\n            \"\"\"\n        contents = list(dir_path.iterdir())\n        pointers = [tee] * (len(contents) - 1) + [last]\n        for pointer, path in zip(pointers, contents):\n            yield (prefix + pointer + path.name)\n            if path.is_dir():\n                extension = branch if pointer == tee else space\n                yield from _tree_iter(path, prefix=prefix + extension)\n    res = ''\n    for line in _tree_iter(self.root_path):\n        res += line + '\\n'\n    return res", "hash": "54a1b20d8a6f9dc58eb5a6f4ec869209cc2a0579a18c8293a96c78673910cf39"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def _load_readme(self):\n    readme_file_names = ['README.md', 'README', 'README.txt']\n    for readme_file_name in readme_file_names:\n        readme_path = self.root_path / readme_file_name\n        if os.path.exists(readme_path):\n            with open(readme_path, 'r') as f:\n                return f.read()\n    return ''", "hash": "bdbe29c42ec9abc8f3d7cb4115915693a7c0ae4fc68a1d1a634453131def541b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "RepoManager.def _tree_iter(dir_path: Path, prefix: str=''):\n    \"\"\"A recursive generator, given a directory Path object\n            will yield a visual tree structure line by line\n            with each line prefixed by the same characters\n            \"\"\"\n    contents = list(dir_path.iterdir())\n    pointers = [tee] * (len(contents) - 1) + [last]\n    for pointer, path in zip(pointers, contents):\n        yield (prefix + pointer + path.name)\n        if path.is_dir():\n            extension = branch if pointer == tee else space\n            yield from _tree_iter(path, prefix=prefix + extension)", "hash": "306d354ba1dd5a152d9530b9b96943f3f60c132833910980b7f6374f7b9fdfa7"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\repo_manager.py", "code_chunk": "import os\nimport subprocess\nimport logging\nfrom pathlib import Path\nfrom itertools import islice\nfrom typing import Optional\nfrom pydantic import BaseModel, Field\nfrom ...nodes import Document", "hash": "c23b57e5561f25ec964fb3ceec26f614ea85f94d0d76bee8b62256e08a09b122"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "Plan.def to_markdown(self):\n    action_str = self.action\n    match self.action:\n        case 'add':\n            action_str = f'**Add** a new file at {self.file_path}'\n        case 'remove':\n            action_str = f'**Remove** file at {self.file_path}'\n        case 'modify':\n            action_str = f'**Modify** file at {self.file_path}'\n    return f'\\n- {action_str}\\n- {self.description}\\n'", "hash": "8c314f51d94f2434536219d742a43e8280e00d33a35b494f96667e0f00fc75fd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "Plan.def __str__(self):\n    action_str = ''\n    match self.action:\n        case 'add':\n            action_str = f'Add a new file at {self.file_path}'\n        case 'remove':\n            action_str = f'Remove file at {self.file_path}'\n        case 'modify':\n            action_str = f'Modify file at {self.file_path}'\n    return action_str", "hash": "9a95a5bfd8cae8c5b6617b299166fb320a088910c2f1b3007e07801321ddf0ab"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "Plan.BaseModel\naction: str = Field(description='Plan action.')\nfile_path: str = Field(description='File path for action.')\ndescription: str = Field(description='Description for action.')", "hash": "e8fd13129b58b91721488d9021ae36fed6f1a6f4244544f4675e4589096d9f27"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def __init__(self):\n    self.document_loader_node = DocumentLoaderNode()\n    self.feature_description = ''\n    self.plans: list[Plan] = []\n    self.repo_url = ''\n    self.model_name = 'gpt-4-1106-preview'\n    self.git_node = GitRepoNode()\n    self.repo_manager: Optional[RepoManager] = None\n    self.file_actions: list[FileAction] = []\n    self._init_openai_node()", "hash": "7ca0280096c8644d261adb63a8b4bf255b0aff4c00fbfe212ded927a16d56ee2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def set_repo_url(self, repo_url: str):\n    \"\"\"\n        Set repo url.\n        \"\"\"\n    self.repo_url = repo_url\n    repo_path = REPO_PATH / Path(repo_url).name\n    self.git_node.git_clone(input=GitRemoteRepositoryInput(url=repo_url, path=repo_path))\n    self.repo_manager = RepoManager(repo_path)\n    self.openai_node.add_single_message(Message(role='system', content=REPO_STRUCTURE_PROMPT.format(file_tree=self.repo_manager.file_tree_str)))", "hash": "5562e1a214a69c4ae12a9f5f72a42b12c152d41089dfd4d41b5b7038188c0dde"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def set_local_repo(self, repo_name: str):\n    \"\"\"\n        Set local repo path.\n        \"\"\"\n    repo_path = REPO_PATH / repo_name\n    self.repo_manager = RepoManager(repo_path)\n    self.openai_node.add_single_message(Message(role='system', content=REPO_STRUCTURE_PROMPT.format(file_tree=self.repo_manager.file_tree_str)))", "hash": "1dbb06ff24b04511d0cfca5cb79af9ab4a52c1ac932c19526cfd90e8bb696039"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def set_feature_description(self, feature_description: str):\n    \"\"\"\n        Set feature description.\n        \"\"\"\n    self.openai_node.add_single_message(Message(role='system', content=FEATURE_PROMPT.format(feature_description=feature_description)))\n    self.feature_description = feature_description", "hash": "9559c79242af8c7ffc1183b0e9d4bbbeb749b7e883b7e1c6583406437dc2b0b0"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def set_focus_files(self):\n    \"\"\"\n        Set focus files of agent for feature development.\n        \"\"\"\n    resp = self.openai_node.chat(input=ChatInput(model=self.model_name, message_text=FOCUS_FILE_PATH_PROMPT.format(format_example=FOCUS_FILE_PATH_EXAMPLE)))\n    files = LLMOutputParser.parse_output(resp.message.content)['files']\n    for file in files:\n        try:\n            self.repo_manager.add_focus_file(file)\n        except FileNotFoundError:\n            logging.warning(f'File {file} does not exist.')", "hash": "813c7c2cb884c932c952a6a4c5f4725ff04a869f569244c8157b5163f878b3b8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def design_plan(self):\n    \"\"\"\n        Design high level plan for feature development.\n        \"\"\"\n    if len(self.repo_manager.focus_files) == 0:\n        logging.warning('No focus files are set. Please set focus files first.')\n    focus_files_dict = self.repo_manager.get_focus_files_content()\n    focus_files_str = '\\n'.join([f'{file_path}:\\n{file_content}' for file_path, file_content in focus_files_dict.items()])\n    self.openai_node.add_single_message(Message(role='system', content=FOCUS_FILE_PROMPT.format(focus_files=focus_files_str)))\n    resp = self.openai_node.chat(input=ChatInput(model=self.model_name, message_text=PLAN_PROMPT.format(format_example=PLAN_FORMAT_EXAMPLE)))\n    plan = LLMOutputParser.parse_output(resp.message.content)['plan']\n    for action, file_path, description in plan:\n        self.plans.append(Plan(action=action.lower(), file_path=file_path, description=description))", "hash": "50a9258d9a61cded98a1bcc95aeebb7a56ad489e88d467b250e4fc79f172ccec"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def implement(self):\n    \"\"\"\n        Implement plan, generate a list of file actions.\n        \"\"\"\n    for plan in self.plans:\n        match plan.action:\n            case 'add':\n                file_action = self._add_file(plan)\n            case 'remove':\n                file_action = self._remove_file(plan)\n            case 'modify':\n                file_action = self._modify_file(plan)\n            case _:\n                raise ValueError(f'Unknown action {plan.action}.')\n        self.file_actions.append(file_action)\n        yield file_action", "hash": "9d279a73831c179fab51db02fdd63baaaa1a0a61b0e0aa972fbce8c4d3f10424"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def apply_file_action(self):\n    self.repo_manager.apply_file_actions(self.file_actions)\n    self.file_actions = []", "hash": "9b38ce281b9e1c250e418cbabd9ba84b9c2b5a6dc27a1418ea70b299e8292740"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def _add_file(self, plan: Plan):\n    assert plan.action == 'add'\n    resp = self.openai_node.chat(input=ChatInput(model=self.model_name, message_text=ADD_FILE_PROMPT.format(file_path=plan.file_path, action_description=plan.description)))\n    content = resp.message.content\n    while content.startswith('\"') and content.endswith('\"'):\n        content = content[1:-1]\n    return FileAction(action='add', file_path=plan.file_path, content=content)", "hash": "19926b2d229eaed77e39167c84a44c9b4f225ea2b5c7529659e5ebadf869ff09"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def _remove_file(self, plan: Plan):\n    return FileAction(action='remove', file_path=plan.file_path)", "hash": "3e201e03cc4d7faeac0417a8c3fcdbdd1b09f375be8f909279f42cd60dfaaee1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def _modify_file(self, plan: Plan):\n    assert plan.action == 'modify'\n    resp = self.openai_node.chat(input=ChatInput(model=self.model_name, message_text=MODIFY_FILE_PROMPT.format(file_path=plan.file_path, file_content=self.repo_manager.get_file_content(plan.file_path, limit_lines=5000), action_description=plan.description)))\n    content = resp.message.content\n    while content.startswith('\"') and content.endswith('\"'):\n        content = content[1:-1]\n    return FileAction(action='modify', file_path=plan.file_path, content=content)", "hash": "69af18c134dbb055587579f1a4497f30c48fa89e301fb577781a5a9b751ac49c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def _init_openai_node(self):\n    \"\"\"\n        Initialize OpenAI node.\n        Add global system messages.\n        \"\"\"\n    self.openai_node = OpenAINode()\n    self.openai_node.add_single_message(Message(role='system', content=SDE_PROMPT))", "hash": "9c59c955829e5c3b234494476e368ba1e76ba9fff1842ad3277fe0d5f77f4c7f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def add_focus_file(self, file_path):\n    \"\"\"\n        Add file to repo.\n        \"\"\"\n    self.repo_manager.add_focus_file(file_path)", "hash": "0caf61188bd9c144545c57c6ab7a5f8b4a871d1612a592c9ea13a39355c712e4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def remove_focus_file(self, file_path):\n    \"\"\"\n        Remove file from repo.\n        \"\"\"\n    self.repo_manager.remove_focus_file(file_path)", "hash": "81b7c09d941499e7f8f6144dcda74dcdefd567bebca49df5347655eb865d01ee"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def get_focus_files(self):\n    \"\"\"\n        Get focus files.\n        \"\"\"\n    return self.repo_manager.focus_files", "hash": "7ec519924d7ba057b00a9ade8f7bc10bc4cc1f43de90999e1374365ff3d3de0e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def clear_focus_files(self):\n    \"\"\"\n        Clear focus files.\n        \"\"\"\n    self.repo_manager.focus_files = {}", "hash": "18901fdaff50263f624b0e7ec890a6547cc489498bda9a46acb9e2f95df7740a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def add_plan(self, plan: Plan):\n    \"\"\"\n        Add plan to implement plan.\n        \"\"\"\n    self.plans.append(plan)", "hash": "0266aa8c12f35e90877ee6e70e02d748733a3c43d82bba3bafd104ec4018f5a1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def remove_plan(self, plan: Plan):\n    \"\"\"\n        Remove plan from implement plan.\n        \"\"\"\n    self.plans.remove(plan)", "hash": "76d939cd85cdd3b8373533c50c8653d98da54e04ce04c4ab9e7cc67c2e490074"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def get_plan(self):\n    \"\"\"\n        Get feature implemetation plan.\n        \"\"\"\n    return self.plans", "hash": "cf5022af3e85a515c7fb30a36baf86c38bb639a3a9b830918e30980d9db27f7e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def set_plans(self, plans: list[Plan]):\n    \"\"\"\n        Set feature implementation plan.\n        \"\"\"\n    self.plans = plans", "hash": "483de748cab0515090eb4b68bbe9508f2f5e50f201053d2566d1e85de6f1dc0a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def get_file_actions(self):\n    \"\"\"\n        Get file actions.\n        \"\"\"\n    return self.file_actions", "hash": "5ac0a224907f72618fcfad2984d414db3e637f36850e2cd2f58a42d17009801b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.BaseAgent\nconfig: AgentConfig = AgentConfig(**software_engineer_config)", "hash": "cecee9e05bd230f7751a8dfea0db88909b529c7b217b030155db3e2c4b21a9ea"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def to_markdown(self):\n    action_str = self.action\n    match self.action:\n        case 'add':\n            action_str = f'**Add** a new file at {self.file_path}'\n        case 'remove':\n            action_str = f'**Remove** file at {self.file_path}'\n        case 'modify':\n            action_str = f'**Modify** file at {self.file_path}'\n    return f'\\n- {action_str}\\n- {self.description}\\n'", "hash": "ecb7836656f13ea0502d99cf8067c9805a58f5b2cd65110f70e210616186ddd9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def __str__(self):\n    action_str = ''\n    match self.action:\n        case 'add':\n            action_str = f'Add a new file at {self.file_path}'\n        case 'remove':\n            action_str = f'Remove file at {self.file_path}'\n        case 'modify':\n            action_str = f'Modify file at {self.file_path}'\n    return action_str", "hash": "0bb46318547578d6fb659d369a75fae6cd1f6d0428b3fbf3259e204473ecb632"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def __init__(self):\n    self.document_loader_node = DocumentLoaderNode()\n    self.feature_description = ''\n    self.plans: list[Plan] = []\n    self.repo_url = ''\n    self.model_name = 'gpt-4-1106-preview'\n    self.git_node = GitRepoNode()\n    self.repo_manager: Optional[RepoManager] = None\n    self.file_actions: list[FileAction] = []\n    self._init_openai_node()", "hash": "7ca0280096c8644d261adb63a8b4bf255b0aff4c00fbfe212ded927a16d56ee2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def set_repo_url(self, repo_url: str):\n    \"\"\"\n        Set repo url.\n        \"\"\"\n    self.repo_url = repo_url\n    repo_path = REPO_PATH / Path(repo_url).name\n    self.git_node.git_clone(input=GitRemoteRepositoryInput(url=repo_url, path=repo_path))\n    self.repo_manager = RepoManager(repo_path)\n    self.openai_node.add_single_message(Message(role='system', content=REPO_STRUCTURE_PROMPT.format(file_tree=self.repo_manager.file_tree_str)))", "hash": "5562e1a214a69c4ae12a9f5f72a42b12c152d41089dfd4d41b5b7038188c0dde"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def set_local_repo(self, repo_name: str):\n    \"\"\"\n        Set local repo path.\n        \"\"\"\n    repo_path = REPO_PATH / repo_name\n    self.repo_manager = RepoManager(repo_path)\n    self.openai_node.add_single_message(Message(role='system', content=REPO_STRUCTURE_PROMPT.format(file_tree=self.repo_manager.file_tree_str)))", "hash": "1dbb06ff24b04511d0cfca5cb79af9ab4a52c1ac932c19526cfd90e8bb696039"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def set_feature_description(self, feature_description: str):\n    \"\"\"\n        Set feature description.\n        \"\"\"\n    self.openai_node.add_single_message(Message(role='system', content=FEATURE_PROMPT.format(feature_description=feature_description)))\n    self.feature_description = feature_description", "hash": "9559c79242af8c7ffc1183b0e9d4bbbeb749b7e883b7e1c6583406437dc2b0b0"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def set_focus_files(self):\n    \"\"\"\n        Set focus files of agent for feature development.\n        \"\"\"\n    resp = self.openai_node.chat(input=ChatInput(model=self.model_name, message_text=FOCUS_FILE_PATH_PROMPT.format(format_example=FOCUS_FILE_PATH_EXAMPLE)))\n    files = LLMOutputParser.parse_output(resp.message.content)['files']\n    for file in files:\n        try:\n            self.repo_manager.add_focus_file(file)\n        except FileNotFoundError:\n            logging.warning(f'File {file} does not exist.')", "hash": "813c7c2cb884c932c952a6a4c5f4725ff04a869f569244c8157b5163f878b3b8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def design_plan(self):\n    \"\"\"\n        Design high level plan for feature development.\n        \"\"\"\n    if len(self.repo_manager.focus_files) == 0:\n        logging.warning('No focus files are set. Please set focus files first.')\n    focus_files_dict = self.repo_manager.get_focus_files_content()\n    focus_files_str = '\\n'.join([f'{file_path}:\\n{file_content}' for file_path, file_content in focus_files_dict.items()])\n    self.openai_node.add_single_message(Message(role='system', content=FOCUS_FILE_PROMPT.format(focus_files=focus_files_str)))\n    resp = self.openai_node.chat(input=ChatInput(model=self.model_name, message_text=PLAN_PROMPT.format(format_example=PLAN_FORMAT_EXAMPLE)))\n    plan = LLMOutputParser.parse_output(resp.message.content)['plan']\n    for action, file_path, description in plan:\n        self.plans.append(Plan(action=action.lower(), file_path=file_path, description=description))", "hash": "50a9258d9a61cded98a1bcc95aeebb7a56ad489e88d467b250e4fc79f172ccec"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def implement(self):\n    \"\"\"\n        Implement plan, generate a list of file actions.\n        \"\"\"\n    for plan in self.plans:\n        match plan.action:\n            case 'add':\n                file_action = self._add_file(plan)\n            case 'remove':\n                file_action = self._remove_file(plan)\n            case 'modify':\n                file_action = self._modify_file(plan)\n            case _:\n                raise ValueError(f'Unknown action {plan.action}.')\n        self.file_actions.append(file_action)\n        yield file_action", "hash": "9d279a73831c179fab51db02fdd63baaaa1a0a61b0e0aa972fbce8c4d3f10424"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def apply_file_action(self):\n    self.repo_manager.apply_file_actions(self.file_actions)\n    self.file_actions = []", "hash": "9b38ce281b9e1c250e418cbabd9ba84b9c2b5a6dc27a1418ea70b299e8292740"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def _add_file(self, plan: Plan):\n    assert plan.action == 'add'\n    resp = self.openai_node.chat(input=ChatInput(model=self.model_name, message_text=ADD_FILE_PROMPT.format(file_path=plan.file_path, action_description=plan.description)))\n    content = resp.message.content\n    while content.startswith('\"') and content.endswith('\"'):\n        content = content[1:-1]\n    return FileAction(action='add', file_path=plan.file_path, content=content)", "hash": "19926b2d229eaed77e39167c84a44c9b4f225ea2b5c7529659e5ebadf869ff09"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def _remove_file(self, plan: Plan):\n    return FileAction(action='remove', file_path=plan.file_path)", "hash": "3e201e03cc4d7faeac0417a8c3fcdbdd1b09f375be8f909279f42cd60dfaaee1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def _modify_file(self, plan: Plan):\n    assert plan.action == 'modify'\n    resp = self.openai_node.chat(input=ChatInput(model=self.model_name, message_text=MODIFY_FILE_PROMPT.format(file_path=plan.file_path, file_content=self.repo_manager.get_file_content(plan.file_path, limit_lines=5000), action_description=plan.description)))\n    content = resp.message.content\n    while content.startswith('\"') and content.endswith('\"'):\n        content = content[1:-1]\n    return FileAction(action='modify', file_path=plan.file_path, content=content)", "hash": "69af18c134dbb055587579f1a4497f30c48fa89e301fb577781a5a9b751ac49c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def _init_openai_node(self):\n    \"\"\"\n        Initialize OpenAI node.\n        Add global system messages.\n        \"\"\"\n    self.openai_node = OpenAINode()\n    self.openai_node.add_single_message(Message(role='system', content=SDE_PROMPT))", "hash": "9c59c955829e5c3b234494476e368ba1e76ba9fff1842ad3277fe0d5f77f4c7f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def add_focus_file(self, file_path):\n    \"\"\"\n        Add file to repo.\n        \"\"\"\n    self.repo_manager.add_focus_file(file_path)", "hash": "0caf61188bd9c144545c57c6ab7a5f8b4a871d1612a592c9ea13a39355c712e4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def remove_focus_file(self, file_path):\n    \"\"\"\n        Remove file from repo.\n        \"\"\"\n    self.repo_manager.remove_focus_file(file_path)", "hash": "81b7c09d941499e7f8f6144dcda74dcdefd567bebca49df5347655eb865d01ee"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def get_focus_files(self):\n    \"\"\"\n        Get focus files.\n        \"\"\"\n    return self.repo_manager.focus_files", "hash": "7ec519924d7ba057b00a9ade8f7bc10bc4cc1f43de90999e1374365ff3d3de0e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def clear_focus_files(self):\n    \"\"\"\n        Clear focus files.\n        \"\"\"\n    self.repo_manager.focus_files = {}", "hash": "18901fdaff50263f624b0e7ec890a6547cc489498bda9a46acb9e2f95df7740a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def add_plan(self, plan: Plan):\n    \"\"\"\n        Add plan to implement plan.\n        \"\"\"\n    self.plans.append(plan)", "hash": "0266aa8c12f35e90877ee6e70e02d748733a3c43d82bba3bafd104ec4018f5a1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def remove_plan(self, plan: Plan):\n    \"\"\"\n        Remove plan from implement plan.\n        \"\"\"\n    self.plans.remove(plan)", "hash": "76d939cd85cdd3b8373533c50c8653d98da54e04ce04c4ab9e7cc67c2e490074"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def get_plan(self):\n    \"\"\"\n        Get feature implemetation plan.\n        \"\"\"\n    return self.plans", "hash": "cf5022af3e85a515c7fb30a36baf86c38bb639a3a9b830918e30980d9db27f7e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def set_plans(self, plans: list[Plan]):\n    \"\"\"\n        Set feature implementation plan.\n        \"\"\"\n    self.plans = plans", "hash": "483de748cab0515090eb4b68bbe9508f2f5e50f201053d2566d1e85de6f1dc0a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "SoftwareEngineerAgent.def get_file_actions(self):\n    \"\"\"\n        Get file actions.\n        \"\"\"\n    return self.file_actions", "hash": "5ac0a224907f72618fcfad2984d414db3e637f36850e2cd2f58a42d17009801b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer.py", "code_chunk": "import json\nimport logging\nfrom typing import Optional\nfrom pydantic import BaseModel, Field\nfrom pathlib import Path\nfrom ..base_agent import BaseAgent, AgentConfig\nfrom .software_engineer_prompt import *\nfrom .repo_manager import RepoManager, FileAction\nfrom ...nodes import DocumentLoaderNode, OpenAINode, ChatInput, Message, GitRepoNode, GitRemoteRepositoryInput\nfrom ....utils.output_parser import LLMOutputParser\nREPO_PATH = Path('src/data/git')\nsoftware_engineer_config = {'name': 'software_engineer', 'description': 'A agent for software engineer.'}", "hash": "1378cd456ed6a03af6846e8c0eead844c824df56baa40bfb656dac0a2eca2bbc"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\agents\\software_engineer\\software_engineer_prompt.py", "code_chunk": "SDE_PROMPT = '\\nYou are a software engineer working on a project. You are working on a feature implementation task.\\n\\n'\nREPO_STRUCTURE_PROMPT = '\\nThe project has a file tree structure as follows:\\n\\n```text\\n{file_tree}\\n```\\n\\n'\nFEATURE_PROMPT = '\\nNow you are assigned to implement a feature, which is described as follows:\\n\\n{feature_description}\\n\\n'\nFOCUS_FILE_PATH_PROMPT = '\\nNow please provide a list of file paths that you think are relevant to this feature implementation task. \\nIf there are more than 5 relevant files, you should only provide top 5 files.\\n\\nYour output should be a title (`##files`, attention: lower case) and a python code block, which include a list of file paths (you are allow to create new files). The example output is as follows:\\n\\n{format_example}\\n\\n---\\n\\nYOU SHOULD ONLY OUTPUT EXISTING FILE PATHS IN THE REPO.\\nDO NOT INCLUDE ANY OTHER INFORMATION IN YOUR OUTPUT.\\nYOU SHOULD ONLY OUTPUT TOP 5 FILES.\\n'\nFOCUS_FILE_PATH_EXAMPLE = '\\n## files\\n```python\\n[\\n    \"path/to/file1\",\\n    \"path/to/file2\", \\n    \"path/to/file3\",\\n]\\n```\\n'\nFOCUS_FILE_PROMPT = '\\nFocus files is a list of files that you should focus on for this feature implementation task. \\nYou should modify these files (or add new file) to implement the feature.\\nThe list of focus files is as follows:\\n\\n{focus_files}\\n'\nPLAN_PROMPT = \"\\nPlease design a high level plan for this feature implementation task.\\nYour output should be a title (`## plan`, attention: lower case) and python list of modification plans. The example output is as follows:\\n\\n{format_example}\\n\\n---\\n\\nIF YOU THINK YOU DON'T NEED TO MODIFY A SPECIFIC FILE, YOU SHOULDN'T INCLUDE IT IN YOUR OUTPUT.\\nDO NOT INCLUDE ANY OTHER INFORMATION IN YOUR OUTPUT.\\n\"\nPLAN_FORMAT_EXAMPLE = '\\n## plan\\n```python\\n[\\n    (\"add\", \"path/to/file1\", \"the reason why you want to add this file\"),\\n    (\"remove\",\"path/to/file2\", \"the reason why you want to remove this file\"),\\n    (\"modify\", \"path/to/file3\", \"the detailed plan for modification\"),\\n    (\"modify\",\"path/to/file4\", \"the detailed plan for modification\"),\\n]\\n'\nADD_FILE_PROMPT = '\\nThe path of the file to be added is {file_path}.\\n\\nThe detailed description of the file to be added is as follows:\\n\\n{action_description}\\n\\nPlease write the file content for me. The output should only be a python string of file content.\\nDO NOT INCLUDE ANY OTHER INFORMATION EXCEPT THE FILE CONTENT IN YOUR OUTPUT.\\n'\nMODIFY_FILE_PROMPT = '\\nThe path of the file to be modified is {file_path}, and the content of the file is as follows:\\n\\n{file_content}\\n\\nThe detailed description of the file to be modified is as follows:\\n\\n{action_description}\\n\\nPlease write the file content for me. The output should only contain file content.\\n\\n---\\n\\nDO NOT CONTAIN QUOTATION MARKS (\", \"\"\", \\', etc.) AT THE BEGINNING AND THE END OF THE FILE CONTENT.\\nYOUR OUTPUT SHOULD JUST USE `\\n` FOR LINE BREAK, DO NOT USE `\\\\n`.\\nDO NOT INCLUDE ANY OTHER INFORMATION EXCEPT FOR THE FILE CONTENT IN YOUR OUTPUT.\\n'", "hash": "f76e2392739c8767a6d9f5ca42ab9cc13d43d75c7c192794143ed3e4a343a0ed"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.def __init__(self, config, yaml_path: Optional[str]=None):\n    self.config = config\n    YamlPathConfig.assistants_yaml_path = yaml_path if yaml_path else 'assistants.yaml'", "hash": "8ed5fe0a048c9e6930751e0f77cb5d9ae9f22e150015556480da67fa572e6d1a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.def set_assistants_yaml_path(yaml_path: str):\n    if not os.path.isabs(yaml_path):\n        stack = inspect.stack()\n        caller_frame = stack[1]\n        caller_path = caller_frame.filename\n        caller_dir = os.path.dirname(caller_path)\n        full_yaml_path = os.path.join(caller_dir, yaml_path)\n    else:\n        full_yaml_path = yaml_path\n    yaml_dir = os.path.dirname(full_yaml_path)\n    os.makedirs(yaml_dir, exist_ok=True)\n    YamlPathConfig.assistants_yaml_path = full_yaml_path", "hash": "b8c341c4b790d880ac3483486bad396634f4f9155d223f12ebaacc306e9ba6db"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.def save_to_yaml(self):\n    assistants_yaml_path = YamlPathConfig.assistants_yaml_path\n    if not os.path.exists(assistants_yaml_path):\n        with open(assistants_yaml_path, 'w') as file:\n            file.write('')\n    with open(assistants_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    for i, d in enumerate(data):\n        if d['id'] == self.config.id:\n            data[i] = self.config.__dict__\n            break\n    else:\n        data.append(self.config.__dict__)\n    with open(assistants_yaml_path, 'w') as file:\n        yaml.dump(data, file)", "hash": "2818954246c75de3f99d503daaf616822d499f34807c98289231d11f5b396b92"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@property\ndef id(self):\n    return self.config.id", "hash": "f8f23b4df2fdc66bb35fa1918d30ca9816773e69e1f689a96b940f793c63bbe1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@property\ndef name(self):\n    return self.config.name", "hash": "18926f81d1b84edec4ea0a642d4e2fa6fb2b6611ef68ddb0c88df8ca57234cbb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@name.setter\ndef name(self, value):\n    self.config.name = value\n    self.save_to_yaml()", "hash": "191b7296e404613ff59bf6915b8a70b5a7833d7894757ce81e9dd87c6d56e38d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@property\ndef instructions(self):\n    return self.config.instructions", "hash": "f0c94984b7db8088d918fcd38d9ab7493527535101af9d150a87c960f2386675"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@instructions.setter\ndef instructions(self, value):\n    self.config.instructions = value", "hash": "d5cca20e8ab18957c2bc11cfe9aa249993ea976caafd3df30dcbeb58d831efee"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@property\ndef description(self):\n    return self.config.description", "hash": "f3207a8fb3672ea1422456dac281434e67634dcf219e5aa9d685daa24d6701c1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@description.setter\ndef description(self, value):\n    self.config.description = value", "hash": "a38b74af64e01aabac3c5cdc72ce38e2312bea7f2f3a82bfbacef8937afd96fb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@property\ndef tools(self):\n    return self.config.tools", "hash": "b1aa7f5fcb674a754bd39e4b71eb62f3ef7cafc5c4357f060d3594fca60a7b69"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@tools.setter\ndef tools(self, value):\n    self.config.tools = value\n    self.save_to_yaml()", "hash": "e06b7174f5927472e880e5af1d1b90581a8d4b156e7c63695b4f10f2b902121c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@property\ndef model(self):\n    return self.config.model", "hash": "33a16f6166a968f07327da4558129f56108240d78e47f65a0d330b190193f22d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@model.setter\ndef model(self, value):\n    self.config.model = value\n    self.save_to_yaml()", "hash": "727188bdb16ef416c72ea5ad1f59c261f7687a14f0ba2ff8237d843ed4c86ad1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.def get_tools_type_list(self):\n    return [tool['type'] for tool in self.config.tools]", "hash": "8b57071b27f6fdf0f8c2633078207e0c3fd4aef8d835ef5291ccaf3f2ecd26dc"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@staticmethod\ndef create(name: str=None, instructions: str=None, tools: list[dict]=[{'type': ''}], model: str='gpt-4', description: str=None, file_ids: list=None) -> 'Assistants':\n    config = AssistantConfig(id=str(uuid.uuid4()), created_at=int(time.time()), name=name, description=description, instructions=instructions, tools=tools, model=model, file_ids=file_ids if file_ids is not None else [])\n    assistant = Assistants(config, YamlPathConfig.assistants_yaml_path)\n    assistant.save_to_yaml()\n    return assistant", "hash": "03b47ef045cfc06d1b2755ddf98811ab09606316f1fa894c60961f70c1f8b452"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@staticmethod\ndef get_all_assistants() -> List[Dict[str, Any]]:\n    \"\"\"\n        \u8bfb\u53d6 YAML \u6587\u4ef6\u5e76\u8fd4\u56de\u6240\u6709 assistants \u7684\u4fe1\u606f\u5217\u8868\u3002\n        \"\"\"\n    if YamlPathConfig.assistants_yaml_path:\n        if not os.path.isfile(YamlPathConfig.assistants_yaml_path):\n            with open(YamlPathConfig.assistants_yaml_path, 'w') as file:\n                yaml.dump([], file)\n    else:\n        raise FileNotFoundError('The threads YAML file path is not set.')\n    with open(YamlPathConfig.assistants_yaml_path, 'r') as file:\n        assistants_data = yaml.safe_load(file) or []\n    assistants_list = []\n    for item in assistants_data:\n        config = AssistantConfig(**item)\n        assistants_list.append(config)\n    return assistants_list", "hash": "86d673cdb5d818391b6573b9e548d40cd2dc1996242d11c7df810ade09c3a261"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@classmethod\ndef from_id(cls, id: str) -> 'Assistants':\n    with open(YamlPathConfig.assistants_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    for d in data:\n        if d['id'] == id:\n            config = AssistantConfig(**d)\n            return cls(config, YamlPathConfig.assistants_yaml_path)\n    raise ValueError(f'No assistant with id {id} found in YAML file.')", "hash": "eef3c7ec9785901b1e107b14fbad265037514706f061313f7cda11f13527f113"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@classmethod\ndef delete_by_id(cls, id: str):\n    with open(YamlPathConfig.assistants_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    for i, d in enumerate(data):\n        if d['id'] == id:\n            del data[i]\n            break\n    else:\n        raise ValueError(f'No assistant with id {id} found in YAML file.')\n    with open(YamlPathConfig.assistants_yaml_path, 'w') as file:\n        yaml.dump(data, file)", "hash": "f8ae9278bb172b08843b8ec8f6a6fafbf33a020127525642871c8881aeb038fd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.", "hash": "9fc874182b8807683935e36b792fbc8a5e98a3e4edd375ddfa9377d7c16d2c75"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.def __init__(self, config, yaml_path: Optional[str]=None):\n    self.config = config\n    YamlPathConfig.assistants_yaml_path = yaml_path if yaml_path else 'assistants.yaml'", "hash": "8ed5fe0a048c9e6930751e0f77cb5d9ae9f22e150015556480da67fa572e6d1a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.def set_assistants_yaml_path(yaml_path: str):\n    if not os.path.isabs(yaml_path):\n        stack = inspect.stack()\n        caller_frame = stack[1]\n        caller_path = caller_frame.filename\n        caller_dir = os.path.dirname(caller_path)\n        full_yaml_path = os.path.join(caller_dir, yaml_path)\n    else:\n        full_yaml_path = yaml_path\n    yaml_dir = os.path.dirname(full_yaml_path)\n    os.makedirs(yaml_dir, exist_ok=True)\n    YamlPathConfig.assistants_yaml_path = full_yaml_path", "hash": "b8c341c4b790d880ac3483486bad396634f4f9155d223f12ebaacc306e9ba6db"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.def save_to_yaml(self):\n    assistants_yaml_path = YamlPathConfig.assistants_yaml_path\n    if not os.path.exists(assistants_yaml_path):\n        with open(assistants_yaml_path, 'w') as file:\n            file.write('')\n    with open(assistants_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    for i, d in enumerate(data):\n        if d['id'] == self.config.id:\n            data[i] = self.config.__dict__\n            break\n    else:\n        data.append(self.config.__dict__)\n    with open(assistants_yaml_path, 'w') as file:\n        yaml.dump(data, file)", "hash": "2818954246c75de3f99d503daaf616822d499f34807c98289231d11f5b396b92"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@property\ndef id(self):\n    return self.config.id", "hash": "f8f23b4df2fdc66bb35fa1918d30ca9816773e69e1f689a96b940f793c63bbe1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@property\ndef name(self):\n    return self.config.name", "hash": "18926f81d1b84edec4ea0a642d4e2fa6fb2b6611ef68ddb0c88df8ca57234cbb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@name.setter\ndef name(self, value):\n    self.config.name = value\n    self.save_to_yaml()", "hash": "191b7296e404613ff59bf6915b8a70b5a7833d7894757ce81e9dd87c6d56e38d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@property\ndef instructions(self):\n    return self.config.instructions", "hash": "f0c94984b7db8088d918fcd38d9ab7493527535101af9d150a87c960f2386675"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@instructions.setter\ndef instructions(self, value):\n    self.config.instructions = value", "hash": "d5cca20e8ab18957c2bc11cfe9aa249993ea976caafd3df30dcbeb58d831efee"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@property\ndef description(self):\n    return self.config.description", "hash": "f3207a8fb3672ea1422456dac281434e67634dcf219e5aa9d685daa24d6701c1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@description.setter\ndef description(self, value):\n    self.config.description = value", "hash": "a38b74af64e01aabac3c5cdc72ce38e2312bea7f2f3a82bfbacef8937afd96fb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@property\ndef tools(self):\n    return self.config.tools", "hash": "b1aa7f5fcb674a754bd39e4b71eb62f3ef7cafc5c4357f060d3594fca60a7b69"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@tools.setter\ndef tools(self, value):\n    self.config.tools = value\n    self.save_to_yaml()", "hash": "e06b7174f5927472e880e5af1d1b90581a8d4b156e7c63695b4f10f2b902121c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@property\ndef model(self):\n    return self.config.model", "hash": "33a16f6166a968f07327da4558129f56108240d78e47f65a0d330b190193f22d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@model.setter\ndef model(self, value):\n    self.config.model = value\n    self.save_to_yaml()", "hash": "727188bdb16ef416c72ea5ad1f59c261f7687a14f0ba2ff8237d843ed4c86ad1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.def get_tools_type_list(self):\n    return [tool['type'] for tool in self.config.tools]", "hash": "8b57071b27f6fdf0f8c2633078207e0c3fd4aef8d835ef5291ccaf3f2ecd26dc"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@staticmethod\ndef create(name: str=None, instructions: str=None, tools: list[dict]=[{'type': ''}], model: str='gpt-4', description: str=None, file_ids: list=None) -> 'Assistants':\n    config = AssistantConfig(id=str(uuid.uuid4()), created_at=int(time.time()), name=name, description=description, instructions=instructions, tools=tools, model=model, file_ids=file_ids if file_ids is not None else [])\n    assistant = Assistants(config, YamlPathConfig.assistants_yaml_path)\n    assistant.save_to_yaml()\n    return assistant", "hash": "03b47ef045cfc06d1b2755ddf98811ab09606316f1fa894c60961f70c1f8b452"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@staticmethod\ndef get_all_assistants() -> List[Dict[str, Any]]:\n    \"\"\"\n        \u8bfb\u53d6 YAML \u6587\u4ef6\u5e76\u8fd4\u56de\u6240\u6709 assistants \u7684\u4fe1\u606f\u5217\u8868\u3002\n        \"\"\"\n    if YamlPathConfig.assistants_yaml_path:\n        if not os.path.isfile(YamlPathConfig.assistants_yaml_path):\n            with open(YamlPathConfig.assistants_yaml_path, 'w') as file:\n                yaml.dump([], file)\n    else:\n        raise FileNotFoundError('The threads YAML file path is not set.')\n    with open(YamlPathConfig.assistants_yaml_path, 'r') as file:\n        assistants_data = yaml.safe_load(file) or []\n    assistants_list = []\n    for item in assistants_data:\n        config = AssistantConfig(**item)\n        assistants_list.append(config)\n    return assistants_list", "hash": "86d673cdb5d818391b6573b9e548d40cd2dc1996242d11c7df810ade09c3a261"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@classmethod\ndef from_id(cls, id: str) -> 'Assistants':\n    with open(YamlPathConfig.assistants_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    for d in data:\n        if d['id'] == id:\n            config = AssistantConfig(**d)\n            return cls(config, YamlPathConfig.assistants_yaml_path)\n    raise ValueError(f'No assistant with id {id} found in YAML file.')", "hash": "eef3c7ec9785901b1e107b14fbad265037514706f061313f7cda11f13527f113"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "Assistants.@classmethod\ndef delete_by_id(cls, id: str):\n    with open(YamlPathConfig.assistants_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    for i, d in enumerate(data):\n        if d['id'] == id:\n            del data[i]\n            break\n    else:\n        raise ValueError(f'No assistant with id {id} found in YAML file.')\n    with open(YamlPathConfig.assistants_yaml_path, 'w') as file:\n        yaml.dump(data, file)", "hash": "f8ae9278bb172b08843b8ec8f6a6fafbf33a020127525642871c8881aeb038fd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\assistant.py", "code_chunk": "import uuid\nimport time\nimport os\nimport yaml\nfrom typing import Optional\nimport inspect\nfrom .config import *\nfrom typing import Dict, Any", "hash": "41cae9f65eedbd41a3fadb1ebc7f3a1192621e9553c320bd805f988d8a625140"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "def extract_bracket_content(s: str) -> list:\n    content = re.findall('\\\\[(.*?)\\\\]', s)\n    content = [c.replace(\"'\", '') for c in content]\n    content = filter(lambda x: x != '', content)\n    ret = []\n    for item in content:\n        if ',' in item:\n            ret.extend(item.split(','))\n        else:\n            ret.append(item)\n    return ret", "hash": "d4c876e5a89b97c9d8fe205bd3ab0117926247d5ab16b4043bccc2c9e6e687ba"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "AsyncThreads.def __init__(self, config: ThreadsConfig, threads_yaml_path: Optional[str]=None):\n    self._config = config\n    self.current_tool = None\n    YamlPathConfig.threads_yaml_path = threads_yaml_path if threads_yaml_path else 'threads.yaml'", "hash": "4f8025de44815d9b1af5e267af22f7ca7121ee011fa9a20ef4996f7c12c1eeb4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "AsyncThreads.@property\ndef config(self):\n    return self._config", "hash": "7159553aa1845606ad03f4bd623c782a191d7a7bccc96d5c8143510fec753da1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "AsyncThreads.@property\ndef id(self):\n    return self._config.id", "hash": "1b565d9be482421511eff2fd76841d756789022aa90dcbb40d03e21e5da9b83b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "AsyncThreads.def set_threads_yaml_path(yaml_path: str):\n    if not os.path.isabs(yaml_path):\n        stack = inspect.stack()\n        caller_frame = stack[1]\n        caller_path = caller_frame.filename\n        caller_dir = os.path.dirname(caller_path)\n        full_yaml_path = os.path.join(caller_dir, yaml_path)\n    else:\n        full_yaml_path = yaml_path\n    yaml_dir = os.path.dirname(full_yaml_path)\n    os.makedirs(yaml_dir, exist_ok=True)\n    YamlPathConfig.threads_yaml_path = full_yaml_path", "hash": "cb2199bf76c8312374246eb31507ef34e4702857d48e60ebc2e3057f22133c53"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "AsyncThreads.@staticmethod\ndef create(yaml_file_path: str) -> 'AsyncThreads':\n    config = ThreadsConfig(id=str(uuid.uuid4()), object='AsyncThreads', created_at=int(time.time()), message_history=[], metadata={})\n    threads = AsyncThreads(config, YamlPathConfig.threads_yaml_path)\n    threads.save_to_yaml()\n    return threads", "hash": "9a5a6e66a0398f25f80703d2048d3553eb714c942668e4404a89fd3e5322103b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "AsyncThreads.@classmethod\ndef from_id(cls, id: str) -> 'AsyncThreads':\n    with open(YamlPathConfig.threads_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    for d in data:\n        if d['id'] == id:\n            config = ThreadsConfig.from_dict(d)\n            return cls(config, YamlPathConfig.threads_yaml_path)\n    raise ValueError(f'No threads with id {id} found in YAML file.')", "hash": "43d78cb0268f047ad0469029bdd9ac6308fa5d40ee05f5c85de63c9e2e9fb99d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "AsyncThreads.@staticmethod\ndef get_all_threads() -> List[Dict[str, Any]]:\n    \"\"\"\n        \u8bfb\u53d6 YAML \u6587\u4ef6\u5e76\u8fd4\u56de\u6240\u6709 threads \u7684\u4fe1\u606f\u5217\u8868\u3002\n        \"\"\"\n    if YamlPathConfig.threads_yaml_path:\n        if not os.path.isfile(YamlPathConfig.threads_yaml_path):\n            with open(YamlPathConfig.threads_yaml_path, 'w') as file:\n                yaml.dump([], file)\n    else:\n        raise FileNotFoundError('The threads YAML file path is not set.')\n    with open(YamlPathConfig.threads_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    threads_list = []\n    for item in data:\n        config = ThreadsConfig.from_dict(item)\n        threads_list.append(config)\n    return threads_list", "hash": "61c847d0eec438db9ad8c5840013adcb8faff3cda411c51fd63eb9a72031d438"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "AsyncThreads.current_tool: Tool\nchat_node: OpenAINode\nasync def save_to_yaml(self):\n    threads_yaml_path = YamlPathConfig.threads_yaml_path\n    if not os.path.exists(threads_yaml_path):\n        with open(threads_yaml_path, 'w') as file:\n            file.write('')\n    with open(threads_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    for i, d in enumerate(data):\n        if d['id'] == self.config.id:\n            data[i] = self.config.to_dict()\n            break\n    else:\n        data.append(self.config.to_dict())\n    with open(threads_yaml_path, 'w') as file:\n        yaml.dump(data, file)\nasync def run(self, assistant_id: str, input_text: str, **kwargs):\n    try:\n        assistant = Assistants.from_id(assistant_id)\n        tools_list = assistant.get_tools_type_list()\n        tools = Tools()\n        tools_summary = tools.get_tools_list_summary(tools_list)\n        if self.current_tool is None or self.current_tool.has_done():\n            chosen_tools = await self._choose_tools(tools_summary, input_text)\n            if len(chosen_tools) == 0:\n                logging.warn('No tool is recommended.')\n                self.current_tool = None\n                res_message = self._chat(input_text, assistant)\n            else:\n                tool_name = chosen_tools[0]\n                self.current_tool = tools.get_tool(tool_name)\n        if self.current_tool is not None and self.current_tool.need_llm_generate_parameters():\n            parameters = self._generate_parameters(self.current_tool, input_text)\n        else:\n            parameters = kwargs\n            parameters['input_text'] = input_text\n        if self.current_tool is not None:\n            res_message = self.current_tool.call(**parameters)\n        if self.current_tool is not None and self.current_tool.need_llm_generate_response():\n            res_message = self._generate_response(self.current_tool, input_text, parameters, res_message, assistant)\n        if isinstance(res_message, dict) and 'assistant' in res_message:\n            assistant_message_str = res_message['assistant']['message']\n            if res_message['type'] == 'success':\n                self._config.message_history.append([{'user': input_text}, {'assistant': assistant_message_str}])\n                self._config.assistant_id = assistant_id\n                await self.save_to_yaml()\n            res_message['content']['tool'] = self.current_tool.config.name\n            return res_message\n        else:\n            assistant_message_str = str(res_message)\n            self._config.message_history.append([{'user': input_text}, {'assistant': assistant_message_str}])\n            self._config.assistant_id = assistant_id\n            await self.save_to_yaml()\n            return {'type': 'success', 'content': {'tool': self.current_tool.config.name}, 'next_stages_info': {}, 'assistant': {'message': assistant_message_str}}\n    except Exception as e:\n        logging.error(f'An error occurred: {e}')\n        return {'type': 'error', 'content': {'message': str(e)}, 'next_stages_info': {}, 'assistant': {'message': ''}}\nasync def _chat(self, prompt: str, assistant: Assistants, system_message: Optional[str]=None) -> str:\n    response_node = AsyncOpenAINode()\n    description = assistant.description\n    instructions = assistant.instructions\n    system_prompt = f\"You're an assistant. That's your description.\\n{description}\\nPlease follow these instructions:\\n{instructions}\\n \"\n    response_node.add_system_message(system_prompt)\n    if system_message:\n        response_node.add_system_message(system_message)\n    if self._config.message_history:\n        for record in self._config.message_history:\n            user_message = record[0]\n            assistant_message = record[1]\n            response_node.add_content(user_message['user'])\n            response_node.add_role('user')\n            response_node.add_content(str(assistant_message['assistant']))\n            response_node.add_role('assistant')\n    message_config = Message(role='user', content=prompt)\n    chat_config = ChatWithMessageInput(message=message_config, model='gpt-4-1106-preview', append_history=False, use_streaming=False)\n    response = await response_node.chat_with_message(chat_config)\n    response = response.message.content\n    return response\nasync def _choose_tools(self, tools_summary: dict, input_text: str, instruct: bool=False) -> list[str]:\n    tools_node = AsyncOpenAINode()\n    if instruct:\n        tools_choose_prompt = TOOLS_CHOOSE_PROMPT + TOOLS_CHOOSE_EXAMPLE_PROMPT + TOOLS_CHOOSE_HINT + f'\\nInput:\\ntools_summary: {tools_summary}\\ninput_text: {input_text}\\nDispose:'\n        chat_config = OldCompleteInput(model='gpt-3.5-turbo-instruct', prompt=tools_choose_prompt, use_streaming=False)\n        response = await tools_node.use_old_openai_with_prompt(chat_config)\n        response = response.text\n    else:\n        tools_node.add_system_message(TOOLS_CHOOSE_PROMPT + TOOLS_CHOOSE_EXAMPLE_PROMPT + TOOLS_CHOOSE_HINT)\n        tools_choose_prompt = f'\\n    Input:\\n    tools_summary: {tools_summary}\\n    input_text: {input_text}\\n    Dispose:\\n    '\n        message_config = Message(role='user', content=tools_choose_prompt)\n        chat_config = ChatWithMessageInput(message=message_config, model='gpt-4-1106-preview', append_history=False, use_streaming=False)\n        response = await tools_node.chat_with_message(chat_config)\n        response = response.message.content\n    match = re.search('\\\\{.*\\\\}', response, re.DOTALL)\n    if match:\n        dict_str = match.group()\n        response = json.loads(dict_str)\n    else:\n        response = json.loads(response)\n    tools_list = response['tool']['name']\n    return tools_list\nasync def _generate_parameters(self, target_tool: Tool, input_text: str, instruct: bool=False) -> dict:\n    tools_node = AsyncOpenAINode()\n    if instruct:\n        parameters_generate_prompt = PARAMETERS_GENERATE_PROMPT + PARAMETERS_GENERATE_EXAMPLE_PROMPT + PARAMETERS_GENERATE_HINT + f'\\n    Input:\\n    tools_name: {target_tool.config.name}\\n    tools_summary: {target_tool.config.summary}\\n    input_text: {input_text}\\n    tool_input_schema: {[parameter.json() for parameter in target_tool.config.parameters]}\\n    '\n        chat_config = OldCompleteInput(model='gpt-3.5-turbo-instruct', prompt=parameters_generate_prompt, use_streaming=False)\n        max_attempts = 5\n        attempts = 0\n        while attempts < max_attempts:\n            try:\n                response = await tools_node.use_old_openai_with_prompt(chat_config)\n                response = response.text\n                parameters = json.loads(response)\n                break\n            except json.JSONDecodeError:\n                attempts += 1\n                continue\n    else:\n        tools_node.add_system_message(PARAMETERS_GENERATE_PROMPT + PARAMETERS_GENERATE_EXAMPLE_PROMPT + PARAMETERS_GENERATE_HINT)\n        parameters_generate_prompt = f'\\n    Input:\\n    tools_name: {target_tool.config.name}\\n    tools_summary: {target_tool.config.summary}\\n    input_text: {input_text}\\n    tool_input_schema: {[parameter.json() for parameter in target_tool.config.parameters]}\\n    '\n        message_config = Message(role='user', content=parameters_generate_prompt)\n        chat_config = ChatWithMessageInput(message=message_config, model='gpt-4-1106-preview', append_history=False, use_streaming=False)\n        max_attempts = 5\n        attempts = 0\n        while attempts < max_attempts:\n            try:\n                response = await tools_node.chat_with_message(chat_config)\n                response = response.message.content\n                parameters = json.loads(response)\n                break\n            except json.JSONDecodeError:\n                attempts += 1\n                continue\n    return parameters\nasync def _generate_response(self, target_tool: Tool, input_text: str, tool_input: dict[str, any], tool_result: dict[str, any], assistant: Assistants) -> str:\n    system_message = RESPONSE_GENERATE_PROMPT + RESPONSE_GENERATE_EXAMPLE_PROMPT + RESPONSE_GENERATE_HINT\n    response_generate_prompt = f'\\nInput:\\ninput_text: {input_text}\\nchosen_tool_info: {target_tool.config.json()}\\ntool_input: {tool_input}\\ntool_result: {tool_result}\\n'\n    return await self._chat(response_generate_prompt, assistant, system_message)", "hash": "f08c5fd83754dfcf84e640c5172ef06634c9c9ef533ab4e204adbecfeb3629f2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "AsyncThreads.def __init__(self, config: ThreadsConfig, threads_yaml_path: Optional[str]=None):\n    self._config = config\n    self.current_tool = None\n    YamlPathConfig.threads_yaml_path = threads_yaml_path if threads_yaml_path else 'threads.yaml'", "hash": "4f8025de44815d9b1af5e267af22f7ca7121ee011fa9a20ef4996f7c12c1eeb4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "AsyncThreads.@property\ndef config(self):\n    return self._config", "hash": "7159553aa1845606ad03f4bd623c782a191d7a7bccc96d5c8143510fec753da1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "AsyncThreads.@property\ndef id(self):\n    return self._config.id", "hash": "1b565d9be482421511eff2fd76841d756789022aa90dcbb40d03e21e5da9b83b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "AsyncThreads.def set_threads_yaml_path(yaml_path: str):\n    if not os.path.isabs(yaml_path):\n        stack = inspect.stack()\n        caller_frame = stack[1]\n        caller_path = caller_frame.filename\n        caller_dir = os.path.dirname(caller_path)\n        full_yaml_path = os.path.join(caller_dir, yaml_path)\n    else:\n        full_yaml_path = yaml_path\n    yaml_dir = os.path.dirname(full_yaml_path)\n    os.makedirs(yaml_dir, exist_ok=True)\n    YamlPathConfig.threads_yaml_path = full_yaml_path", "hash": "cb2199bf76c8312374246eb31507ef34e4702857d48e60ebc2e3057f22133c53"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "AsyncThreads.@staticmethod\ndef create(yaml_file_path: str) -> 'AsyncThreads':\n    config = ThreadsConfig(id=str(uuid.uuid4()), object='AsyncThreads', created_at=int(time.time()), message_history=[], metadata={})\n    threads = AsyncThreads(config, YamlPathConfig.threads_yaml_path)\n    threads.save_to_yaml()\n    return threads", "hash": "9a5a6e66a0398f25f80703d2048d3553eb714c942668e4404a89fd3e5322103b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "AsyncThreads.@classmethod\ndef from_id(cls, id: str) -> 'AsyncThreads':\n    with open(YamlPathConfig.threads_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    for d in data:\n        if d['id'] == id:\n            config = ThreadsConfig.from_dict(d)\n            return cls(config, YamlPathConfig.threads_yaml_path)\n    raise ValueError(f'No threads with id {id} found in YAML file.')", "hash": "43d78cb0268f047ad0469029bdd9ac6308fa5d40ee05f5c85de63c9e2e9fb99d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "AsyncThreads.@staticmethod\ndef get_all_threads() -> List[Dict[str, Any]]:\n    \"\"\"\n        \u8bfb\u53d6 YAML \u6587\u4ef6\u5e76\u8fd4\u56de\u6240\u6709 threads \u7684\u4fe1\u606f\u5217\u8868\u3002\n        \"\"\"\n    if YamlPathConfig.threads_yaml_path:\n        if not os.path.isfile(YamlPathConfig.threads_yaml_path):\n            with open(YamlPathConfig.threads_yaml_path, 'w') as file:\n                yaml.dump([], file)\n    else:\n        raise FileNotFoundError('The threads YAML file path is not set.')\n    with open(YamlPathConfig.threads_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    threads_list = []\n    for item in data:\n        config = ThreadsConfig.from_dict(item)\n        threads_list.append(config)\n    return threads_list", "hash": "61c847d0eec438db9ad8c5840013adcb8faff3cda411c51fd63eb9a72031d438"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\async_threads.py", "code_chunk": "import uuid\nfrom typing import Any, List, Optional, Dict\nfrom .assistant import Assistants\nfrom ..nodes.openai.openai import OpenAINode, AsyncOpenAINode\nfrom ..nodes.openai.openai_model import *\nfrom .tools.tools import Tools, Tool\nfrom .config import *\nimport time\nimport yaml\nimport os\nimport re\nimport logging\nimport json\nimport inspect\nfrom .prompt.few_shot_cot_tools_choose_prompt import *\nfrom .prompt.parameters_generate_prompt import *\nfrom .prompt.response_generate_prompt import *", "hash": "8e86867f7b29ee7600dba90403d5e92ceae6e3b43dd6342eec51e6de86e44bdb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\config.py", "code_chunk": "MessageRecord.BaseModel\nrole: str = Field(description='\u89d2\u8272')\ncontent: str = Field(description='\u5185\u5bb9')", "hash": "980be36b57d4cda3e1f5697646a424f88b867240719f6f6d8324cf0ed6339ecc"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\config.py", "code_chunk": "YamlPathConfig.threads_yaml_path = 'threads.yaml'\nassistants_yaml_path = 'assistants.yaml'\ntools_yaml_path = 'tools.yaml'", "hash": "7a02ce0fe5161c3fdde40a17e87121a6fa3250df2f46acd0120dadd5a379e503"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\config.py", "code_chunk": "AssistantConfig.BaseModel\nid: str = Field(description='\u52a9\u624b ID')\nobject: str = Field(default='assistant', description='\u5bf9\u8c61\u7c7b\u578b')\ncreated_at: int = Field(description='\u521b\u5efa\u65f6\u95f4')\nname: str = Field(description='\u52a9\u624b\u540d\u79f0')\ndescription: Optional[str] = Field(default=None, description='\u52a9\u624b\u63cf\u8ff0')\nmodel: str = Field(description='\u6a21\u578b')\ninstructions: str = Field(description='\u6307\u4ee4')\ntools: list[dict] = Field(description='\u5de5\u5177')\nfile_ids: list[str] = Field(default=[], description='\u6587\u4ef6 ID')\nmetadata: dict = Field(default={}, description='\u5143\u6570\u636e')", "hash": "7240447548bb2976e50d514a221288f719440368b7991b3b4e3313324b4df477"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\config.py", "code_chunk": "ThreadsConfig.def to_dict(self):\n    data = self.__dict__.copy()\n    data['message_history'] = list(data['message_history'])\n    return data", "hash": "f90f8a84c97ca2f3c5d50c9a49ec53dd2b4d3f073f93a14f81cf1e0c8e4f9beb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\config.py", "code_chunk": "ThreadsConfig.@classmethod\ndef from_dict(cls, data):\n    history = data.get('message_history', [])\n    if len(history) > 10:\n        history = history[-10:]\n    data['message_history'] = deque(history, maxlen=10)\n    return cls(**data)", "hash": "7a6552f15d527b3cd74c8e6ae1f40f10666ddee22ec849ad29d82a65f4302de4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\config.py", "code_chunk": "ThreadsConfig.BaseModel\nid: str = Field(description='\u7ebf\u7a0b ID')\nobject: str = Field(default='thread', description='\u5bf9\u8c61\u7c7b\u578b')\ncreated_at: int = Field(description='\u521b\u5efa\u65f6\u95f4')\nassistant_id: Optional[str] = Field(description='\u52a9\u624b ID')\nmessage_history: deque[List[dict]] = Field(deque(maxlen=10), description='\u6d88\u606f')\nmetadata: dict = Field(default={}, description='\u5143\u6570\u636e')", "hash": "628695769b1aafac34d938848f33c21ceb9b0f55c716c39133ef61acc495d5ac"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\config.py", "code_chunk": "ThreadsConfig.def to_dict(self):\n    data = self.__dict__.copy()\n    data['message_history'] = list(data['message_history'])\n    return data", "hash": "f90f8a84c97ca2f3c5d50c9a49ec53dd2b4d3f073f93a14f81cf1e0c8e4f9beb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\config.py", "code_chunk": "ThreadsConfig.@classmethod\ndef from_dict(cls, data):\n    history = data.get('message_history', [])\n    if len(history) > 10:\n        history = history[-10:]\n    data['message_history'] = deque(history, maxlen=10)\n    return cls(**data)", "hash": "7a6552f15d527b3cd74c8e6ae1f40f10666ddee22ec849ad29d82a65f4302de4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\config.py", "code_chunk": "from collections import deque\nfrom typing import List, Optional\nfrom pydantic import BaseModel, Field", "hash": "54ae3730a6d00fa3a5b8caced7a96a284821d1adc4169dd9d6fb68ad83117985"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "def extract_bracket_content(s: str) -> list:\n    content = re.findall('\\\\[(.*?)\\\\]', s)\n    content = [c.replace(\"'\", '') for c in content]\n    content = filter(lambda x: x != '', content)\n    ret = []\n    for item in content:\n        if ',' in item:\n            ret.extend(item.split(','))\n        else:\n            ret.append(item)\n    return ret", "hash": "2b88c67c2a0d6dbcdb0c4856a8f466d2c711f9525823223572f18933500dce22"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def __init__(self, config: ThreadsConfig, threads_yaml_path: Optional[str]=None):\n    self._config = config\n    self.current_tool = None\n    YamlPathConfig.threads_yaml_path = threads_yaml_path if threads_yaml_path else 'threads.yaml'", "hash": "5edfdf6ca3fe9749f46c0657c011d590d666b64c44144125bfe085ac53bb498b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.@property\ndef config(self):\n    return self._config", "hash": "9ed87345e9fbcdea8853d0993fd8f57d2b0553056893ec539344352fc5b16c87"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.@property\ndef id(self):\n    return self._config.id", "hash": "7b3384d7468f9fec8f83c58ef830b1adaa950781c0a98274ac77c0539bb25412"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def set_threads_yaml_path(yaml_path: str):\n    if not os.path.isabs(yaml_path):\n        stack = inspect.stack()\n        caller_frame = stack[1]\n        caller_path = caller_frame.filename\n        caller_dir = os.path.dirname(caller_path)\n        full_yaml_path = os.path.join(caller_dir, yaml_path)\n    else:\n        full_yaml_path = yaml_path\n    yaml_dir = os.path.dirname(full_yaml_path)\n    os.makedirs(yaml_dir, exist_ok=True)\n    YamlPathConfig.threads_yaml_path = full_yaml_path", "hash": "76a1b4bf5599c34e1222b2246c7ef731da3b2050b39b8e300b6fa700d41c0555"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def save_to_yaml(self):\n    threads_yaml_path = YamlPathConfig.threads_yaml_path\n    if not os.path.exists(threads_yaml_path):\n        with open(threads_yaml_path, 'w') as file:\n            file.write('')\n    with open(threads_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    for i, d in enumerate(data):\n        if d['id'] == self.config.id:\n            data[i] = self.config.to_dict()\n            break\n    else:\n        data.append(self.config.to_dict())\n    with open(threads_yaml_path, 'w') as file:\n        yaml.dump(data, file)", "hash": "caecf8cbe9a867a50e6114c014f0b2dbfa9f363bf1212105ae4e0463443a32ed"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.@staticmethod\ndef create() -> 'Threads':\n    config = ThreadsConfig(id=str(uuid.uuid4()), object='thread', created_at=int(time.time()), message_history=[], metadata={})\n    threads = Threads(config, YamlPathConfig.threads_yaml_path)\n    threads.save_to_yaml()\n    return threads", "hash": "6b38aa467e075f690fd98a8dd92da09e9c9d6462b48ef08df186e4ad28d96d00"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.@classmethod\ndef from_id(cls, id: str) -> 'Threads':\n    with open(YamlPathConfig.threads_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    for d in data:\n        if d['id'] == id:\n            config = ThreadsConfig.from_dict(d)\n            return cls(config, YamlPathConfig.threads_yaml_path)\n    raise ValueError(f'No threads with id {id} found in YAML file.')", "hash": "6e073190f077d9e8c75297a4d37edd9787af691be9491b331d94f397e627a556"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.@staticmethod\ndef get_all_threads() -> List[Dict[str, Any]]:\n    \"\"\"\n        \u8bfb\u53d6 YAML \u6587\u4ef6\u5e76\u8fd4\u56de\u6240\u6709 threads \u7684\u4fe1\u606f\u5217\u8868\u3002\n        \"\"\"\n    if YamlPathConfig.threads_yaml_path:\n        if not os.path.isfile(YamlPathConfig.threads_yaml_path):\n            with open(YamlPathConfig.threads_yaml_path, 'w') as file:\n                yaml.dump([], file)\n    else:\n        raise FileNotFoundError('The threads YAML file path is not set.')\n    with open(YamlPathConfig.threads_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    threads_list = []\n    for item in data:\n        config = ThreadsConfig.from_dict(item)\n        threads_list.append(config)\n    return threads_list", "hash": "d217146f2e7fcbdf47c5688e1a99e98f1bf41b845c500ef76817bf62f843d2ee"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def run(self, assistant_id: str, input_text: str, **kwargs):\n    try:\n        assistant = Assistants.from_id(assistant_id)\n        tools_list = assistant.get_tools_type_list()\n        tools = Tools()\n        tools_summary = tools.get_tools_list_summary(tools_list)\n        if self.current_tool is None or self.current_tool.has_done():\n            chosen_tools = self._choose_tools(tools_summary, input_text)\n            if len(chosen_tools) == 0:\n                logging.warn('No tool is recommended.')\n                self.current_tool = None\n                res_message = self._chat(input_text, assistant)\n            else:\n                tool_name = chosen_tools[0]\n                self.current_tool = tools.get_tool(tool_name)\n        if self.current_tool is not None and self.current_tool.need_llm_generate_parameters():\n            parameters = self._generate_parameters(self.current_tool, input_text)\n        else:\n            parameters = kwargs\n            parameters['input_text'] = input_text\n        if self.current_tool is not None:\n            res_message = self.current_tool.call(**parameters)\n            tool_tmp_message = str(res_message)\n        if self.current_tool is not None and self.current_tool.need_llm_generate_response():\n            res_message = self._generate_response(self.current_tool, input_text, parameters, tool_tmp_message, assistant)\n        if isinstance(res_message, dict) and 'assistant' in res_message:\n            res_message['content']['tool'] = self.current_tool.config.name\n            res_message['content']['tool_type'] = self.current_tool.tool_type\n            res_message['content']['tool_response'] = tool_tmp_message\n            if res_message['type'] == 'success':\n                self._config.message_history.append([{'user': input_text}, {'assistant': res_message}])\n                self._config.assistant_id = assistant_id\n                self.save_to_yaml()\n            return res_message\n        else:\n            assistant_message_str = str(res_message)\n            result_dict = {'type': 'success', 'content': {'tool': self.current_tool.config.name if self.current_tool else '', 'tool_type': self.current_tool.tool_type if self.current_tool else '', 'tool_response': tool_tmp_message if self.current_tool else ''}, 'next_stages_info': {}, 'assistant': {'message': assistant_message_str}}\n            self._config.message_history.append([{'user': input_text}, {'assistant': result_dict}])\n            self._config.assistant_id = assistant_id\n            self.save_to_yaml()\n            return result_dict\n    except Exception as e:\n        logging.error(f'An error occurred: {e}')\n        return {'type': 'error', 'content': {'message': str(e)}, 'next_stages_info': {}, 'assistant': {'message': ''}}", "hash": "120460f12f42d60037903f8d19104c7faec879b33cf27b08a82184c38423a991"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def _chat(self, prompt: str, assistant: Assistants, system_message: Optional[str]=None) -> str:\n    response_node = OpenAINode()\n    description = assistant.description\n    instructions = assistant.instructions\n    system_prompt = f\"You're an assistant. That's your description.\\n{description}\\nPlease follow these instructions:\\n{instructions}\\n \"\n    response_node.add_system_message(system_prompt)\n    if system_message:\n        response_node.add_system_message(system_message)\n    if self._config.message_history:\n        for record in self._config.message_history:\n            user_message = record[0]\n            assistant_message = record[1]\n            response_node.add_content(user_message['user'])\n            response_node.add_role('user')\n            response_node.add_content(str(assistant_message['assistant']))\n            response_node.add_role('assistant')\n    message_config = Message(role='user', content=prompt)\n    chat_config = ChatWithMessageInput(message=message_config, model='gpt-4-1106-preview', append_history=False, use_streaming=False)\n    response = response_node.chat_with_message(chat_config).message.content\n    return response", "hash": "e4aa71feed55548dd8e0649544811c675398b8024c6f6aa677b3927c0249b308"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def _choose_tools(self, tools_summary: dict, input_text: str, instruct: bool=False) -> list[str]:\n    tools_node = OpenAINode()\n    if instruct:\n        tools_choose_prompt = TOOLS_CHOOSE_PROMPT + TOOLS_CHOOSE_EXAMPLE_PROMPT + TOOLS_CHOOSE_HINT + f'\\nInput:\\ntools_summary: {tools_summary}\\ninput_text: {input_text}\\nDispose:'\n        chat_config = OldCompleteInput(model='gpt-3.5-turbo-instruct', prompt=tools_choose_prompt, use_streaming=False)\n        response = tools_node.use_old_openai_with_prompt(chat_config).text\n    else:\n        tools_node.add_system_message(TOOLS_CHOOSE_PROMPT + TOOLS_CHOOSE_EXAMPLE_PROMPT + TOOLS_CHOOSE_HINT)\n        tools_choose_prompt = f'\\n    Input:\\n    tools_summary: {tools_summary}\\n    input_text: {input_text}\\n    Dispose:\\n    '\n        message_config = Message(role='user', content=tools_choose_prompt)\n        chat_config = ChatWithMessageInput(message=message_config, model='gpt-4-1106-preview', append_history=False, use_streaming=False)\n        response = tools_node.chat_with_message(chat_config).message.content\n    match = re.search('\\\\{.*\\\\}', response, re.DOTALL)\n    if match:\n        dict_str = match.group()\n        response = json.loads(dict_str)\n    else:\n        response = json.loads(response)\n    tools_list = response['tool']['name']\n    return tools_list", "hash": "9b20b7234fa20676ed44a34404cd87d27967ffd3dd6d7d752fa90a9db64f5c14"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def _generate_parameters(self, target_tool: Tool, input_text: str, instruct: bool=False) -> dict:\n    tools_node = OpenAINode()\n    if instruct:\n        parameters_generate_prompt = PARAMETERS_GENERATE_PROMPT + PARAMETERS_GENERATE_EXAMPLE_PROMPT + PARAMETERS_GENERATE_HINT + f'\\n    Input:\\n    tools_name: {target_tool.config.name}\\n    tools_summary: {target_tool.config.summary}\\n    input_text: {input_text}\\n    tool_input_schema: {[parameter.json() for parameter in target_tool.config.parameters]}\\n    '\n        chat_config = OldCompleteInput(model='gpt-3.5-turbo-instruct', prompt=parameters_generate_prompt, use_streaming=False)\n        max_attempts = 5\n        attempts = 0\n        while attempts < max_attempts:\n            try:\n                response = tools_node.use_old_openai_with_prompt(chat_config).text\n                parameters = json.loads(response)\n                break\n            except json.JSONDecodeError:\n                attempts += 1\n                continue\n    else:\n        tools_node.add_system_message(PARAMETERS_GENERATE_PROMPT + PARAMETERS_GENERATE_EXAMPLE_PROMPT + PARAMETERS_GENERATE_HINT)\n        parameters_generate_prompt = f'\\n    Input:\\n    tools_name: {target_tool.config.name}\\n    tools_summary: {target_tool.config.summary}\\n    input_text: {input_text}\\n    tool_input_schema: {[parameter.json() for parameter in target_tool.config.parameters]}\\n    '\n        message_config = Message(role='user', content=parameters_generate_prompt)\n        chat_config = ChatWithMessageInput(message=message_config, model='gpt-4-1106-preview', append_history=False, use_streaming=False)\n        max_attempts = 5\n        attempts = 0\n        while attempts < max_attempts:\n            try:\n                response = tools_node.chat_with_message(chat_config).message.content\n                parameters = json.loads(response)\n                break\n            except json.JSONDecodeError:\n                attempts += 1\n                continue\n    return parameters", "hash": "711082d4f23ddc82bd97e38d79cdb3e4e66aaa5e86344cdaaf05d92ebda53125"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def _generate_response(self, target_tool: Tool, input_text: str, tool_input: dict[str, any], tool_result: dict[str, any], assistant: Assistants) -> str:\n    system_message = RESPONSE_GENERATE_PROMPT + RESPONSE_GENERATE_EXAMPLE_PROMPT + RESPONSE_GENERATE_HINT\n    response_generate_prompt = f'\\nInput:\\ninput_text: {input_text}\\nchosen_tool_info: {target_tool.config.json()}\\ntool_input: {tool_input}\\ntool_result: {tool_result}\\n'\n    return self._chat(response_generate_prompt, assistant, system_message)", "hash": "bc781ebf7198bb91f821718405b849eb06d780bd15a562951053ac09fbc58cf3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.current_tool: Tool\nchat_node: OpenAINode", "hash": "1c1feb4e43f177b3ddb31891efa194a46f874e70fc2828c64a9f9e99b2031d1e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def __init__(self, config: ThreadsConfig, threads_yaml_path: Optional[str]=None):\n    self._config = config\n    self.current_tool = None\n    YamlPathConfig.threads_yaml_path = threads_yaml_path if threads_yaml_path else 'threads.yaml'", "hash": "5edfdf6ca3fe9749f46c0657c011d590d666b64c44144125bfe085ac53bb498b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.@property\ndef config(self):\n    return self._config", "hash": "9ed87345e9fbcdea8853d0993fd8f57d2b0553056893ec539344352fc5b16c87"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.@property\ndef id(self):\n    return self._config.id", "hash": "7b3384d7468f9fec8f83c58ef830b1adaa950781c0a98274ac77c0539bb25412"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def set_threads_yaml_path(yaml_path: str):\n    if not os.path.isabs(yaml_path):\n        stack = inspect.stack()\n        caller_frame = stack[1]\n        caller_path = caller_frame.filename\n        caller_dir = os.path.dirname(caller_path)\n        full_yaml_path = os.path.join(caller_dir, yaml_path)\n    else:\n        full_yaml_path = yaml_path\n    yaml_dir = os.path.dirname(full_yaml_path)\n    os.makedirs(yaml_dir, exist_ok=True)\n    YamlPathConfig.threads_yaml_path = full_yaml_path", "hash": "76a1b4bf5599c34e1222b2246c7ef731da3b2050b39b8e300b6fa700d41c0555"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def save_to_yaml(self):\n    threads_yaml_path = YamlPathConfig.threads_yaml_path\n    if not os.path.exists(threads_yaml_path):\n        with open(threads_yaml_path, 'w') as file:\n            file.write('')\n    with open(threads_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    for i, d in enumerate(data):\n        if d['id'] == self.config.id:\n            data[i] = self.config.to_dict()\n            break\n    else:\n        data.append(self.config.to_dict())\n    with open(threads_yaml_path, 'w') as file:\n        yaml.dump(data, file)", "hash": "caecf8cbe9a867a50e6114c014f0b2dbfa9f363bf1212105ae4e0463443a32ed"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.@staticmethod\ndef create() -> 'Threads':\n    config = ThreadsConfig(id=str(uuid.uuid4()), object='thread', created_at=int(time.time()), message_history=[], metadata={})\n    threads = Threads(config, YamlPathConfig.threads_yaml_path)\n    threads.save_to_yaml()\n    return threads", "hash": "6b38aa467e075f690fd98a8dd92da09e9c9d6462b48ef08df186e4ad28d96d00"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.@classmethod\ndef from_id(cls, id: str) -> 'Threads':\n    with open(YamlPathConfig.threads_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    for d in data:\n        if d['id'] == id:\n            config = ThreadsConfig.from_dict(d)\n            return cls(config, YamlPathConfig.threads_yaml_path)\n    raise ValueError(f'No threads with id {id} found in YAML file.')", "hash": "6e073190f077d9e8c75297a4d37edd9787af691be9491b331d94f397e627a556"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.@staticmethod\ndef get_all_threads() -> List[Dict[str, Any]]:\n    \"\"\"\n        \u8bfb\u53d6 YAML \u6587\u4ef6\u5e76\u8fd4\u56de\u6240\u6709 threads \u7684\u4fe1\u606f\u5217\u8868\u3002\n        \"\"\"\n    if YamlPathConfig.threads_yaml_path:\n        if not os.path.isfile(YamlPathConfig.threads_yaml_path):\n            with open(YamlPathConfig.threads_yaml_path, 'w') as file:\n                yaml.dump([], file)\n    else:\n        raise FileNotFoundError('The threads YAML file path is not set.')\n    with open(YamlPathConfig.threads_yaml_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    threads_list = []\n    for item in data:\n        config = ThreadsConfig.from_dict(item)\n        threads_list.append(config)\n    return threads_list", "hash": "d217146f2e7fcbdf47c5688e1a99e98f1bf41b845c500ef76817bf62f843d2ee"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def run(self, assistant_id: str, input_text: str, **kwargs):\n    try:\n        assistant = Assistants.from_id(assistant_id)\n        tools_list = assistant.get_tools_type_list()\n        tools = Tools()\n        tools_summary = tools.get_tools_list_summary(tools_list)\n        if self.current_tool is None or self.current_tool.has_done():\n            chosen_tools = self._choose_tools(tools_summary, input_text)\n            if len(chosen_tools) == 0:\n                logging.warn('No tool is recommended.')\n                self.current_tool = None\n                res_message = self._chat(input_text, assistant)\n            else:\n                tool_name = chosen_tools[0]\n                self.current_tool = tools.get_tool(tool_name)\n        if self.current_tool is not None and self.current_tool.need_llm_generate_parameters():\n            parameters = self._generate_parameters(self.current_tool, input_text)\n        else:\n            parameters = kwargs\n            parameters['input_text'] = input_text\n        if self.current_tool is not None:\n            res_message = self.current_tool.call(**parameters)\n            tool_tmp_message = str(res_message)\n        if self.current_tool is not None and self.current_tool.need_llm_generate_response():\n            res_message = self._generate_response(self.current_tool, input_text, parameters, tool_tmp_message, assistant)\n        if isinstance(res_message, dict) and 'assistant' in res_message:\n            res_message['content']['tool'] = self.current_tool.config.name\n            res_message['content']['tool_type'] = self.current_tool.tool_type\n            res_message['content']['tool_response'] = tool_tmp_message\n            if res_message['type'] == 'success':\n                self._config.message_history.append([{'user': input_text}, {'assistant': res_message}])\n                self._config.assistant_id = assistant_id\n                self.save_to_yaml()\n            return res_message\n        else:\n            assistant_message_str = str(res_message)\n            result_dict = {'type': 'success', 'content': {'tool': self.current_tool.config.name if self.current_tool else '', 'tool_type': self.current_tool.tool_type if self.current_tool else '', 'tool_response': tool_tmp_message if self.current_tool else ''}, 'next_stages_info': {}, 'assistant': {'message': assistant_message_str}}\n            self._config.message_history.append([{'user': input_text}, {'assistant': result_dict}])\n            self._config.assistant_id = assistant_id\n            self.save_to_yaml()\n            return result_dict\n    except Exception as e:\n        logging.error(f'An error occurred: {e}')\n        return {'type': 'error', 'content': {'message': str(e)}, 'next_stages_info': {}, 'assistant': {'message': ''}}", "hash": "120460f12f42d60037903f8d19104c7faec879b33cf27b08a82184c38423a991"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def _chat(self, prompt: str, assistant: Assistants, system_message: Optional[str]=None) -> str:\n    response_node = OpenAINode()\n    description = assistant.description\n    instructions = assistant.instructions\n    system_prompt = f\"You're an assistant. That's your description.\\n{description}\\nPlease follow these instructions:\\n{instructions}\\n \"\n    response_node.add_system_message(system_prompt)\n    if system_message:\n        response_node.add_system_message(system_message)\n    if self._config.message_history:\n        for record in self._config.message_history:\n            user_message = record[0]\n            assistant_message = record[1]\n            response_node.add_content(user_message['user'])\n            response_node.add_role('user')\n            response_node.add_content(str(assistant_message['assistant']))\n            response_node.add_role('assistant')\n    message_config = Message(role='user', content=prompt)\n    chat_config = ChatWithMessageInput(message=message_config, model='gpt-4-1106-preview', append_history=False, use_streaming=False)\n    response = response_node.chat_with_message(chat_config).message.content\n    return response", "hash": "e4aa71feed55548dd8e0649544811c675398b8024c6f6aa677b3927c0249b308"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def _choose_tools(self, tools_summary: dict, input_text: str, instruct: bool=False) -> list[str]:\n    tools_node = OpenAINode()\n    if instruct:\n        tools_choose_prompt = TOOLS_CHOOSE_PROMPT + TOOLS_CHOOSE_EXAMPLE_PROMPT + TOOLS_CHOOSE_HINT + f'\\nInput:\\ntools_summary: {tools_summary}\\ninput_text: {input_text}\\nDispose:'\n        chat_config = OldCompleteInput(model='gpt-3.5-turbo-instruct', prompt=tools_choose_prompt, use_streaming=False)\n        response = tools_node.use_old_openai_with_prompt(chat_config).text\n    else:\n        tools_node.add_system_message(TOOLS_CHOOSE_PROMPT + TOOLS_CHOOSE_EXAMPLE_PROMPT + TOOLS_CHOOSE_HINT)\n        tools_choose_prompt = f'\\n    Input:\\n    tools_summary: {tools_summary}\\n    input_text: {input_text}\\n    Dispose:\\n    '\n        message_config = Message(role='user', content=tools_choose_prompt)\n        chat_config = ChatWithMessageInput(message=message_config, model='gpt-4-1106-preview', append_history=False, use_streaming=False)\n        response = tools_node.chat_with_message(chat_config).message.content\n    match = re.search('\\\\{.*\\\\}', response, re.DOTALL)\n    if match:\n        dict_str = match.group()\n        response = json.loads(dict_str)\n    else:\n        response = json.loads(response)\n    tools_list = response['tool']['name']\n    return tools_list", "hash": "9b20b7234fa20676ed44a34404cd87d27967ffd3dd6d7d752fa90a9db64f5c14"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def _generate_parameters(self, target_tool: Tool, input_text: str, instruct: bool=False) -> dict:\n    tools_node = OpenAINode()\n    if instruct:\n        parameters_generate_prompt = PARAMETERS_GENERATE_PROMPT + PARAMETERS_GENERATE_EXAMPLE_PROMPT + PARAMETERS_GENERATE_HINT + f'\\n    Input:\\n    tools_name: {target_tool.config.name}\\n    tools_summary: {target_tool.config.summary}\\n    input_text: {input_text}\\n    tool_input_schema: {[parameter.json() for parameter in target_tool.config.parameters]}\\n    '\n        chat_config = OldCompleteInput(model='gpt-3.5-turbo-instruct', prompt=parameters_generate_prompt, use_streaming=False)\n        max_attempts = 5\n        attempts = 0\n        while attempts < max_attempts:\n            try:\n                response = tools_node.use_old_openai_with_prompt(chat_config).text\n                parameters = json.loads(response)\n                break\n            except json.JSONDecodeError:\n                attempts += 1\n                continue\n    else:\n        tools_node.add_system_message(PARAMETERS_GENERATE_PROMPT + PARAMETERS_GENERATE_EXAMPLE_PROMPT + PARAMETERS_GENERATE_HINT)\n        parameters_generate_prompt = f'\\n    Input:\\n    tools_name: {target_tool.config.name}\\n    tools_summary: {target_tool.config.summary}\\n    input_text: {input_text}\\n    tool_input_schema: {[parameter.json() for parameter in target_tool.config.parameters]}\\n    '\n        message_config = Message(role='user', content=parameters_generate_prompt)\n        chat_config = ChatWithMessageInput(message=message_config, model='gpt-4-1106-preview', append_history=False, use_streaming=False)\n        max_attempts = 5\n        attempts = 0\n        while attempts < max_attempts:\n            try:\n                response = tools_node.chat_with_message(chat_config).message.content\n                parameters = json.loads(response)\n                break\n            except json.JSONDecodeError:\n                attempts += 1\n                continue\n    return parameters", "hash": "711082d4f23ddc82bd97e38d79cdb3e4e66aaa5e86344cdaaf05d92ebda53125"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "Threads.def _generate_response(self, target_tool: Tool, input_text: str, tool_input: dict[str, any], tool_result: dict[str, any], assistant: Assistants) -> str:\n    system_message = RESPONSE_GENERATE_PROMPT + RESPONSE_GENERATE_EXAMPLE_PROMPT + RESPONSE_GENERATE_HINT\n    response_generate_prompt = f'\\nInput:\\ninput_text: {input_text}\\nchosen_tool_info: {target_tool.config.json()}\\ntool_input: {tool_input}\\ntool_result: {tool_result}\\n'\n    return self._chat(response_generate_prompt, assistant, system_message)", "hash": "bc781ebf7198bb91f821718405b849eb06d780bd15a562951053ac09fbc58cf3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\threads.py", "code_chunk": "import uuid\nfrom typing import Any, List, Optional, Dict\nfrom .assistant import Assistants\nfrom ..nodes.openai.openai import OpenAINode\nfrom ..nodes.openai.openai_model import *\nfrom .tools.tools import Tools, Tool\nfrom .config import *\nimport time\nimport yaml\nimport os\nimport re\nimport logging\nimport json\nimport inspect\nfrom .prompt.few_shot_cot_tools_choose_prompt import *\nfrom .prompt.parameters_generate_prompt import *\nfrom .prompt.response_generate_prompt import *", "hash": "6af75e75aac88adf8636de189173d9fef2fe6d13a79e3801e86872f911b2937d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\__init__.py", "code_chunk": "from .assistant import Assistants\nfrom .threads import Threads\nfrom .tools.tools import Tools", "hash": "575b60c087781c5744c191ed9a0e7727bb944facc543eb94792d46a805226e9f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\prompt\\few_shot_cot_tools_choose_prompt.py", "code_chunk": "TOOLS_CHOOSE_PROMPT = \"\\nAs a tool selector, you'll provide users with suggestions on tool selection. Depending on the provided tool summary (tools_summary) and user input (input_text), you'll need to follow these steps:\\n\\n1. Read and understand the tool summary (tools_summary):\\n   - Understand the features, suitcases, and limitations of each tool.\\n\\n2. Analyze User Input (input_text):\\n   - Understand the user's needs or problems.\\n   - Identify keywords or phrases to determine which tool best suits the user's needs.\\n\\n3. Decision-making logic:\\n   - Recommend a tool if the user's needs correspond to the tool's functionality.\\n   - If the user's needs are not suitable for any tool, or if the information is not sufficient to make a judgment, no tool is recommended.\\n\\n4. Output:\\n   - If a tool is recommended, output the tool name (toolname).\\n   - If no tool is recommended, the output is empty.\\n\\nNote that recommendations for tool selection should be based on the user's needs and refer to the tool summary provided. Follow the steps above and make sure to provide accurate tool selection suggestions in the output.\\n\"\nTOOLS_CHOOSE_EXAMPLE_PROMPT = '\\nHere is some examples about tools choosing:\\n\\nInput:\\ntools_summary: {\\n  \"ToolA\": \"For text analysis and data extraction\",\\n  \"ToolB\": \"For image processing and editing\",\\n  ToolC: For audio editing and processing\\n}\\ninput_text: \"I need to analyze a piece of text to extract key information.\"\\n\\nDispose:\\n- Analyze the input_text and identify the requirements as \"text analytics and data extraction\".\\n- Depending on the tools_summary, ToolA matches this requirement.\\n\\nOutput:\\n{\\n    \"thoughts\": {\\n        \"text\": \"\u7528\u6237\u9700\u8981\u5206\u6790\u4e00\u6bb5\u6587\u5b57\u5e76\u63d0\u53d6\u5173\u952e\u4fe1\u606f\u3002\",\\n        \"reasoning\": \"\u6839\u636e\u5de5\u5177\u6982\u8981\uff0cToolA\u4e13\u7528\u4e8e\u6587\u672c\u5206\u6790\u548c\u6570\u636e\u63d0\u53d6\uff0c\u8fd9\u4e0e\u7528\u6237\u7684\u9700\u6c42\u76f8\u7b26\u3002\",\\n        \"criticism\": \"\u867d\u7136\u7528\u6237\u7684\u9700\u6c42\u660e\u786e\uff0c\u4f46\u4ecd\u9700\u8003\u8651\u6587\u672c\u7684\u5177\u4f53\u7c7b\u578b\u548c\u5206\u6790\u7684\u6df1\u5ea6\u6765\u786e\u4fddToolA\u80fd\u591f\u6ee1\u8db3\u9700\u6c42\u3002\",\\n        \"speak\": \"\u60a8\u5e0c\u671b\u63d0\u53d6\u7684\u5173\u952e\u4fe1\u606f\u662f\u4ec0\u4e48\u7c7b\u578b\u7684\uff1f\u8fd9\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u4f7f\u7528ToolA\u3002\"\\n    },\\n    \"tool\": {\\n        \"name\": [\"ToolA\"]\\n    }\\n}\\n\\n\\nInput:\\ntools_summary: {\\n  \"ToolA\": \"For text analysis and data extraction\",\\n  \"ToolB\": \"For image processing and editing\",\\n  \"ToolC\": \"For text editing and processing\"\\n}\\ninput_text: \"I need to analyze the video and tell me how long it is.\"\\n\\nOutput:\\n{\\n    \"thoughts\": {\\n        \"text\": \"\u7528\u6237\u9700\u8981\u5206\u6790\u89c6\u9891\u5e76\u4e86\u89e3\u89c6\u9891\u65f6\u957f\u3002\",\\n        \"reasoning\": \"\u7528\u6237\u7684\u9700\u6c42\u662f\u4e0e\u89c6\u9891\u5206\u6790\u76f8\u5173\u7684\uff0c\u800c\u63d0\u4f9b\u7684\u5de5\u5177\u4e2d\u6ca1\u6709\u76f4\u63a5\u9488\u5bf9\u89c6\u9891\u5904\u7406\u6216\u5206\u6790\u7684\u5de5\u5177\u3002ToolA\u548cToolC\u4e3b\u8981\u7528\u4e8e\u6587\u672c\u5904\u7406\uff0cToolB\u5219\u7528\u4e8e\u56fe\u50cf\u5904\u7406\u548c\u7f16\u8f91\u3002\",\\n        \"criticism\": \"\u867d\u7136ToolB\u4e0e\u56fe\u50cf\u5904\u7406\u6709\u5173\uff0c\u4f46\u5b83\u5e76\u4e0d\u9002\u7528\u4e8e\u89c6\u9891\u5206\u6790\u6216\u5904\u7406\u89c6\u9891\u65f6\u957f\u8fd9\u7c7b\u9700\u6c42\u3002\u6b64\u5916\uff0c\u6ca1\u6709\u5de5\u5177\u88ab\u63cf\u8ff0\u4e3a\u76f4\u63a5\u652f\u6301\u89c6\u9891\u5904\u7406\u529f\u80fd\u3002\",\\n        \"speak\": \"\u770b\u6765\u6211\u4eec\u76ee\u524d\u63d0\u4f9b\u7684\u5de5\u5177\u90fd\u4e0d\u9002\u5408\u60a8\u7684\u9700\u6c42\uff0c\u56e0\u4e3a\u5b83\u4eec\u4e3b\u8981\u662f\u7528\u4e8e\u6587\u672c\u548c\u56fe\u50cf\u5904\u7406\uff0c\u800c\u4e0d\u662f\u89c6\u9891\u5206\u6790\u3002\"\\n    },\\n    \"tool\": {\\n        \"name\": [\\n            \\n        ]\\n    }\\n}\\n\\nInput:\\ntools_summary: {\\n\"ToolA\": \"For text analysis and data extraction\",\\n\"ToolB\": \"For image processing and editing\",\\n\"ToolC\": \"For creating interactive web applications\"\\n}\\ninput_text: \"I need to analyze survey data and create an interactive web dashboard to display the results.\"\\n\\nOutput:\\n{\\n    \"thoughts\": {\\n        \"text\": \"\u7528\u6237\u9700\u8981\u5206\u6790\u8c03\u67e5\u6570\u636e\u5e76\u521b\u5efa\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u7684\u7f51\u7edc\u4eea\u8868\u677f\u6765\u5c55\u793a\u7ed3\u679c\u3002\",\\n        \"reasoning\": \"\u6839\u636e\u5de5\u5177\u6458\u8981\uff0cToolA \u9002\u7528\u4e8e\u6587\u672c\u5206\u6790\u548c\u6570\u636e\u63d0\u53d6\uff0c\u800c ToolC \u9002\u7528\u4e8e\u521b\u5efa\u4ea4\u4e92\u5f0f\u7684\u7f51\u7edc\u5e94\u7528\u7a0b\u5e8f\u3002\",\\n        \"criticism\": \"\u867d\u7136 ToolA \u9002\u7528\u4e8e\u6570\u636e\u5206\u6790\uff0c\u4f46\u65e0\u6cd5\u521b\u5efa\u7f51\u7edc\u4eea\u8868\u677f\uff1bToolC \u53ef\u4ee5\u521b\u5efa\u4ea4\u4e92\u5f0f\u7684\u7f51\u7edc\u5e94\u7528\uff0c\u4f46\u53ef\u80fd\u4e0d\u5177\u5907\u5206\u6790\u6570\u636e\u7684\u529f\u80fd\u3002\",\\n        \"speak\": \"\u6839\u636e\u60a8\u7684\u9700\u6c42\uff0cToolA \u548c ToolC \u90fd\u53ef\u80fd\u662f\u6709\u7528\u7684\u5de5\u5177\uff0c\u4f46\u9700\u8981\u7ed3\u5408\u4f7f\u7528\u624d\u80fd\u6ee1\u8db3\u60a8\u7684\u9700\u6c42\u3002\"\\n    },\\n    \"tool\": {\\n        \"name\": [\"ToolA\", \"ToolC\"]\\n    }\\n}\\n\\n\\n\\n'\nTOOLS_CHOOSE_HINT = '\\nYou should only respond in JSON format as described below \\nResponse Format: \\n\\n{{{{\\n    \"thoughts\": {{{{\\n        \"text\": \"your thoughts in the current context\",\\n        \"reasoning\": \"reasoning for tool selection and input content\",\\n        \"criticism\": \"critical thinking on tool selection and input in current context\",\\n        \"speak\": \"words you want to speak to the user\",\\n    }}}},\\n    \"tool\": {{{{\\n        \"name\": [\\'tool_name\\'], \\n    }}}}\\n}}}}\\n\\nThe strings corresponding to \"text\", \"reasoning\", \"criticism\", and \"speak\" in JSON should be described in Chinese.\\n\\nIf you don\\'t need to use a tool(like solely chat scene), or have already reasoned the final answer associated with user input from the tool, You must abide by the following rules: \\n1. The tool\\'s name in json is [].\\n\\nDo not output any other information and do not contain quotation marks, such as `, \", \\' and so on.\\nEnsure the output can be parsed by Python json.loads.\\nDon\\'t output in markdown format, something like ```json or ```,just output in the corresponding string format\\n\\n'", "hash": "c442b9fd059ab58ac848ee11c8dcbc16712f721b8916d8e2a48e4d1e2f5effbd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\prompt\\few_shot_extract_parametes_from_input.py", "code_chunk": "EXTRACT_PARAMETES_PROMPT = \"\\nAs a text parameter matcher, your job is to install the function parameter requirements from the text to extract the corresponding parameters.\\n1. You need to read and understand the following text(input_text):\\n2. Extract the corresponding content from the text according to the following parameter information:\\n3. Follow these steps:\\n\\n- First, read and understand the text carefully.\\n   - Second, look for the appropriate content in the text based on the parameter information provided.\\n   - Next, generate a parameter reference dictionary based on what you find. If you don't find a match for a parameter in the text, leave it blank in the dictionary.\\n\\nPerform the preceding steps in sequence and generate a dictionary of parameter parameters.\\n\\nTextual content (input_text):\\n[insert text content here]\\n\\nParameter information (parameter_info):\\n[insert parameter info here]\\n\\nGenerated parameter reference dictionary:\\n[Generate a parameter reference dictionary here, and if the corresponding value cannot be matched, an empty dictionary will be generated]\\n\"\nEXTRACT_PARAMETES_EXAMPLE_PROMPT = '\\nHere is some examples\\n\\nTextual content (input_text):\\n\"Alice, who is 25 years old, works at Acme Corp. Her email is alice@example.com.\"\\n\\nParameter information (parameter_info):\\n[{\\'name\\': \\'name\\', \\'required\\': True, \\'parameter_schema\\': {\\'type\\': \\'string\\', \\'description\\': \\'The name of this people.\\', \\'properties\\': None, \\'items\\': None}},{\\'name\\': \\'age\\', \\'required\\': True, \\'parameter_schema\\': {\\'type\\': \\'int\\', \\'description\\': \\'The age of this people.\\', \\'properties\\': None, \\'items\\': None}},{\\'name\\': \\'email\\', \\'required\\': True, \\'parameter_schema\\': {\\'type\\': \\'string\\', \\'description\\': \\'The email of this people.\\', \\'properties\\': None, \\'items\\': None}}]\\n\\nGenerated parameter reference dictionary:\\n{\"name\": \"Alice\", \"age\": 25, \"email\": \"alice@example.com\"}\\n\\nTextual content (input_text):\\n\"The weather in Paris is mostly sunny this week, with a high of 18\u00b0C and a low of 7\u00b0C.\"\\n\\nParameter information (parameter_info):\\n[{\\'name\\': \\'w\\', \\'required\\': True, \\'parameter_schema\\': {\\'type\\': \\'string\\', \\'description\\': \\'What kind of weather?\\', \\'properties\\': None, \\'items\\': None}},{\\'name\\': \\'age\\', \\'required\\': True, \\'parameter_schema\\': {\\'type\\': \\'int\\', \\'description\\': \\'The age of this people.\\', \\'properties\\': None, \\'items\\': None}},{\\'name\\': \\'email\\', \\'required\\': True, \\'parameter_schema\\': {\\'type\\': \\'string\\', \\'description\\': \\'The email of this people.\\', \\'properties\\': None, \\'items\\': None}}]\\n\\nGenerated parameter reference dictionary:\\n{\"w\": \"sunny\"}\\n\\nTextual content (input_text):\\n\"This new novel is thrilling and full of unexpected twists.\"\\n\\nParameter information (parameter_info):\\n[{\\'name\\': \\'x\\', \\'required\\': True, \\'parameter_schema\\': {\\'type\\': \\'string\\', \\'description\\': \\'input x content\\', \\'properties\\': None, \\'items\\': None}},{\\'name\\': \\'age\\', \\'required\\': True, \\'parameter_schema\\': {\\'type\\': \\'int\\', \\'description\\': \\'The age of this people.\\', \\'properties\\': None, \\'items\\': None}},{\\'name\\': \\'email\\', \\'required\\': True, \\'parameter_schema\\': {\\'type\\': \\'string\\', \\'description\\': \\'The email of this people.\\', \\'properties\\': None, \\'items\\': None}}]\\n\\nGenerated parameter reference dictionary:\\n{}\\n'\nEXTRACT_PARAMETES_HINT = '\\nPlease provide the information in dictionary format. Make sure that the name of each parameter appears as a key, and extract its matching information from the text as the corresponding value.\\n'", "hash": "e266aee0f55408d6ae8c1026bfff3017fee94fc318d828c5e872230649602bf9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\prompt\\few_shot_response_prompt.py", "code_chunk": "RESPONSE_PROMPT = '\\nAs a polite AI assistant, you need to observe the required parameter information and then ask the user questions to get the corresponding parameter information.\\nPlease provide specific information or feedback based on the following parameter information parameter_info. Your answer should be clear and unambiguous, relevant to the information provided by the parameters, and provide appropriate details and examples.\\n'\nRESPONSE_EXAMPLE_PROMPT = \"\\nHere is some examples\\n\\nParameter information (parameter_info):\\n[{'name': 'name', 'required': True, 'parameter_schema': {'type': 'string', 'description': 'The name of this people.', 'properties': None, 'items': None}},{'name': 'age', 'required': True, 'parameter_schema': {'type': 'int', 'description': 'The age of this people.', 'properties': None, 'items': None}},{'name': 'email', 'required': True, 'parameter_schema': {'type': 'string', 'description': 'The email of this people.', 'properties': None, 'items': None}}]\\n\\nResponse sentence:\\nTo proceed, could you please provide the name, age, and email of the person in question? These details are essential for us to move forward.\\n\\nParameter information (parameter_info):\\n[{'name': 'w', 'required': True, 'parameter_schema': {'type': 'string', 'description': 'What kind of weather?', 'properties': None, 'items': None}},{'name': 'age', 'required': True, 'parameter_schema': {'type': 'int', 'description': 'The age of this people.', 'properties': None, 'items': None}},{'name': 'email', 'required': True, 'parameter_schema': {'type': 'string', 'description': 'The email of this people.', 'properties': None, 'items': None}}]\\n\\nResponse sentence:\\nCould you please tell me what type of weather you are experiencing, how old the person in question is, and their email address?\\n\\nParameter information (parameter_info):\\n[{'name': 'x', 'required': True, 'parameter_schema': {'type': 'string', 'description': 'input x content', 'properties': None, 'items': None}},{'name': 'age', 'required': True, 'parameter_schema': {'type': 'int', 'description': 'The age of this people.', 'properties': None, 'items': None}},{'name': 'email', 'required': True, 'parameter_schema': {'type': 'string', 'description': 'The email of this people.', 'properties': None, 'items': None}}]\\n\\nResponse sentence:\\nCould you please provide the content for 'x' (a string input), the age of the person involved (an integer), and their email address (a string input)?\\n\"\nRESPONSE_PROMPT_HINT = '\\nplease output a sentence to user.\\nThe goal is for the user to answer based on the parameters\\n'", "hash": "86218f267b3f56cec7f18f7e156105a4b3629afa04ca65652c89359fd061ae08"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\prompt\\few_shot_tools_choose_prompt.py", "code_chunk": "TOOLS_CHOOSE_PROMPT = \"\\nAs a tool selector, you'll provide users with suggestions on tool selection. Depending on the provided tool summary (tools_summary) and user input (input_text), you'll need to follow these steps:\\n\\n1. Read and understand the tool summary (tools_summary):\\n   - Understand the features, suitcases, and limitations of each tool.\\n\\n2. Analyze User Input (input_text):\\n   - Understand the user's needs or problems.\\n   - Identify keywords or phrases to determine which tool best suits the user's needs.\\n\\n3. Decision-making logic:\\n   - Recommend a tool if the user's needs correspond to the tool's functionality.\\n   - If the user's needs are not suitable for any tool, or if the information is not sufficient to make a judgment, no tool is recommended.\\n\\n4. Output:\\n   - If a tool is recommended, output the tool name (toolname).\\n   - If no tool is recommended, the output is empty.\\n\\nNote that recommendations for tool selection should be based on the user's needs and refer to the tool summary provided. Follow the steps above and make sure to provide accurate tool selection suggestions in the output.\\n\"\nTOOLS_CHOOSE_EXAMPLE_PROMPT = '\\nHere is some examples about tools choosing:\\n\\nInput:\\ntools_summary: {\\n  \"ToolA\": \"For text analysis and data extraction\",\\n  \"ToolB\": \"For image processing and editing\",\\n  ToolC: For audio editing and processing\\n}\\ninput_text: \"I need to analyze a piece of text to extract key information.\"\\n\\nDispose:\\n- Analyze the input_text and identify the requirements as \"text analytics and data extraction\".\\n- Depending on the tools_summary, ToolA matches this requirement.\\n\\nOutput:\\n[ToolA]\\n\\nInput:\\ntools_summary: {\\n  \"ToolA\": \"For text analysis and data extraction\",\\n  \"ToolB\": \"For image processing and editing\",\\n  \"ToolC\": \"For text editing and processing\"\\n}\\ninput_text: \"I need to analyze the video and tell me how long it is.\"\\n\\nDispose:\\n- Analyze the input_text and identify the requirement as \"Analyze the video and obtain the video duration\".\\n- According to tools_summary, there is no tool that matches this need.\\n\\nOutput:\\n[]\\n'\nTOOLS_CHOOSE_HINT = '\\nYou should only output the python list of tool name, such as [ToolA, ToolB, ToolC]. Do not output any other information and do not contain quotation marks, such as `, \", \\' and so on.\\n'", "hash": "c8217b0697bf9ac63658f1f9d98c6cc19eebacf52662c59e0ad94e813d442977"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\prompt\\parameters_generate_prompt.py", "code_chunk": "PARAMETERS_GENERATE_PROMPT = \"\\nAs a tool's parameters generator, you'll generate tool parameters. Depending on the provided tool name (tool_name), tool summary (tool_summary), user input (input_text) and tool input schema (tool_input_schema), you'll need to follow these steps:\\n\\n1. Read and understand the tool summary (tools_summary):\\n    - Understand the functionality, features, and limitations of the tool.\\n\\n2. Analyze User Input (input_text):\\n    - Understand the user's needs or problems.\\n    - Identify keywords or phrases to determine which parameters need to be generated.\\n\\n3. Analyze tool input schema:\\n    - Understand the schema of the tool input.\\n    - Identify the parameters that need to be generated.\\n\\n4. Output:\\n    - Generate the parameters that need to be generated as json format.\\n    - If no parameters need to be generated, the output is empty string.\\n\\nNote that the generation of tool parameters should be based on the user's needs and refer to the tool summary and tool input schema provided. Follow the steps above and make sure to provide accurate tool parameters in the output.\\n\"\nPARAMETERS_GENERATE_EXAMPLE_PROMPT = '\\nHere is some examples about parameters generating:\\n\\nInput:\\ntool_name: \"code interpreter\"\\ntool_summary: \"Run the code through code_interpreter and return a dictionary including a log of the code run and whether it was successful or not.\"\\ninput_text: \"Tell me the 17th Fibonacci number.\"\\ntool_input_schema: [\\n    \\\\{\\n    \"name\": \"code\",\\n    \"description\": \"code text that requires code_interpreter to run\",\\n    \"required\": true,\\n    \"schema\": {\\n        \"type\": \"string\"\\n    }\\n\\\\}\\n]\\n\\nOutput:\\n\\\\{\\n\"code\": \"def fibonacci(n):\\n    a, b = 0, 1\\n    for _ in range(n-1):\\n        a, b = b, a + b\\n    return a\\n\\nprint(fibonacci(17))\",\\n\\\\}\\n'\nPARAMETERS_GENERATE_HINT = '\\nYou should only output the json string of parameters, such as {\"code\": \"print(\\'Hello World\\')\"}. Do not output any other information and do not contain quotation marks, such as `, \", \\' and so on.\\nEnsure the response can be parsed by Python json.loads.\\nDon\\'t output in markdown format, something like ```json or ```,just output in the corresponding string format\\n'", "hash": "501a9ffc21d6814a401fd594df990335e1eb4622ce1a69c6cf35a3cd16804ccd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\prompt\\response_generate_prompt.py", "code_chunk": "RESPONSE_GENERATE_PROMPT = \"\\nAs a response generator, you'll provide users with suggestions on response generation. Depending on the provided user input (input_text), chosen tool infomation (chosen_tool_info), tool input (tool_input),  tool result (tool_result) , you'll need to follow these steps:\\n\\n1. Read and understand the chosen tool infomation (chosen_tool_info):\\n    - Understand the functionality, feature of the chosen tool.\\n\\n2. Analyze user input and tool input and result:\\n    - Understand the user's needs or problems.\\n    - Understand the tool input generate by LLM and tool result generate by tool.\\n\\n3. Output:\\n    - Rearrange the tool's result, make it more readable and understandable.\\n    - Generate the response that need to be generated as string format.\\n\\nNote that the generation of response should be based on the user's needs and refer to the chosen tool infomation provided. Follow the steps above and make sure to provide accurate response in the output.\\n\"\nRESPONSE_GENERATE_EXAMPLE_PROMPT = '\\nHere is some examples about response generating:\\n\\nInput:\\ninput_text: \"Tell me the 17th Fibonacci number.\"\\nchosen_tool_info: \\\\{\\n    \"name\": \"code interpreter\",\\n    \"summary\": \"Run the code through code_interpreter and return a dictionary including a log of the code run and whether it was successful or not.\",\\n    ...\\n\\\\}\\ntool_input: \\\\{\\n    \"code\": \"def fibonacci(n):\\n    a, b = 0, 1\\n    for _ in range(n-1):\\n        a, b = b, a + b\\n    return a\\n\\nprint(fibonacci(17))\"\\n\\\\}\\ntool_result: \\\\{\\n    \"result\": \"987\\n\",\\n    \"success\": true\\n\\\\}\\n\\nOutput:\\n\"The 17th Fibonacci number is 987.\"\\n'\nRESPONSE_GENERATE_HINT = '\\nYou should only output the string of response, such as \"The 17th Fibonacci number is 987.\". Do not output any other information and do not contain quotation marks, such as `, \", \\' and so on.\\n'", "hash": "1799c2e85e025366d040151e61d4ad41413ecb32d2f446d8676741f80aaa8a55"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def __init__(self):\n    super().__init__('da_tool_entity.yaml')\n    self.tmp_dict = {}\n    self.task = DataAnalysisAgent()\n    self.previous_action = []", "hash": "0ceaee74860eddc3b08626cfe651d49a61f05f2c2e917b70485e2274ec0a422c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _call(self, **kwargs):\n    if 'goto' not in kwargs:\n        if self.current_stage.name == self.config.start_stage:\n            return {'type': 'success', 'content': {'message': 'swe tool is started'}}\n        else:\n            return {'type': 'error', 'content': {'message': 'please provide `goto` parameter'}}\n    request_next_stage = kwargs['goto']\n    if request_next_stage not in self.config.all_stages:\n        return {'type': 'error', 'content': {'message': f'stage {request_next_stage} not found'}}\n    self.current_stage = self.config.all_stages[request_next_stage]\n    match self.current_stage.name:\n        case 'stage_1':\n            return self._stage1(kwargs['project_name'])\n        case 'stage_2':\n            return self._stage2(kwargs['file_list'])\n        case 'stage_3':\n            return self._stage3(kwargs['project_requirement'])\n        case 'stage_4':\n            return self._stage4()\n        case 'stage_5':\n            return self._stage5(kwargs['project_type'])\n        case 'stage_6':\n            return self._stage6()\n        case 'stage_7':\n            return self._stage7()\n        case self.config.finish_stage:\n            return self._finish()\n        case _:\n            return {'type': 'error', 'content': {'message': f'stage {self.current_stage.name} not found'}}", "hash": "4b3522195f5db83e72895a103cd4b4b4d1b01fa3b493bbd48d174e09917a407f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _stage1(self, project_name: str):\n    self.task.set_project_name(project_name)\n    return {'type': 'success', 'content': {'message': 'stage1 done, successfully set project_name'}}", "hash": "945156b986fd63bb3bba70eb336c6df6dfcca54a6247351e06b8ae9dbd231c1c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _stage2(self, file_list: List[str]):\n    for file_path in file_list:\n        if os.path.exists(file_path) and os.path.isfile(file_path):\n            self.task.add_file_path(file_path)\n        else:\n            return {'type': 'error', 'content': {'message': 'file at path: %s not found.' % file_path}}\n    return {'type': 'success', 'content': {'message': 'stage2 done, add files'}}", "hash": "cbdee0cb7d4fedf6134f387d359271e38b06979a1c55658225bd2ffd13fd9563"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _stage3(self, project_requirement: str):\n    self.task.set_project_requirement(project_requirement)\n    return {'type': 'success', 'content': {'result': 'stage3 done'}}", "hash": "a38d659d0557cb1d0a1fc29e75eaaa7797b92eee8d9fdf55a15a325a749fe70b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _stage4(self):\n    types = self.task.plan_project_type()\n    return {'type': 'success', 'content': {'result': 'stage4 done', 'planned_types': types}}", "hash": "b69c6c99f8bca334b32019924e853040dce0e40946bb379a2bde84fbfd83456d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _stage5(self, project_type: str):\n    self.task.set_project_type(project_type)\n    self.task.obtain_step_plan()\n    plan_list = self.task.step_plan[:self.task.step_numbers]\n    return {'type': 'success', 'content': {'result': 'stage5 done', 'plan_list': plan_list}}", "hash": "038f457fb6dbf95e13ca6693653338564b0859ecb332f8c187f2847440967871"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _stage6(self):\n    for step_idx in range(self.task.step_numbers):\n        self.task.step_code_generator(step_idx)\n    return {'type': 'success', 'content': {'result': 'stage6 done', 'code': self.task.step_code[:self.task.step_numbers]}}", "hash": "fd8d2e9f7268ef66939e7fa81aa4aa996a65a9c3b31bad4d1608559917f3066a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _stage7(self):\n    for step_idx in range(self.task.step_numbers):\n        self.task.step_report_generator(step_idx)\n    return {'type': 'success', 'content': {'result': 'stage6 done', 'code': self.task.step_report[:self.task.step_numbers]}}", "hash": "fabe267483b1aa9dc9610323060aa92a6f5ef6956f52f82a28efd636b0c4522e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _finish(self):\n    return {'type': 'success', 'content': {'message': 'stateful tool is finished'}}", "hash": "e34d0dee08595707a1e267608299812a323c141417d4c90847b5242e3dc92b40"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.StatefulToolEntity", "hash": "850bd7ef9bfea5845f9e7f50690a430301ffa1a3d5dc78b12a7496ed1094f11e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def __init__(self):\n    super().__init__('da_tool_entity.yaml')\n    self.tmp_dict = {}\n    self.task = DataAnalysisAgent()\n    self.previous_action = []", "hash": "0ceaee74860eddc3b08626cfe651d49a61f05f2c2e917b70485e2274ec0a422c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _call(self, **kwargs):\n    if 'goto' not in kwargs:\n        if self.current_stage.name == self.config.start_stage:\n            return {'type': 'success', 'content': {'message': 'swe tool is started'}}\n        else:\n            return {'type': 'error', 'content': {'message': 'please provide `goto` parameter'}}\n    request_next_stage = kwargs['goto']\n    if request_next_stage not in self.config.all_stages:\n        return {'type': 'error', 'content': {'message': f'stage {request_next_stage} not found'}}\n    self.current_stage = self.config.all_stages[request_next_stage]\n    match self.current_stage.name:\n        case 'stage_1':\n            return self._stage1(kwargs['project_name'])\n        case 'stage_2':\n            return self._stage2(kwargs['file_list'])\n        case 'stage_3':\n            return self._stage3(kwargs['project_requirement'])\n        case 'stage_4':\n            return self._stage4()\n        case 'stage_5':\n            return self._stage5(kwargs['project_type'])\n        case 'stage_6':\n            return self._stage6()\n        case 'stage_7':\n            return self._stage7()\n        case self.config.finish_stage:\n            return self._finish()\n        case _:\n            return {'type': 'error', 'content': {'message': f'stage {self.current_stage.name} not found'}}", "hash": "4b3522195f5db83e72895a103cd4b4b4d1b01fa3b493bbd48d174e09917a407f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _stage1(self, project_name: str):\n    self.task.set_project_name(project_name)\n    return {'type': 'success', 'content': {'message': 'stage1 done, successfully set project_name'}}", "hash": "945156b986fd63bb3bba70eb336c6df6dfcca54a6247351e06b8ae9dbd231c1c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _stage2(self, file_list: List[str]):\n    for file_path in file_list:\n        if os.path.exists(file_path) and os.path.isfile(file_path):\n            self.task.add_file_path(file_path)\n        else:\n            return {'type': 'error', 'content': {'message': 'file at path: %s not found.' % file_path}}\n    return {'type': 'success', 'content': {'message': 'stage2 done, add files'}}", "hash": "cbdee0cb7d4fedf6134f387d359271e38b06979a1c55658225bd2ffd13fd9563"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _stage3(self, project_requirement: str):\n    self.task.set_project_requirement(project_requirement)\n    return {'type': 'success', 'content': {'result': 'stage3 done'}}", "hash": "a38d659d0557cb1d0a1fc29e75eaaa7797b92eee8d9fdf55a15a325a749fe70b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _stage4(self):\n    types = self.task.plan_project_type()\n    return {'type': 'success', 'content': {'result': 'stage4 done', 'planned_types': types}}", "hash": "b69c6c99f8bca334b32019924e853040dce0e40946bb379a2bde84fbfd83456d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _stage5(self, project_type: str):\n    self.task.set_project_type(project_type)\n    self.task.obtain_step_plan()\n    plan_list = self.task.step_plan[:self.task.step_numbers]\n    return {'type': 'success', 'content': {'result': 'stage5 done', 'plan_list': plan_list}}", "hash": "038f457fb6dbf95e13ca6693653338564b0859ecb332f8c187f2847440967871"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _stage6(self):\n    for step_idx in range(self.task.step_numbers):\n        self.task.step_code_generator(step_idx)\n    return {'type': 'success', 'content': {'result': 'stage6 done', 'code': self.task.step_code[:self.task.step_numbers]}}", "hash": "fd8d2e9f7268ef66939e7fa81aa4aa996a65a9c3b31bad4d1608559917f3066a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _stage7(self):\n    for step_idx in range(self.task.step_numbers):\n        self.task.step_report_generator(step_idx)\n    return {'type': 'success', 'content': {'result': 'stage6 done', 'code': self.task.step_report[:self.task.step_numbers]}}", "hash": "fabe267483b1aa9dc9610323060aa92a6f5ef6956f52f82a28efd636b0c4522e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "DAToolEntity.def _finish(self):\n    return {'type': 'success', 'content': {'message': 'stateful tool is finished'}}", "hash": "e34d0dee08595707a1e267608299812a323c141417d4c90847b5242e3dc92b40"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\da_tool_entity.py", "code_chunk": "import os\nfrom typing import List\nfrom .stateful_tool_entity import *\nfrom ...agents.data_analysis.data_analysis import DataAnalysisAgent", "hash": "94e83d9577554944198393423e60835e7ac01eb526885545eef0e50e5d190317"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\example_stateful_tool_entity.py", "code_chunk": "ExampleStatefulToolEntity.def __init__(self):\n    super().__init__('example_stateful_tool.yaml')", "hash": "3fe689c6701af0588e8215b29b520bf2bb9a98ea2ed8817afab85f11e79aab06"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\example_stateful_tool_entity.py", "code_chunk": "ExampleStatefulToolEntity.def _call(self, **kwargs):\n    if 'goto' not in kwargs:\n        if self.current_stage.name == self.config.start_stage:\n            return {'type': 'success', 'content': {'message': 'stateful tool is started'}}\n        else:\n            return {'type': 'error', 'content': {'message': 'please provide `goto` parameter'}}\n    request_next_stage = kwargs['goto']\n    if request_next_stage not in self.config.all_stages:\n        return {'type': 'error', 'content': {'message': f'stage {request_next_stage} not found'}}\n    self.current_stage = self.config.all_stages[request_next_stage]\n    match self.current_stage.name:\n        case 'stage_1':\n            return self._stage1(kwargs['x'])\n        case 'stage_2':\n            return self._stage2(kwargs['y'])\n        case 'stage_3':\n            return self._stage3()\n        case self.config.finish_stage:\n            return self._finish()\n        case _:\n            return {'type': 'error', 'content': {'message': f'stage {self.current_stage.name} not found'}}", "hash": "3036587b9394c07a89e5a4c39bb493557d874aa6040a6088a0c847f5a03c901a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\example_stateful_tool_entity.py", "code_chunk": "ExampleStatefulToolEntity.def _stage1(self, x: int):\n    self.x = x\n    return {'type': 'success', 'content': {'message': 'stage1 done'}}", "hash": "4bb569acde33854a6d984f9df4b3c9f4e9d9a3ba0aef3367679e2914a158431d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\example_stateful_tool_entity.py", "code_chunk": "ExampleStatefulToolEntity.def _stage2(self, y: int):\n    self.y = y\n    return {'type': 'success', 'content': {'message': 'stage2 done'}}", "hash": "e263dfb0a22854383091efb96d26d0388fbd2314a7c5377516cf7d7d7b5da2a9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\example_stateful_tool_entity.py", "code_chunk": "ExampleStatefulToolEntity.def _stage3(self):\n    return {'type': 'success', 'content': {'result': self.x + self.y}}", "hash": "6734c6d7917dd11a24832a1b60ad92c8363a247a6f8a131d86123167a23f89c7"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\example_stateful_tool_entity.py", "code_chunk": "ExampleStatefulToolEntity.def _finish(self):\n    return {'type': 'success', 'content': {'message': 'stateful tool is finished'}}", "hash": "e2e553cb55eda9dabc557742aa72e235abbcafb8aa922c831203363841baa3ba"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\example_stateful_tool_entity.py", "code_chunk": "ExampleStatefulToolEntity.StatefulToolEntity\n'\\n    This example tool entity is stateful, and it has 3 inner stages.\\n\\n    stage1: take integer x as input\\n    stage2: take integer y as input\\n    stage3: no input, return x + y\\n    '", "hash": "60c44ca5ef2938ceb58e3c71e5838c4f44861d43c1119167a181cf8fba1b4dbe"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\example_stateful_tool_entity.py", "code_chunk": "ExampleStatefulToolEntity.def __init__(self):\n    super().__init__('example_stateful_tool.yaml')", "hash": "3fe689c6701af0588e8215b29b520bf2bb9a98ea2ed8817afab85f11e79aab06"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\example_stateful_tool_entity.py", "code_chunk": "ExampleStatefulToolEntity.def _call(self, **kwargs):\n    if 'goto' not in kwargs:\n        if self.current_stage.name == self.config.start_stage:\n            return {'type': 'success', 'content': {'message': 'stateful tool is started'}}\n        else:\n            return {'type': 'error', 'content': {'message': 'please provide `goto` parameter'}}\n    request_next_stage = kwargs['goto']\n    if request_next_stage not in self.config.all_stages:\n        return {'type': 'error', 'content': {'message': f'stage {request_next_stage} not found'}}\n    self.current_stage = self.config.all_stages[request_next_stage]\n    match self.current_stage.name:\n        case 'stage_1':\n            return self._stage1(kwargs['x'])\n        case 'stage_2':\n            return self._stage2(kwargs['y'])\n        case 'stage_3':\n            return self._stage3()\n        case self.config.finish_stage:\n            return self._finish()\n        case _:\n            return {'type': 'error', 'content': {'message': f'stage {self.current_stage.name} not found'}}", "hash": "3036587b9394c07a89e5a4c39bb493557d874aa6040a6088a0c847f5a03c901a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\example_stateful_tool_entity.py", "code_chunk": "ExampleStatefulToolEntity.def _stage1(self, x: int):\n    self.x = x\n    return {'type': 'success', 'content': {'message': 'stage1 done'}}", "hash": "4bb569acde33854a6d984f9df4b3c9f4e9d9a3ba0aef3367679e2914a158431d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\example_stateful_tool_entity.py", "code_chunk": "ExampleStatefulToolEntity.def _stage2(self, y: int):\n    self.y = y\n    return {'type': 'success', 'content': {'message': 'stage2 done'}}", "hash": "e263dfb0a22854383091efb96d26d0388fbd2314a7c5377516cf7d7d7b5da2a9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\example_stateful_tool_entity.py", "code_chunk": "ExampleStatefulToolEntity.def _stage3(self):\n    return {'type': 'success', 'content': {'result': self.x + self.y}}", "hash": "6734c6d7917dd11a24832a1b60ad92c8363a247a6f8a131d86123167a23f89c7"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\example_stateful_tool_entity.py", "code_chunk": "ExampleStatefulToolEntity.def _finish(self):\n    return {'type': 'success', 'content': {'message': 'stateful tool is finished'}}", "hash": "e2e553cb55eda9dabc557742aa72e235abbcafb8aa922c831203363841baa3ba"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\example_stateful_tool_entity.py", "code_chunk": "from .stateful_tool_entity import *", "hash": "7f9612c37718391136951545e7801f0c7207d5c5d027fb9a6f6cdb564db23b17"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\model.py", "code_chunk": "ObjectType.str\nEnum\nSTRING = 'string'\nNUMBER = 'number'\nBOOLEAN = 'boolean'\nOBJECT = 'object'\nARRAY = 'array'", "hash": "d27d560796e37a94aeef8932a4d22ded9ea1f690cdd0f2b9a3e80aee302786c4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\model.py", "code_chunk": "Schema.BaseModel\ntype: Literal['string', 'number', 'boolean', 'object', 'array'] = Field(description='\u53c2\u6570\u7c7b\u578b')\ndescription: Optional[str] = Field(description='\u53c2\u6570\u63cf\u8ff0')\nproperties: Optional[dict[str, Schema]] = Field(description='\u53c2\u6570\u7c7b\u578b\u4e3a object \u65f6\u7684\u5143\u7d20\u7c7b\u578b')\nitems: Optional[list[Schema]] = Field(description='\u53c2\u6570\u7c7b\u578b\u4e3a array \u65f6\u7684\u5143\u7d20\u7c7b\u578b')", "hash": "ca33708c7f3d7a24b3f6069e3a565b566596ec47377e2ce5e03b32a970fead61"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\model.py", "code_chunk": "Parameter.BaseModel\nname: str = Field(description='\u53c2\u6570\u540d')\nrequired: bool = Field(description='\u662f\u5426\u5fc5\u987b')\nparameter_schema: Schema = Field(description='\u53c2\u6570schema')", "hash": "8c0b99ccc1b8d60d064e90a1e0987032e7ded3fcdabdf2677dcfad7a512f0d4e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\model.py", "code_chunk": "Response.BaseModel\ndescription: str = Field(description='\u54cd\u5e94\u63cf\u8ff0')\ncontent: dict[str, Schema] = Field(description='\u54cd\u5e94\u5185\u5bb9')", "hash": "93dbff61439a829050b166b561495488faad79ad23a1a6e9d3fc80f32daccfdd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\model.py", "code_chunk": "Stage.BaseModel\nname: str = Field(description='Stage \u540d\u79f0')\nnext_stage_entry: dict[str, list[Parameter]] = Field(description='\u4e0b\u4e00\u4e2a\u53ef\u80fd\u7684 Stage \u540d\u4ee5\u53ca\u5bf9\u5e94\u9700\u8981\u4f20\u5165\u7684\u53c2\u6570\u5217\u8868')\nneed_llm_generate_parameters: bool = Field(description='\u5728\u8fd9\u4e2a Stage \u8f93\u5165\u65f6\u662f\u5426\u9700\u8981 LLM \u751f\u6210\u53c2\u6570')\nneed_llm_generate_response: bool = Field(description='\u5728\u8fd9\u4e2a Stage \u8f93\u5165\u65f6\u662f\u5426\u9700\u8981 LLM \u751f\u6210\u56de\u590d\u5185\u5bb9')", "hash": "5596800bd7655a17ed3281b7a8ea58be95296e7b2955dda8caf95a635b254fe4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\model.py", "code_chunk": "from __future__ import annotations\nfrom typing import Optional, Literal\nfrom enum import Enum\nfrom pydantic import BaseModel, Field", "hash": "093dd5497b497e5636728f5215dfccc0bbe3b4facd947e209723b4238e8e189a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntityConfig.BaseModel\nstart_stage: str = Field(description='The start stage of the tool entity.')\nfinish_stage: str = Field(description='The finish stage of the tool entity.')\nall_stages: dict[str, Stage] = Field(description='All stages of the tool entity.')", "hash": "f39c139d43073574d0bbc276a8169126951d21e194d32531511d8152ce2fc126"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def __init__(self, config_file_name: str):\n    stack = inspect.stack()\n    caller_frame = stack[1]\n    caller_path = caller_frame.filename\n    caller_dir = os.path.dirname(caller_path)\n    config_path = os.path.join(caller_dir, config_file_name)\n    with open(config_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    self.config = StatefulToolEntityConfig(**data)\n    self.current_stage = self.config.all_stages[self.config.start_stage]", "hash": "d3e4e9283a4cb3467b5e425383f1933c211571bbe3fe66f3b0f7ccb538f8e350"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def is_stateful(self) -> bool:\n    return True", "hash": "0b139f381973fe9a1a12f5c28f7527ad56225f2eac60e4c5693f964bd4d2ba82"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def current_state(self):\n    if self.current_stage.name == self.config.finish_stage:\n        return State.DONE\n    elif self.current_stage.name == self.config.start_stage:\n        return State.IDLE\n    else:\n        return State.RUNNING", "hash": "b51fbf4a120df88c0a5db1d7da481208ad785d2c6f1b0ccb7658b9d2da857c64"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def need_llm_generate_parameters(self) -> bool:\n    return self.current_stage.need_llm_generate_parameters", "hash": "44a21c75dafacb5b4e1618a94ddfa04fd6aa21e102358a721a2d63e97d2da129"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def need_llm_generate_response(self) -> bool:\n    return self.current_stage.need_llm_generate_response", "hash": "606259e284c2320b07d10844b6992dde0e287ed41fd882f143d1594f6f819cf7"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def _get_next_stages_info(self) -> dict[str, list[dict]]:\n    return self.current_stage.dict()['next_stage_entry']", "hash": "1c46533c2ca1bbf9ec97970dcbc139addd6c57d2606cf841906e2e31f34eaf4b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def call(self, **kwargs):\n    if 'goto' in kwargs:\n        cur_stage_entry = self._get_next_stages_info()\n        parameter_info = cur_stage_entry[next(iter(cur_stage_entry))]\n        input_text = kwargs['input_text']\n        if len(parameter_info) > 0:\n            parametes = self._extract_parametes(input_text, parameter_info)\n            if len(parametes) == 0:\n                return {'type': 'error', 'assistant': {'message': 'Please enter the corresponding parameter value correctly'}}\n            else:\n                kwargs.update(parametes)\n    res = self._call(**kwargs)\n    cur_stage_entry = self._get_next_stages_info()\n    if cur_stage_entry:\n        parameter_info = cur_stage_entry[next(iter(cur_stage_entry))]\n        if len(parameter_info) == 0:\n            response = f'{self.current_stage.name} is ready,Enter any response to continue'\n        else:\n            response = self._response_chat(parameter_info)\n    else:\n        response = f'{self.current_stage.name} is finish,Enter any response to continue'\n    return {**res, 'next_stages_info': self._get_next_stages_info(), 'assistant': {'message': f'{response}'}}", "hash": "577060da2b82071f199b2011e87df9736bf812b8ebab9dc3f3b6b132318485fb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def _response_chat(self, parameter_info: list):\n    response_node = OpenAINode()\n    system_prompt = RESPONSE_PROMPT + RESPONSE_EXAMPLE_PROMPT + RESPONSE_PROMPT_HINT\n    response_node.add_system_message(system_prompt)\n    prompt = f'Parameter information (parameter_info):{parameter_info}\\nplease output a sentence to user.\\nResponse sentence:\\n'\n    message_config = Message(role='user', content=prompt)\n    chat_config = ChatWithMessageInput(message=message_config, model='gpt-4-1106-preview', append_history=False, use_streaming=False)\n    response = response_node.chat_with_message(chat_config).message.content\n    return response", "hash": "03dc3a7b6649059828ba72c73ddcb40752951f77485e51bc7b6b9bf30e3244a1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def _extract_parametes(self, input_text: str, parameter_info: list):\n    parametes_node = OpenAINode()\n    parametes_node.add_system_message(EXTRACT_PARAMETES_PROMPT + EXTRACT_PARAMETES_EXAMPLE_PROMPT + EXTRACT_PARAMETES_HINT)\n    prompt = f'\\nTextual content (input_text):{input_text}\\nParameter information (parameter_info):{parameter_info}\\nGenerated parameter reference dictionary:\\n'\n    message_config = Message(role='user', content=prompt)\n    chat_config = ChatWithMessageInput(message=message_config, model='gpt-4-1106-preview', append_history=False, use_streaming=False)\n    max_attempts = 5\n    attempts = 0\n    while attempts < max_attempts:\n        try:\n            response = parametes_node.chat_with_message(chat_config).message.content\n            print(f'response:{response}')\n            parametes = json.loads(response)\n            break\n        except json.JSONDecodeError:\n            attempts += 1\n            continue\n    return parametes", "hash": "58f56dac0cd1a134055df9b456719b2ef1d8e53a539a7b796676a6b2317b3cdd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.@abstractmethod\ndef _call(self, **kwargs):\n    pass", "hash": "231fdf47f345fbb4ae55e44ad9f0da2f98ed779fb77a86a4ae7cd2643ce26a6f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.BaseToolEntity\nABC\nconfig: StatefulToolEntityConfig\ncurrent_stage: Stage", "hash": "bc8c0aa968b1c5ff62d595031fe527c316da0c41a83490398f5d3c9deeec42ad"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def __init__(self, config_file_name: str):\n    stack = inspect.stack()\n    caller_frame = stack[1]\n    caller_path = caller_frame.filename\n    caller_dir = os.path.dirname(caller_path)\n    config_path = os.path.join(caller_dir, config_file_name)\n    with open(config_path, 'r') as file:\n        data = yaml.safe_load(file) or []\n    self.config = StatefulToolEntityConfig(**data)\n    self.current_stage = self.config.all_stages[self.config.start_stage]", "hash": "d3e4e9283a4cb3467b5e425383f1933c211571bbe3fe66f3b0f7ccb538f8e350"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def is_stateful(self) -> bool:\n    return True", "hash": "0b139f381973fe9a1a12f5c28f7527ad56225f2eac60e4c5693f964bd4d2ba82"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def current_state(self):\n    if self.current_stage.name == self.config.finish_stage:\n        return State.DONE\n    elif self.current_stage.name == self.config.start_stage:\n        return State.IDLE\n    else:\n        return State.RUNNING", "hash": "b51fbf4a120df88c0a5db1d7da481208ad785d2c6f1b0ccb7658b9d2da857c64"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def need_llm_generate_parameters(self) -> bool:\n    return self.current_stage.need_llm_generate_parameters", "hash": "44a21c75dafacb5b4e1618a94ddfa04fd6aa21e102358a721a2d63e97d2da129"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def need_llm_generate_response(self) -> bool:\n    return self.current_stage.need_llm_generate_response", "hash": "606259e284c2320b07d10844b6992dde0e287ed41fd882f143d1594f6f819cf7"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def _get_next_stages_info(self) -> dict[str, list[dict]]:\n    return self.current_stage.dict()['next_stage_entry']", "hash": "1c46533c2ca1bbf9ec97970dcbc139addd6c57d2606cf841906e2e31f34eaf4b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def call(self, **kwargs):\n    if 'goto' in kwargs:\n        cur_stage_entry = self._get_next_stages_info()\n        parameter_info = cur_stage_entry[next(iter(cur_stage_entry))]\n        input_text = kwargs['input_text']\n        if len(parameter_info) > 0:\n            parametes = self._extract_parametes(input_text, parameter_info)\n            if len(parametes) == 0:\n                return {'type': 'error', 'assistant': {'message': 'Please enter the corresponding parameter value correctly'}}\n            else:\n                kwargs.update(parametes)\n    res = self._call(**kwargs)\n    cur_stage_entry = self._get_next_stages_info()\n    if cur_stage_entry:\n        parameter_info = cur_stage_entry[next(iter(cur_stage_entry))]\n        if len(parameter_info) == 0:\n            response = f'{self.current_stage.name} is ready,Enter any response to continue'\n        else:\n            response = self._response_chat(parameter_info)\n    else:\n        response = f'{self.current_stage.name} is finish,Enter any response to continue'\n    return {**res, 'next_stages_info': self._get_next_stages_info(), 'assistant': {'message': f'{response}'}}", "hash": "577060da2b82071f199b2011e87df9736bf812b8ebab9dc3f3b6b132318485fb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def _response_chat(self, parameter_info: list):\n    response_node = OpenAINode()\n    system_prompt = RESPONSE_PROMPT + RESPONSE_EXAMPLE_PROMPT + RESPONSE_PROMPT_HINT\n    response_node.add_system_message(system_prompt)\n    prompt = f'Parameter information (parameter_info):{parameter_info}\\nplease output a sentence to user.\\nResponse sentence:\\n'\n    message_config = Message(role='user', content=prompt)\n    chat_config = ChatWithMessageInput(message=message_config, model='gpt-4-1106-preview', append_history=False, use_streaming=False)\n    response = response_node.chat_with_message(chat_config).message.content\n    return response", "hash": "03dc3a7b6649059828ba72c73ddcb40752951f77485e51bc7b6b9bf30e3244a1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.def _extract_parametes(self, input_text: str, parameter_info: list):\n    parametes_node = OpenAINode()\n    parametes_node.add_system_message(EXTRACT_PARAMETES_PROMPT + EXTRACT_PARAMETES_EXAMPLE_PROMPT + EXTRACT_PARAMETES_HINT)\n    prompt = f'\\nTextual content (input_text):{input_text}\\nParameter information (parameter_info):{parameter_info}\\nGenerated parameter reference dictionary:\\n'\n    message_config = Message(role='user', content=prompt)\n    chat_config = ChatWithMessageInput(message=message_config, model='gpt-4-1106-preview', append_history=False, use_streaming=False)\n    max_attempts = 5\n    attempts = 0\n    while attempts < max_attempts:\n        try:\n            response = parametes_node.chat_with_message(chat_config).message.content\n            print(f'response:{response}')\n            parametes = json.loads(response)\n            break\n        except json.JSONDecodeError:\n            attempts += 1\n            continue\n    return parametes", "hash": "58f56dac0cd1a134055df9b456719b2ef1d8e53a539a7b796676a6b2317b3cdd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "StatefulToolEntity.@abstractmethod\ndef _call(self, **kwargs):\n    pass", "hash": "231fdf47f345fbb4ae55e44ad9f0da2f98ed779fb77a86a4ae7cd2643ce26a6f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\stateful_tool_entity.py", "code_chunk": "from .model import *\nfrom .tool_entity import *\nfrom ...nodes.openai.openai import OpenAINode\nfrom ...nodes.openai.openai_model import *\nfrom ...assistant.prompt.few_shot_extract_parametes_from_input import *\nfrom ...assistant.prompt.few_shot_response_prompt import *\nimport inspect\nimport json", "hash": "ba7cb00b56433b38adf0d00a044f713d91e6c77597e31c39ae69c1ef87489b5b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def __init__(self):\n    super().__init__('swe_tool.yaml')\n    self.tmp_dict = {}\n    self.task = SoftwareEngineerAgent()\n    self.previous_action = []", "hash": "89fb45931d60881e16ddb2c9d21a4ebbc190e9e1f81f64ef1027acf6d704a1e8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _call(self, **kwargs):\n    if 'goto' not in kwargs:\n        if self.current_stage.name == self.config.start_stage:\n            return {'type': 'success', 'content': {'message': 'swe tool is started'}}\n        else:\n            return {'type': 'error', 'content': {'message': 'please provide `goto` parameter'}}\n    request_next_stage = kwargs['goto']\n    if request_next_stage not in self.config.all_stages:\n        return {'type': 'error', 'content': {'message': f'stage {request_next_stage} not found'}}\n    self.current_stage = self.config.all_stages[request_next_stage]\n    match self.current_stage.name:\n        case 'stage_1':\n            return self._stage1(kwargs['repo_url'])\n        case 'stage_2':\n            return self._stage2(kwargs['feature'])\n        case 'stage_3':\n            return self._stage3(kwargs['focus_files_name_list'])\n        case 'stage_4':\n            return self._stage4(kwargs['action'], kwargs['plan_idx'], kwargs['focus_file_name'], kwargs['description'])\n        case 'stage_5':\n            return self._stage5()\n        case 'stage_6':\n            return self._stage6(kwargs['action'], kwargs['action_idx'], kwargs['revise_comments'])\n        case self.config.finish_stage:\n            return self._finish()\n        case _:\n            return {'type': 'error', 'content': {'message': f'stage {self.current_stage.name} not found'}}", "hash": "a02a61724274c5191c7f18a4824edfc9fc3ff6329744acd7f2c5801791bcd602"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _stage1(self, repo_url: str):\n    self.repo_url = repo_url\n    if repo_url.startswith('http'):\n        self.task.set_repo_url(repo_url)\n    else:\n        self.task.set_local_repo(repo_url)\n    return {'type': 'success', 'content': {'message': 'stage1 done,get repo_url'}}", "hash": "08e79ecae3271a02b88e30602b9efbf040a7f1b11ec9d8e77a038d5be61228b1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _stage2(self, feature: str):\n    self.feature = feature\n    self.task.set_feature_description(feature)\n    return {'type': 'success', 'content': {'message': 'stage2 done,get feature'}}", "hash": "afdbc24951176bd66b6880dd9e912203286a5ac0e41bd69dd10437a6a59bbd6d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _stage3(self, focus_files_name_list: List[str]):\n    self.task.set_focus_files()\n    for focus_files_name in focus_files_name_list:\n        self.task.add_focus_file(focus_files_name)\n    self.task.design_plan()\n    plans = self.task.get_plan()\n    return {'type': 'success', 'content': {'result': 'stage3 done', 'plans': str(plans)}}", "hash": "2c861111c1762a7fad854927a7f19b4812067d1a64a5d542f3f29babafa03d80"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _stage4(self, action: int, plan_idx: int, focus_file_name: str, description: str):\n    ADD_PLAN = 0\n    REMOVE_PLAN = 1\n    MODIFY_PLAN = 2\n    plans = self.task.get_plan()\n    if action == ADD_PLAN:\n        plans.append(Plan(action='add', file_path=focus_file_name, description=description))\n    elif action == REMOVE_PLAN:\n        print('the deleting plan is: ')\n        print(plans[plan_idx])\n        del plans[plan_idx]\n    elif action == MODIFY_PLAN:\n        plans[plan_idx].file_path = focus_file_name\n        plans[plan_idx].description = description\n        plans[plan_idx].action = 'modify'\n    self.task.set_plans(plans)\n    return {'type': 'success', 'content': {'result': 'stage4 done', 'plans': str(plans)}}", "hash": "77e9ed6d06a45060ebc21d460b4670867f230d5cbbd5e02d67a596eb8a7362fe"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _stage5(self):\n    actions = []\n    for action in self.task.implement():\n        actions.append(action.content)\n        self.previous_action.append(action)\n    return {'type': 'success', 'content': {'result': 'stage5 done', 'actions': self.previous_action}}", "hash": "30d12b8982ad6b069160d1aa0c81d8da320e66fc61630ce6f079e9d0426c77c8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _stage6(self, action: int, action_idx: int, revise_comments: str):\n    APPLY = 0\n    NOT_APPLY = 1\n    REVISE = 2\n    if action == APPLY:\n        file_actions = self.task.get_file_actions()\n        self.task.apply_one_file_action(action_idx)\n        finish_file_actions = self.task.get_finish_file_actions()\n        finish_file_actions.append(file_actions[action_idx])\n        self.task.set_finish_file_actions(finish_file_actions)\n        del file_actions[action_idx]\n        self.task.set_file_actions(file_actions)\n    elif action == NOT_APPLY:\n        file_actions = self.task.get_file_actions()\n        finish_file_actions = self.task.get_finish_file_actions()\n        finish_file_actions.append(file_actions[action_idx])\n        self.task.set_finish_file_actions(finish_file_actions)\n        del file_actions[action_idx]\n        self.task.set_file_actions(file_actions)\n    elif action == REVISE:\n        new_action = self.task.agent._revise_code(f'{self.task.previous_action[action_idx]}', revise_comments, action_idx)\n        self.previous_action.append(new_action)\n        return {'type': 'success', 'content': {'result': 'stage6 done', 'actions': self.previous_action}}\n    return {'type': 'success', 'content': {'result': 'stage6 done'}}", "hash": "7e74fea2c567698b50ca2ea184c7eca1f403f920ed20753efae4ff8f27d7115b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _finish(self):\n    return {'type': 'success', 'content': {'message': 'stateful tool is finished'}}", "hash": "d4e0bc6ae7a4e2f04c70c904dcd58f6d20530182e61481e51ca2d99b4228c185"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.StatefulToolEntity", "hash": "df92ca15292ea96b2f5916481d2d384828f66f6c1673e710d40c341333b714ff"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def __init__(self):\n    super().__init__('swe_tool.yaml')\n    self.tmp_dict = {}\n    self.task = SoftwareEngineerAgent()\n    self.previous_action = []", "hash": "89fb45931d60881e16ddb2c9d21a4ebbc190e9e1f81f64ef1027acf6d704a1e8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _call(self, **kwargs):\n    if 'goto' not in kwargs:\n        if self.current_stage.name == self.config.start_stage:\n            return {'type': 'success', 'content': {'message': 'swe tool is started'}}\n        else:\n            return {'type': 'error', 'content': {'message': 'please provide `goto` parameter'}}\n    request_next_stage = kwargs['goto']\n    if request_next_stage not in self.config.all_stages:\n        return {'type': 'error', 'content': {'message': f'stage {request_next_stage} not found'}}\n    self.current_stage = self.config.all_stages[request_next_stage]\n    match self.current_stage.name:\n        case 'stage_1':\n            return self._stage1(kwargs['repo_url'])\n        case 'stage_2':\n            return self._stage2(kwargs['feature'])\n        case 'stage_3':\n            return self._stage3(kwargs['focus_files_name_list'])\n        case 'stage_4':\n            return self._stage4(kwargs['action'], kwargs['plan_idx'], kwargs['focus_file_name'], kwargs['description'])\n        case 'stage_5':\n            return self._stage5()\n        case 'stage_6':\n            return self._stage6(kwargs['action'], kwargs['action_idx'], kwargs['revise_comments'])\n        case self.config.finish_stage:\n            return self._finish()\n        case _:\n            return {'type': 'error', 'content': {'message': f'stage {self.current_stage.name} not found'}}", "hash": "a02a61724274c5191c7f18a4824edfc9fc3ff6329744acd7f2c5801791bcd602"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _stage1(self, repo_url: str):\n    self.repo_url = repo_url\n    if repo_url.startswith('http'):\n        self.task.set_repo_url(repo_url)\n    else:\n        self.task.set_local_repo(repo_url)\n    return {'type': 'success', 'content': {'message': 'stage1 done,get repo_url'}}", "hash": "08e79ecae3271a02b88e30602b9efbf040a7f1b11ec9d8e77a038d5be61228b1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _stage2(self, feature: str):\n    self.feature = feature\n    self.task.set_feature_description(feature)\n    return {'type': 'success', 'content': {'message': 'stage2 done,get feature'}}", "hash": "afdbc24951176bd66b6880dd9e912203286a5ac0e41bd69dd10437a6a59bbd6d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _stage3(self, focus_files_name_list: List[str]):\n    self.task.set_focus_files()\n    for focus_files_name in focus_files_name_list:\n        self.task.add_focus_file(focus_files_name)\n    self.task.design_plan()\n    plans = self.task.get_plan()\n    return {'type': 'success', 'content': {'result': 'stage3 done', 'plans': str(plans)}}", "hash": "2c861111c1762a7fad854927a7f19b4812067d1a64a5d542f3f29babafa03d80"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _stage4(self, action: int, plan_idx: int, focus_file_name: str, description: str):\n    ADD_PLAN = 0\n    REMOVE_PLAN = 1\n    MODIFY_PLAN = 2\n    plans = self.task.get_plan()\n    if action == ADD_PLAN:\n        plans.append(Plan(action='add', file_path=focus_file_name, description=description))\n    elif action == REMOVE_PLAN:\n        print('the deleting plan is: ')\n        print(plans[plan_idx])\n        del plans[plan_idx]\n    elif action == MODIFY_PLAN:\n        plans[plan_idx].file_path = focus_file_name\n        plans[plan_idx].description = description\n        plans[plan_idx].action = 'modify'\n    self.task.set_plans(plans)\n    return {'type': 'success', 'content': {'result': 'stage4 done', 'plans': str(plans)}}", "hash": "77e9ed6d06a45060ebc21d460b4670867f230d5cbbd5e02d67a596eb8a7362fe"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _stage5(self):\n    actions = []\n    for action in self.task.implement():\n        actions.append(action.content)\n        self.previous_action.append(action)\n    return {'type': 'success', 'content': {'result': 'stage5 done', 'actions': self.previous_action}}", "hash": "30d12b8982ad6b069160d1aa0c81d8da320e66fc61630ce6f079e9d0426c77c8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _stage6(self, action: int, action_idx: int, revise_comments: str):\n    APPLY = 0\n    NOT_APPLY = 1\n    REVISE = 2\n    if action == APPLY:\n        file_actions = self.task.get_file_actions()\n        self.task.apply_one_file_action(action_idx)\n        finish_file_actions = self.task.get_finish_file_actions()\n        finish_file_actions.append(file_actions[action_idx])\n        self.task.set_finish_file_actions(finish_file_actions)\n        del file_actions[action_idx]\n        self.task.set_file_actions(file_actions)\n    elif action == NOT_APPLY:\n        file_actions = self.task.get_file_actions()\n        finish_file_actions = self.task.get_finish_file_actions()\n        finish_file_actions.append(file_actions[action_idx])\n        self.task.set_finish_file_actions(finish_file_actions)\n        del file_actions[action_idx]\n        self.task.set_file_actions(file_actions)\n    elif action == REVISE:\n        new_action = self.task.agent._revise_code(f'{self.task.previous_action[action_idx]}', revise_comments, action_idx)\n        self.previous_action.append(new_action)\n        return {'type': 'success', 'content': {'result': 'stage6 done', 'actions': self.previous_action}}\n    return {'type': 'success', 'content': {'result': 'stage6 done'}}", "hash": "7e74fea2c567698b50ca2ea184c7eca1f403f920ed20753efae4ff8f27d7115b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "SWEToolEntity.def _finish(self):\n    return {'type': 'success', 'content': {'message': 'stateful tool is finished'}}", "hash": "d4e0bc6ae7a4e2f04c70c904dcd58f6d20530182e61481e51ca2d99b4228c185"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\swe_tool_entity.py", "code_chunk": "import logging\nfrom typing import List, Optional\nfrom .stateful_tool_entity import *\nfrom ...agents.software_engineer.software_engineer import SoftwareEngineerAgent", "hash": "d94d14271f1abec5283b5ff3cdfb640e0f1e00e01ccc7816eb733e11010e12cb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "def serve_code_interpreter(code: str) -> dict[str, any]:\n    from ...nodes.code_runner.code_runner import CodeRunnerNode, RunCodeInput\n    code_runner_node = CodeRunnerNode()\n    code_runner_node.init_python_repl()\n    res = code_runner_node.run_code(RunCodeInput(code=code))\n    return {'type': 'success', 'content': {'result': res}}", "hash": "8eeb1b90ba55023f14337ae09b38753f5750c42148ca5b3928a59b8bc4090f73"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "def register_function_tool(func):\n    FUNCTION_TOOL_ENTITIES[func.__name__] = func\n    return func", "hash": "0b4efd6e0125e753c533a753d2461ed4e3a8283f5767f0073ebbbe4b51173ed2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "def register_stateful_tool(cls):\n    STATEFUL_TOOL_ENTITIES[cls.__name__] = cls\n    return cls", "hash": "77f19f593004c4511d2fbf96788ff701d57b5cd87ed1c61435a285ee3cf7922d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "ToolConfig.BaseModel\nname: str = Field(description='\u5de5\u5177\u540d\u79f0')\nentity_name: str = Field(description='\u5de5\u5177\u5b9e\u4f53\u540d\u79f0')\nsummary: str = Field(description='\u5de5\u5177\u63cf\u8ff0')\nparameters: list[Parameter] = Field(description='\u53c2\u6570\u5217\u8868')\nresponses: dict[str, Response] = Field(description='\u54cd\u5e94\u5217\u8868')", "hash": "5cec3f9cf3ad7b6360098a5aeb1669d327dbe1de1dd6a41cceb31f739d5031ba"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tool.def __init__(self, config: ToolConfig):\n    self.config = config\n    entity_name = config.entity_name\n    if entity_name in FUNCTION_TOOL_ENTITIES:\n        self.entity = FunctionToolEntity(FUNCTION_TOOL_ENTITIES[entity_name])\n        self._tool_type = 'function'\n    elif entity_name in STATEFUL_TOOL_ENTITIES:\n        self.entity = STATEFUL_TOOL_ENTITIES[entity_name]()\n        self._tool_type = 'stateful'\n    else:\n        raise Exception(f'Tool entity {entity_name} not found.')", "hash": "f6c40fe0e953db9d47a25c70ef7c8ac61cd6227272a5d826f746dac51ee8a6b5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tool.@property\ndef tool_type(self):\n    return self._tool_type", "hash": "212d20ebf7de7f001ab1cfc5a41006845674656dedd6bf744820ca1ee015c773"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tool.@tool_type.setter\ndef tool_type(self, value):\n    self._tool_type = value", "hash": "ac8d83226879dd6a3891449eeff2ff7bf6c369d55be818491dc335383a623d68"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tool.def call(self, **kwargs):\n    return self.entity.call(**kwargs)", "hash": "52312627902ef99ed1dd352111f306949d6edf2f8f98ba73b3cc9c06430210c2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tool.def need_llm_generate_parameters(self) -> bool:\n    return self.entity.need_llm_generate_parameters()", "hash": "8b79bb590ccc428b4a615f017650f6fd394171eacf85db55fa8190d0f7d251ef"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tool.def need_llm_generate_response(self) -> bool:\n    return self.entity.need_llm_generate_response()", "hash": "5e1bc5d368a4c0bf78d22f36cda07aa695f071cb9e95ddcbefdacc7ebbc81b8d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tool.def has_done(self) -> bool:\n    return self.entity.current_state() == State.DONE", "hash": "19b716b239188e34ea6a77f4345c0780f8e057ad6433f767b8580aee791f335a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tool.config: ToolConfig\nentity: BaseToolEntity\n_tool_type: str", "hash": "2205487513881d34b39b284498d0fb967dbaca6e00dc04608112ebc5d17b2abc"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.def __init__(self):\n    self.tools = {}\n    stack = inspect.stack()\n    caller_frame = stack[1]\n    caller_path = caller_frame.filename\n    caller_dir = os.path.dirname(caller_path)\n    yaml_file_path = os.path.join(caller_dir, YamlPathConfig.tools_yaml_path)\n    tools_yaml_path = yaml_file_path\n    with open(tools_yaml_path, 'r') as f:\n        config_obj = yaml.safe_load(f)\n        for tool_name, tool_config in config_obj['tools'].items():\n            self.tools[tool_name] = Tool(config=ToolConfig(**tool_config))", "hash": "e16c6232928fb85684a698dd8de4114c6e208e7e5a8d8a707148861de5d877a1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.def set_tools_yaml_path(yaml_path: str):\n    if not os.path.isabs(yaml_path):\n        stack = inspect.stack()\n        caller_frame = stack[1]\n        caller_path = caller_frame.filename\n        caller_dir = os.path.dirname(caller_path)\n        full_yaml_path = os.path.join(caller_dir, yaml_path)\n    else:\n        full_yaml_path = yaml_path\n    yaml_dir = os.path.dirname(full_yaml_path)\n    os.makedirs(yaml_dir, exist_ok=True)\n    YamlPathConfig.tools_yaml_path = full_yaml_path", "hash": "b8a8b353b6a2d444690cf2171a45777e43471e557eea741be75b4fce8fc1eb19"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.def get_tool(self, tool_name: str) -> Tool:\n    tool = self.tools.get(tool_name)\n    if tool is None:\n        raise ValueError(f'No tool named {tool_name} found.')\n    return tool", "hash": "605a2126a422f13e5763d5411a32db4794d6e4d65ff16c92130846c91f5a65ba"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.def get_tool_summary(self, tool_name: str) -> str:\n    tool = self.tools.get(tool_name)\n    if tool is None:\n        raise ValueError(f'No tool named {tool_name} found.')\n    return tool.config.summary", "hash": "d90e193ac38043c95e7a026ed8d74c322bc66fe77d737c7a15bfd5a3d53b53e4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.def get_tools_list_summary(self, tools_list: list[str]) -> dict[str, str]:\n    tools_summary = {}\n    for tool_name in tools_list:\n        summary = self.get_tool_summary(tool_name)\n        tools_summary[tool_name] = summary\n    return tools_summary", "hash": "44218e9e8b1e5a9028970ab66126c7cb48d173dfe608a56aca3e6f20aed8bab0"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.tools: dict[str, Tool]", "hash": "403125f652bf562b3d14a384aea93077dc05416e97c078da18cccecfac264b43"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.def __init__(self, config: ToolConfig):\n    self.config = config\n    entity_name = config.entity_name\n    if entity_name in FUNCTION_TOOL_ENTITIES:\n        self.entity = FunctionToolEntity(FUNCTION_TOOL_ENTITIES[entity_name])\n        self._tool_type = 'function'\n    elif entity_name in STATEFUL_TOOL_ENTITIES:\n        self.entity = STATEFUL_TOOL_ENTITIES[entity_name]()\n        self._tool_type = 'stateful'\n    else:\n        raise Exception(f'Tool entity {entity_name} not found.')", "hash": "b320565c9017db3bf68b8ae90afbbd0ef7d09fedbf2533706c2f93819a02809e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.@property\ndef tool_type(self):\n    return self._tool_type", "hash": "065d6b2d22f3715f80cc8ee8ea13a7d580a2c03f1cdecde09a55793abc5d3591"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.@tool_type.setter\ndef tool_type(self, value):\n    self._tool_type = value", "hash": "e6f879fd7efcaffb9ef2636fe6fd3af66d2e687717922141a21446d94e4e6a54"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.def call(self, **kwargs):\n    return self.entity.call(**kwargs)", "hash": "ace2c2d65d42ecfea84513898184dba5032dc6c2c28ce317b44831dea22ba1df"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.def need_llm_generate_parameters(self) -> bool:\n    return self.entity.need_llm_generate_parameters()", "hash": "77d7e1471c98779d6f45f7814519f801355d5e261a943a7104342ddac08840a7"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.def need_llm_generate_response(self) -> bool:\n    return self.entity.need_llm_generate_response()", "hash": "7ca406ef6304563ff27c447f5a01c895d59f10eae5d2e0e96c4b2b27647f9808"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.def has_done(self) -> bool:\n    return self.entity.current_state() == State.DONE", "hash": "e227f5fbc6994afe3b233d7d96a04dcd1bebb512ef3146e6275bb7af73747df4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.def __init__(self):\n    self.tools = {}\n    stack = inspect.stack()\n    caller_frame = stack[1]\n    caller_path = caller_frame.filename\n    caller_dir = os.path.dirname(caller_path)\n    yaml_file_path = os.path.join(caller_dir, YamlPathConfig.tools_yaml_path)\n    tools_yaml_path = yaml_file_path\n    with open(tools_yaml_path, 'r') as f:\n        config_obj = yaml.safe_load(f)\n        for tool_name, tool_config in config_obj['tools'].items():\n            self.tools[tool_name] = Tool(config=ToolConfig(**tool_config))", "hash": "e16c6232928fb85684a698dd8de4114c6e208e7e5a8d8a707148861de5d877a1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.def set_tools_yaml_path(yaml_path: str):\n    if not os.path.isabs(yaml_path):\n        stack = inspect.stack()\n        caller_frame = stack[1]\n        caller_path = caller_frame.filename\n        caller_dir = os.path.dirname(caller_path)\n        full_yaml_path = os.path.join(caller_dir, yaml_path)\n    else:\n        full_yaml_path = yaml_path\n    yaml_dir = os.path.dirname(full_yaml_path)\n    os.makedirs(yaml_dir, exist_ok=True)\n    YamlPathConfig.tools_yaml_path = full_yaml_path", "hash": "b8a8b353b6a2d444690cf2171a45777e43471e557eea741be75b4fce8fc1eb19"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.def get_tool(self, tool_name: str) -> Tool:\n    tool = self.tools.get(tool_name)\n    if tool is None:\n        raise ValueError(f'No tool named {tool_name} found.')\n    return tool", "hash": "605a2126a422f13e5763d5411a32db4794d6e4d65ff16c92130846c91f5a65ba"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.def get_tool_summary(self, tool_name: str) -> str:\n    tool = self.tools.get(tool_name)\n    if tool is None:\n        raise ValueError(f'No tool named {tool_name} found.')\n    return tool.config.summary", "hash": "d90e193ac38043c95e7a026ed8d74c322bc66fe77d737c7a15bfd5a3d53b53e4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "Tools.def get_tools_list_summary(self, tools_list: list[str]) -> dict[str, str]:\n    tools_summary = {}\n    for tool_name in tools_list:\n        summary = self.get_tool_summary(tool_name)\n        tools_summary[tool_name] = summary\n    return tools_summary", "hash": "44218e9e8b1e5a9028970ab66126c7cb48d173dfe608a56aca3e6f20aed8bab0"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "import yaml\nimport os\nimport inspect\nfrom pydantic import BaseModel, Field\nfrom .tool_entity import BaseToolEntity, FunctionToolEntity, State\nfrom .model import Parameter, Response\nfrom .swe_tool_entity import SWEToolEntity\nfrom .example_stateful_tool_entity import ExampleStatefulToolEntity\nfrom ..config import YamlPathConfig\nfrom .da_tool_entity import DAToolEntity", "hash": "7997f83f3d58077803d0b697e7596d5a534c64b5967a6b95e5013862e49340ce"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tools.py", "code_chunk": "FUNCTION_TOOL_ENTITIES = {'code_interpreter': serve_code_interpreter}\nSTATEFUL_TOOL_ENTITIES = {'example_stateful_tool': ExampleStatefulToolEntity, 'swe_tool': SWEToolEntity, 'DAToolEntity': DAToolEntity}", "hash": "12b45d181a93c2ca956ee40dc128c66ed559f01f9b935b41f4d5492f48994fb5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "State.str\nEnum\nIDLE = 'idle'\nRUNNING = 'running'\nDONE = 'done'", "hash": "4368a3fdebb25a857382a1cc3600537f78b32847d41f627bd74d65db628a6b22"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "BaseToolEntity.@abstractmethod\ndef current_state(self):\n    pass", "hash": "d6c86aa9eeaab402f7b9aeed8bfac306520858c56a78edbdb4a6d05dc1d22489"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "BaseToolEntity.@abstractmethod\ndef call(self, **kwargs):\n    pass", "hash": "4744589c32ddab8527df8c40c59279f9ff15c16a5d62d8a85d2abbeb03d57e9e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "BaseToolEntity.@abstractmethod\ndef need_llm_generate_parameters(self) -> bool:\n    pass", "hash": "90a0f8c1347e685ad8e6fadba8719fc68546f2c6cb146cf279bc8a6f44422f38"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "BaseToolEntity.@abstractmethod\ndef need_llm_generate_response(self) -> bool:\n    pass", "hash": "f3a3ecba67f8e1b5798458a604b15c010b2f33eae957d7b89e72c5a781699d76"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "BaseToolEntity.@abstractmethod\ndef is_stateful(self) -> bool:\n    pass", "hash": "ab7489d0730e0555d0609bb4b1fbeb28a8f60c8c66a0e212f5529cc77e42f525"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "BaseToolEntity.ABC", "hash": "3dd5a9a534e3245be10e60877f2834fea19bde05a0e2b33005a21e7df07c6c72"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.def __init__(self, func: callable):\n    self.func = func\n    self.state = State.IDLE\n    self.parameters = {}", "hash": "cc0b5ea58465a41809cafc492ece1ed52b93d39aba19b5dc4e94ee972a30e261"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.def current_state(self):\n    return self.state", "hash": "d4fc7a26bad174684f152c86b03f16493500bb33627ebbac4d6ae459187b49e2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.def need_llm_generate_parameters(self) -> bool:\n    return True", "hash": "fddc53f0b1771343644fffcc344ba87a70f62630b63eaefa56d52f08b74b9e9e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.def need_llm_generate_response(self) -> bool:\n    return True", "hash": "fa1c4c66bb26988a75954ec4559cd68e9ea291bb3f472313b4aa85276a8ad828"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.def is_stateful(self) -> bool:\n    return False", "hash": "7b62c9965873dbc031e8d0a0573990b67593f19a729aec193424cefc73681e92"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.def call(self, **kwargs):\n    if self.state == State.IDLE:\n        self.state = State.RUNNING\n        res = self.func(**kwargs)\n        self.state = State.DONE\n        return res\n    else:\n        raise Exception(f'FunctionTool is in state {self.state}, not {State.IDLE}')", "hash": "f379fcf86fcabea0a4abd89537ce9bf11ecb1d3dc6aa66640a64ed2e2d49fca9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.BaseToolEntity\nparameters: dict[str, any]\nfunc: callable", "hash": "ec982b10fd14e4765052531b2ab1bd349d26d2c8ebb7fadefcf1709f357dd4e5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.@abstractmethod\ndef current_state(self):\n    pass", "hash": "1b7d4f8a6f5e6133c17f2590b75daf1d9f01dc8880ee5705e3783afae1fc58be"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.@abstractmethod\ndef call(self, **kwargs):\n    pass", "hash": "380bc8e3967edfec26f8d501df6e95d999d89747701608823426226fda069b67"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.@abstractmethod\ndef need_llm_generate_parameters(self) -> bool:\n    pass", "hash": "dfc3e7e4450142c8e46cebe7ce52faf0d02b8bb13e9d4829ebe05a28ad10e21b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.@abstractmethod\ndef need_llm_generate_response(self) -> bool:\n    pass", "hash": "23cee498c348e4c9a14ae8b5efc5126ecbca4ea3933f112848dd846974f89288"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.@abstractmethod\ndef is_stateful(self) -> bool:\n    pass", "hash": "d1d61c359914e9d153cb1d2a58a6bbfbeb18652287bd43be4af499ac33f6028d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.def __init__(self, func: callable):\n    self.func = func\n    self.state = State.IDLE\n    self.parameters = {}", "hash": "cc0b5ea58465a41809cafc492ece1ed52b93d39aba19b5dc4e94ee972a30e261"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.def current_state(self):\n    return self.state", "hash": "d4fc7a26bad174684f152c86b03f16493500bb33627ebbac4d6ae459187b49e2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.def need_llm_generate_parameters(self) -> bool:\n    return True", "hash": "fddc53f0b1771343644fffcc344ba87a70f62630b63eaefa56d52f08b74b9e9e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.def need_llm_generate_response(self) -> bool:\n    return True", "hash": "fa1c4c66bb26988a75954ec4559cd68e9ea291bb3f472313b4aa85276a8ad828"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.def is_stateful(self) -> bool:\n    return False", "hash": "7b62c9965873dbc031e8d0a0573990b67593f19a729aec193424cefc73681e92"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "FunctionToolEntity.def call(self, **kwargs):\n    if self.state == State.IDLE:\n        self.state = State.RUNNING\n        res = self.func(**kwargs)\n        self.state = State.DONE\n        return res\n    else:\n        raise Exception(f'FunctionTool is in state {self.state}, not {State.IDLE}')", "hash": "f379fcf86fcabea0a4abd89537ce9bf11ecb1d3dc6aa66640a64ed2e2d49fca9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\assistant\\tools\\tool_entity.py", "code_chunk": "from abc import ABC, abstractmethod\nfrom enum import Enum\nfrom pydantic import BaseModel, Field\nimport os\nimport yaml", "hash": "b393d8845a9788983f616fa5192b3637c61acb526064ee685de8725747305dbd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\base_node.py", "code_chunk": "NodeInput.BaseModel\nfunc_name: str\nfunc_input: BaseModel", "hash": "ab70406d0d2f0731187e3566d44efe07263841f9ef2dbb2fda1bc176e4e4df11"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\base_node.py", "code_chunk": "NodeConfig.BaseModel\nname: str = Field(description='Node \u540d\u79f0')\ndescription: str = Field(default='', description='Node \u63cf\u8ff0')\nfunctions: dict[str, str] = Field(default={}, description='Node \u6240\u6709\u529f\u80fd\u63cf\u8ff0')", "hash": "3bdf57d51fb7fcbb5467ded52eada3adba71b5fb08db5dc339336d22822a7bb1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\base_node.py", "code_chunk": "BaseNode.def __init__(self):\n    self.func_mapping = {}\n    avail_funcs = [func_name for func_name in dir(self) if not func_name.startswith('_')]\n    for func_name in self.config.functions.keys():\n        if func_name not in avail_funcs:\n            raise Exception(f'Node {self.config.name} does not contain {func_name} method.')\n        else:\n            self.func_mapping[func_name] = getattr(self, func_name)", "hash": "0926b21853c64e4a78778c4142efa2d192bfb5cad793450c573b333ffcf9107a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\base_node.py", "code_chunk": "BaseNode.def run(self, input: NodeInput):\n    if input.func_name not in self.func_mapping.keys():\n        raise Exception(f'Node {self.config.name} does not contain {input.func_name} method.')\n    else:\n        return self.func_mapping[input.func_name](input.func_input)", "hash": "ccfc5b0daab472d065f4adc30677dd3bce1d4b110e03dc0b9ff7e9a42f73242c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\base_node.py", "code_chunk": "BaseNode.ABC\nconfig: NodeConfig\nfunc_mapping: dict[str, Callable]", "hash": "f143d063e93e2e2ecf30641458e2817ff15ae834fadf65bedc5c06864b40260f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\base_node.py", "code_chunk": "BaseNode.def __init__(self):\n    self.func_mapping = {}\n    avail_funcs = [func_name for func_name in dir(self) if not func_name.startswith('_')]\n    for func_name in self.config.functions.keys():\n        if func_name not in avail_funcs:\n            raise Exception(f'Node {self.config.name} does not contain {func_name} method.')\n        else:\n            self.func_mapping[func_name] = getattr(self, func_name)", "hash": "0926b21853c64e4a78778c4142efa2d192bfb5cad793450c573b333ffcf9107a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\base_node.py", "code_chunk": "BaseNode.def run(self, input: NodeInput):\n    if input.func_name not in self.func_mapping.keys():\n        raise Exception(f'Node {self.config.name} does not contain {input.func_name} method.')\n    else:\n        return self.func_mapping[input.func_name](input.func_input)", "hash": "ccfc5b0daab472d065f4adc30677dd3bce1d4b110e03dc0b9ff7e9a42f73242c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\base_node.py", "code_chunk": "from typing import Callable\nfrom abc import ABC, abstractmethod\nfrom pydantic import BaseModel, Field", "hash": "58a6205161b216e9d58a106c17f3e3e6de53046995971b62c5ebfd43921b7466"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\__init__.py", "code_chunk": "from .code_runner.code_runner import *\nfrom .code_runner.code_runner_model import *\nfrom .openai.openai import *\nfrom .openai.openai_model import *\nfrom .document_loader.document_loader import *\nfrom .document_loader.document_model import *\nfrom .data_analysis.data_analysis import *\nfrom .data_analysis.data_analysis_model import *\nfrom .git.file_io import *\nfrom .git.file_io_model import *\nfrom .git.git_base_node import *\nfrom .git.git_branch import *\nfrom .git.git_commit import *\nfrom .git.git_repo import *", "hash": "55596bd25fc94924bd117dfa5667106613c3ab5151bde1d8d33b0755892001be"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\code_runner\\code_runner.py", "code_chunk": "CodeRunnerNode.def __init__(self):\n    super().__init__()\n    self.pythonREPL = None", "hash": "d1752dc573d4eb955fd1d458f8e8ce01a77e3db18646fc1f96088add7c20fd2c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\code_runner\\code_runner.py", "code_chunk": "CodeRunnerNode.def run_code(self, input: RunCodeInput):\n    if self.pythonREPL is None:\n        self.init_python_repl()\n    return self.pythonREPL.run(input.code)", "hash": "9bd5b59f2bd1e8cd6b0042ecd2de40834c5cc5f865c2bc4c1355c95e04237934"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\code_runner\\code_runner.py", "code_chunk": "CodeRunnerNode.def run_code_from_file(self, input: RunCodeFromFileInput):\n    working_dir = input.working_dir\n    if ' ' in input.working_dir:\n        working_dir = f'\"{input.working_dir}\"'\n    file_path = input.file_path\n    if ' ' in input.file_path:\n        file_path = f'\"{input.file_path}\"'\n    proc = PythonProcess(working_dir=working_dir, python_file_path=file_path)\n    return proc.run()", "hash": "a2112e1bed028b23b1ba687d2611e904e869dc4eef65815d28ea21411ab2296e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\code_runner\\code_runner.py", "code_chunk": "CodeRunnerNode.def init_python_repl(self, globals_: Optional[dict]=None, locals_: Optional[dict]=None):\n    self.pythonREPL = PythonREPL(globals_, locals_)", "hash": "82d15a581a6647cd7e3dea5fa8667419c43787ad7f59e834ba8d62cf60cac74a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\code_runner\\code_runner.py", "code_chunk": "CodeRunnerNode.BaseNode\nconfig: NodeConfig = NodeConfig(**code_runner_config)\npythonREPL: PythonREPL", "hash": "9aa9de79619af655d297a4a23564c4c8d90026f9e7e21d2c0aed790010256aff"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\code_runner\\code_runner.py", "code_chunk": "CodeRunnerNode.def __init__(self):\n    super().__init__()\n    self.pythonREPL = None", "hash": "d1752dc573d4eb955fd1d458f8e8ce01a77e3db18646fc1f96088add7c20fd2c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\code_runner\\code_runner.py", "code_chunk": "CodeRunnerNode.def run_code(self, input: RunCodeInput):\n    if self.pythonREPL is None:\n        self.init_python_repl()\n    return self.pythonREPL.run(input.code)", "hash": "9bd5b59f2bd1e8cd6b0042ecd2de40834c5cc5f865c2bc4c1355c95e04237934"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\code_runner\\code_runner.py", "code_chunk": "CodeRunnerNode.def run_code_from_file(self, input: RunCodeFromFileInput):\n    working_dir = input.working_dir\n    if ' ' in input.working_dir:\n        working_dir = f'\"{input.working_dir}\"'\n    file_path = input.file_path\n    if ' ' in input.file_path:\n        file_path = f'\"{input.file_path}\"'\n    proc = PythonProcess(working_dir=working_dir, python_file_path=file_path)\n    return proc.run()", "hash": "a2112e1bed028b23b1ba687d2611e904e869dc4eef65815d28ea21411ab2296e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\code_runner\\code_runner.py", "code_chunk": "CodeRunnerNode.def init_python_repl(self, globals_: Optional[dict]=None, locals_: Optional[dict]=None):\n    self.pythonREPL = PythonREPL(globals_, locals_)", "hash": "82d15a581a6647cd7e3dea5fa8667419c43787ad7f59e834ba8d62cf60cac74a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\code_runner\\code_runner.py", "code_chunk": "import ast\nfrom typing import Optional\nfrom ...nodes.base_node import BaseNode, NodeConfig\nfrom ...nodes.code_runner.code_runner_model import RunCodeInput, RunCodeFromFileInput\nfrom ....utils.code_executor.python_process import PythonProcess\nfrom ....utils.code_executor.python_repl import PythonREPL\ncode_runner_config = {'name': 'code_runner', 'description': 'A simple node that run python code.', 'functions': {'run_code': 'Run python code in string format.', 'run_code_from_file': 'Run python code in specific files.'}}", "hash": "6d9b3f998566ea7a958db4d81b352e25354163841a710fcbae7fe5556dea5bfe"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\code_runner\\code_runner_model.py", "code_chunk": "RunCodeInput.BaseModel\ncode: str = Field(description='Python code to be executed.')", "hash": "b3cf5e3cf7f9d52ff05929e139830de903f108d3e6ccf77638a49d59da9a3a42"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\code_runner\\code_runner_model.py", "code_chunk": "RunCodeFromFileInput.BaseModel\nworking_dir: str = Field(description='Working directory for the code.')\nfile_path: str = Field(description='Entry python file to be executed.')\nkwargs: Optional[dict] = Field(default={}, description='Keyword arguments.')", "hash": "5d93ef51ffb471298ab3b98c854f87936ea58fbdb8341c96105993e8d12fb889"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\code_runner\\code_runner_model.py", "code_chunk": "from typing import Optional\nfrom pydantic import BaseModel, Field", "hash": "56d19fb056f49e86c113d889898d366054a00d903dfecd175bf63c107ff1972b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisNode.def __init__(self):\n    super().__init__()\n    self.data = {}", "hash": "d4e50a1d0826203b50d0059bfa4f8436c213ca3b91748303d773d0a295c78c30"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisNode.def load_data_from_file(self, input: UploadFile=File(...), properties: UserProperties=Form(...)):\n    source_path = DEFAULT_DATA_ANALYSIS_FOLDER / properties.user_id / properties.session_id / input.filename\n    source_path.parent.mkdir(parents=True, exist_ok=True)\n    self.user_properties = properties\n    with open(source_path, 'wb') as buffer:\n        buffer.write(input.file.read())\n    load_data_input = LoadDataInput(source_type=input.filename.split('.')[-1].lower(), source_path=str(source_path))\n    return self.load_data(load_data_input=load_data_input)", "hash": "ed7ab63cae8f0c65c78e573343861a851c3a593809c0c569fa81c50f88983e37"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisNode.def load_data(self, input: LoadDataInput):\n    if input.name is None:\n        input.name = input.source_path.split('/')[-1].split('.')[0]\n    try:\n        if input.source_type == 'csv':\n            self.data[input.name] = pd.read_csv(input.source_path)\n        elif input.source_type == 'json':\n            self.data[input.name] = pd.read_json(input.source_path)\n        else:\n            self.data[input.name] = input.source_path\n        return f'Data loaded successfully.'\n    except Exception as e:\n        return f'An error occurred while loading the data: {e}'", "hash": "0274b71cc9254f4dfb16e6de1356d9a1a379a927d0cbf0c1fdbcbc4f646359fd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisNode.def clean_data(self, input: CleanDataInput):\n    try:\n        if input.name in self.data.keys():\n            return 'No data loaded to clean.'\n        if input.drop_columns:\n            self.data[input.name].drop(columns=input.drop_columns, inplace=True)\n        if input.fill_na:\n            self.data[input.name].fillna(value=input.fill_na, inplace=True)\n        return 'Data cleaned successfully.'\n    except Exception as e:\n        return f'An error occurred while cleaning the data: {e}'", "hash": "aa8ccc4b2242e120b2dabc91d2d9d532b2f3fdb08b9c4153dfcd0c2ad948a91e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisNode.BaseNode\nconfig: NodeConfig = NodeConfig(**data_analysis_node_config)\ndata: dict[str, pd.DataFrame | str] = None\nuser_properties = None", "hash": "ce13d9379ae554ee84c98912dcb33630ab13042f5bb02914aa6f8179a602603a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisNode.def __init__(self):\n    super().__init__()\n    self.data = {}", "hash": "d4e50a1d0826203b50d0059bfa4f8436c213ca3b91748303d773d0a295c78c30"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisNode.def load_data_from_file(self, input: UploadFile=File(...), properties: UserProperties=Form(...)):\n    source_path = DEFAULT_DATA_ANALYSIS_FOLDER / properties.user_id / properties.session_id / input.filename\n    source_path.parent.mkdir(parents=True, exist_ok=True)\n    self.user_properties = properties\n    with open(source_path, 'wb') as buffer:\n        buffer.write(input.file.read())\n    load_data_input = LoadDataInput(source_type=input.filename.split('.')[-1].lower(), source_path=str(source_path))\n    return self.load_data(load_data_input=load_data_input)", "hash": "ed7ab63cae8f0c65c78e573343861a851c3a593809c0c569fa81c50f88983e37"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisNode.def load_data(self, input: LoadDataInput):\n    if input.name is None:\n        input.name = input.source_path.split('/')[-1].split('.')[0]\n    try:\n        if input.source_type == 'csv':\n            self.data[input.name] = pd.read_csv(input.source_path)\n        elif input.source_type == 'json':\n            self.data[input.name] = pd.read_json(input.source_path)\n        else:\n            self.data[input.name] = input.source_path\n        return f'Data loaded successfully.'\n    except Exception as e:\n        return f'An error occurred while loading the data: {e}'", "hash": "0274b71cc9254f4dfb16e6de1356d9a1a379a927d0cbf0c1fdbcbc4f646359fd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\data_analysis\\data_analysis.py", "code_chunk": "DataAnalysisNode.def clean_data(self, input: CleanDataInput):\n    try:\n        if input.name in self.data.keys():\n            return 'No data loaded to clean.'\n        if input.drop_columns:\n            self.data[input.name].drop(columns=input.drop_columns, inplace=True)\n        if input.fill_na:\n            self.data[input.name].fillna(value=input.fill_na, inplace=True)\n        return 'Data cleaned successfully.'\n    except Exception as e:\n        return f'An error occurred while cleaning the data: {e}'", "hash": "aa8ccc4b2242e120b2dabc91d2d9d532b2f3fdb08b9c4153dfcd0c2ad948a91e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\data_analysis\\data_analysis.py", "code_chunk": "from fastapi import UploadFile, File, Form\nfrom typing import Optional\nimport pandas as pd\nfrom ..base_node import BaseNode, NodeConfig\nfrom .data_analysis_model import LoadDataInput, CleanDataInput\nfrom ...common_models import UserProperties, DEFAULT_DATA_ANALYSIS_FOLDER\ndata_analysis_node_config = {'name': 'data_analysis', 'description': 'A node for data analysis tasks.', 'functions': {'load_data_from_file': 'Load data from a given file.', 'load_data': 'Load data from a given source.', 'clean_data': 'Clean the loaded data.'}}", "hash": "d0e8f9ad03d335e46ddae8bef3a100bd2911475eecf7dfd9bf76e663b2c14e20"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\data_analysis\\data_analysis_model.py", "code_chunk": "LoadDataInput.BaseModel\nname: Optional[str]\nsource_type: str\nsource_path: str", "hash": "efaa4df41088a02895e8e27201a8d857a699dbb389f2fe9902ee38a2f478fef8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\data_analysis\\data_analysis_model.py", "code_chunk": "CleanDataInput.BaseModel\nname: str\ndrop_columns: Optional[List[str]]\nfill_na: Optional[Dict[str, Union[str, float, int]]]", "hash": "b3ca573e878e56d00123abe0414970ee60fd87a37190700f536f340543381319"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\data_analysis\\data_analysis_model.py", "code_chunk": "from pydantic import BaseModel\nfrom typing import List, Dict, Union, Optional", "hash": "1f81e588ca103f3d88bb52d046700829eab106742ce0a4bf01d926374fa5c677"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "DocumentLoaderNode.def __init__(self):\n    super().__init__()\n    self.redis = Redis()", "hash": "d91ea09579d0fb31e8981865d24d158b6c96fa613f2e1d32b4490a192c5df766"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "DocumentLoaderNode.def create_document_from_file(self, input: UploadFile=File(...), properties: UserProperties=Form(...)):\n    document = Document.create_document_from_file(input, properties)\n    return self.process_document(document)", "hash": "d8a8cd4d92aa5249308fba824b800adace61b5f7a7bd31dc58c394a2d2c39be3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "DocumentLoaderNode.def create_document_from_url(self, input: UrlDocumentInput, properties: UserProperties=Form(...)):\n    document = Document.create_document_from_url(input, properties)\n    return self.process_document(document)", "hash": "98ba91894209e25ed4fa28c73ecce6bb93ceaa60024949cd9661da573df7e3ad"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "DocumentLoaderNode.def split_documents(self, input: SplitDocumentInput):\n    if input.file_id is None and input.document is None:\n        logger.error('Either file_id or document must be provided.')\n        return None\n    elif input.file_id is not None:\n        logger.debug(f'Spliting documents for: {input.file_id}')\n        for doc_json in self.redis.safe_get_with_key_type(input.user_properties, RedisKeyType.DOCUMENTS):\n            doc = Document(**json.loads(doc_json))\n            if doc.file_id == input.file_id:\n                return self._split_documents(doc, input.chunk_size, input.chunk_overlap)\n        return None\n    elif input.document is not None:\n        return self._split_documents(input.document, input.chunk_size, input.chunk_overlap)\n    else:\n        raise ValueError('Unknown error')", "hash": "8cf99ab32a2c7b4edf52aa794a0c6b9059c2fe23f32942037ece23b25d8d7fbd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "DocumentLoaderNode.def process_document(self, input: Document):\n    \"\"\"\n        Process the file to compute the documents\n\n        Args:\n            input (Document): The document to process\n            save_redis (bool, optional): Whether to save the document to Redis. Defaults to True.\n        \"\"\"\n    file_path = str(input.file_path)\n    if input.file_extension == 'csv':\n        loader = CSVLoader(file_path)\n    elif input.file_extension == 'docx':\n        loader = Docx2txtLoader(file_path)\n    elif input.file_extension == 'pdf':\n        loader = PyMuPDFLoader(file_path)\n    elif input.file_extension == 'txt':\n        loader = TextLoader(file_path)\n    elif input.file_extension == 'web':\n        loader = WebBaseLoader(input.file_name)\n    elif input.file_extension == 'git':\n        repo_path = input.file_path\n        repo_path_str = str(repo_path) + '/'\n        repo_path.parent.mkdir(parents=True, exist_ok=True)\n        repo = Repo.clone_from(input.file_name, repo_path_str)\n        branch = repo.head.reference\n        gitignore_file = os.path.join(repo_path_str, '.gitignore')\n        if os.path.exists(gitignore_file):\n            os.remove(gitignore_file)\n        with open(gitignore_file, 'w') as fp:\n            pass\n        loader = GitLoader(repo_path=repo_path_str, branch=branch)\n    elif input.file_extension == 'json':\n        pass\n    else:\n        raise ValueError(f'Unsupported file extension: {input.file_extension}')\n    documents = loader.load()\n    input.documents = documents\n    if not self.redis.exists_with_key_type(input.user_properties, RedisKeyType.DOCUMENTS):\n        logger.debug(f'Creating new knowledge base for {input.user_properties.user_id}:{input.user_properties.session_id} in Redis.')\n        self.redis.safe_set_with_key_type(input.user_properties, RedisKeyType.DOCUMENTS, [])\n    new_documents = self.redis.safe_get_with_key_type(input.user_properties, RedisKeyType.DOCUMENTS)\n    new_documents.append(input.json())\n    self.redis.safe_set_with_key_type(input.user_properties, RedisKeyType.DOCUMENTS, new_documents)\n    return input.json()", "hash": "29d3a50d46863bd61d416f8a5ce5a054b63708d87833ddc6169a87af424546d4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "DocumentLoaderNode.def remove_document(self, input: Document):\n    if input.file_path is not None:\n        if os.path.isfile(input.file_path):\n            os.remove(input.file_path)\n        elif os.path.isdir(input.file_path):\n            shutil.rmtree(input.file_path)\n    type = RedisKeyType.DOCUMENTS\n    if not self.redis.exists_with_key_type(input.user_properties, type):\n        logger.error(f'Document {input.file_name} does not exist.')\n        return\n    all_documents = self.redis.safe_get_with_key_type(input.user_properties, type)\n    processed_documents = []\n    for doc_json in all_documents:\n        doc = Document(**json.loads(doc_json))\n        if doc.file_id != input.file_id:\n            processed_documents.append(doc_json)\n    self.redis.safe_set_with_key_type(input.user_properties, type, processed_documents)", "hash": "0935a860d3eb06cc8be45ebcb7ecea2500bdce41d86c0f48ad200d50eefb7a55"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "DocumentLoaderNode.def _split_documents(self, input: Document, chunk_size: Optional[int]=500, chunk_overlap: Optional[int]=0):\n    \"\"\"\n        Split the documents from the file\n        \"\"\"\n    logger.debug(f'Spliting documents from file {input.file_name}')\n    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n    documents = text_splitter.split_documents(input.documents)\n    return documents", "hash": "ae6d72364ddd53d6b88be03df9ffff94a350ab7cb98458ab58ab0e4d9f6ad92f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "DocumentLoaderNode.BaseNode\nconfig: NodeConfig = NodeConfig(**document_loader_config)", "hash": "152837c056010f80fd001a8e7f29c381cf8245a021df33c1d20e061a1cf38c65"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "DocumentLoaderNode.def __init__(self):\n    super().__init__()\n    self.redis = Redis()", "hash": "d91ea09579d0fb31e8981865d24d158b6c96fa613f2e1d32b4490a192c5df766"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "DocumentLoaderNode.def create_document_from_file(self, input: UploadFile=File(...), properties: UserProperties=Form(...)):\n    document = Document.create_document_from_file(input, properties)\n    return self.process_document(document)", "hash": "d8a8cd4d92aa5249308fba824b800adace61b5f7a7bd31dc58c394a2d2c39be3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "DocumentLoaderNode.def create_document_from_url(self, input: UrlDocumentInput, properties: UserProperties=Form(...)):\n    document = Document.create_document_from_url(input, properties)\n    return self.process_document(document)", "hash": "98ba91894209e25ed4fa28c73ecce6bb93ceaa60024949cd9661da573df7e3ad"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "DocumentLoaderNode.def split_documents(self, input: SplitDocumentInput):\n    if input.file_id is None and input.document is None:\n        logger.error('Either file_id or document must be provided.')\n        return None\n    elif input.file_id is not None:\n        logger.debug(f'Spliting documents for: {input.file_id}')\n        for doc_json in self.redis.safe_get_with_key_type(input.user_properties, RedisKeyType.DOCUMENTS):\n            doc = Document(**json.loads(doc_json))\n            if doc.file_id == input.file_id:\n                return self._split_documents(doc, input.chunk_size, input.chunk_overlap)\n        return None\n    elif input.document is not None:\n        return self._split_documents(input.document, input.chunk_size, input.chunk_overlap)\n    else:\n        raise ValueError('Unknown error')", "hash": "8cf99ab32a2c7b4edf52aa794a0c6b9059c2fe23f32942037ece23b25d8d7fbd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "DocumentLoaderNode.def process_document(self, input: Document):\n    \"\"\"\n        Process the file to compute the documents\n\n        Args:\n            input (Document): The document to process\n            save_redis (bool, optional): Whether to save the document to Redis. Defaults to True.\n        \"\"\"\n    file_path = str(input.file_path)\n    if input.file_extension == 'csv':\n        loader = CSVLoader(file_path)\n    elif input.file_extension == 'docx':\n        loader = Docx2txtLoader(file_path)\n    elif input.file_extension == 'pdf':\n        loader = PyMuPDFLoader(file_path)\n    elif input.file_extension == 'txt':\n        loader = TextLoader(file_path)\n    elif input.file_extension == 'web':\n        loader = WebBaseLoader(input.file_name)\n    elif input.file_extension == 'git':\n        repo_path = input.file_path\n        repo_path_str = str(repo_path) + '/'\n        repo_path.parent.mkdir(parents=True, exist_ok=True)\n        repo = Repo.clone_from(input.file_name, repo_path_str)\n        branch = repo.head.reference\n        gitignore_file = os.path.join(repo_path_str, '.gitignore')\n        if os.path.exists(gitignore_file):\n            os.remove(gitignore_file)\n        with open(gitignore_file, 'w') as fp:\n            pass\n        loader = GitLoader(repo_path=repo_path_str, branch=branch)\n    elif input.file_extension == 'json':\n        pass\n    else:\n        raise ValueError(f'Unsupported file extension: {input.file_extension}')\n    documents = loader.load()\n    input.documents = documents\n    if not self.redis.exists_with_key_type(input.user_properties, RedisKeyType.DOCUMENTS):\n        logger.debug(f'Creating new knowledge base for {input.user_properties.user_id}:{input.user_properties.session_id} in Redis.')\n        self.redis.safe_set_with_key_type(input.user_properties, RedisKeyType.DOCUMENTS, [])\n    new_documents = self.redis.safe_get_with_key_type(input.user_properties, RedisKeyType.DOCUMENTS)\n    new_documents.append(input.json())\n    self.redis.safe_set_with_key_type(input.user_properties, RedisKeyType.DOCUMENTS, new_documents)\n    return input.json()", "hash": "29d3a50d46863bd61d416f8a5ce5a054b63708d87833ddc6169a87af424546d4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "DocumentLoaderNode.def remove_document(self, input: Document):\n    if input.file_path is not None:\n        if os.path.isfile(input.file_path):\n            os.remove(input.file_path)\n        elif os.path.isdir(input.file_path):\n            shutil.rmtree(input.file_path)\n    type = RedisKeyType.DOCUMENTS\n    if not self.redis.exists_with_key_type(input.user_properties, type):\n        logger.error(f'Document {input.file_name} does not exist.')\n        return\n    all_documents = self.redis.safe_get_with_key_type(input.user_properties, type)\n    processed_documents = []\n    for doc_json in all_documents:\n        doc = Document(**json.loads(doc_json))\n        if doc.file_id != input.file_id:\n            processed_documents.append(doc_json)\n    self.redis.safe_set_with_key_type(input.user_properties, type, processed_documents)", "hash": "0935a860d3eb06cc8be45ebcb7ecea2500bdce41d86c0f48ad200d50eefb7a55"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "DocumentLoaderNode.def _split_documents(self, input: Document, chunk_size: Optional[int]=500, chunk_overlap: Optional[int]=0):\n    \"\"\"\n        Split the documents from the file\n        \"\"\"\n    logger.debug(f'Spliting documents from file {input.file_name}')\n    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n    documents = text_splitter.split_documents(input.documents)\n    return documents", "hash": "ae6d72364ddd53d6b88be03df9ffff94a350ab7cb98458ab58ab0e4d9f6ad92f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_loader.py", "code_chunk": "from fastapi import UploadFile, File, Form\nfrom typing import Optional, Union\nfrom pathlib import Path\nfrom git import Repo\nfrom langchain.document_loaders import CSVLoader\nfrom langchain.document_loaders import Docx2txtLoader\nfrom langchain.document_loaders import PyMuPDFLoader\nfrom langchain.document_loaders import TextLoader\nfrom langchain.document_loaders import GitLoader\nfrom langchain.document_loaders import WebBaseLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nimport json\nimport os\nimport shutil\nfrom .document_model import Document, SplitDocumentInput, UrlDocumentInput\nfrom ...common_models import UserProperties, RedisKeyType, DEFAULT_USER_ID, DEFAULT_SESSION_ID, DEFAULT_GIT_FOLDER\nfrom ..base_node import BaseNode, NodeConfig\nfrom ...service.redis import Redis\nfrom ....utils.logger import get_logger\nlogger = get_logger(__name__)\ndocument_loader_config = {'name': 'document_loader', 'description': 'A node that is capable of reading various document types. Redis key format would be user_id:session_id:documents', 'functions': {'create_document_from_file': 'Create a document from a given file.', 'create_document_from_url': 'Create a document from a given URL.', 'split_documents': 'Split the documents from the file with default chunk size and overlap.', 'process_document': \"Process the file's content into text\", 'remove_document': 'Remove the document from the Redis and local.'}}", "hash": "3cfd0b0eae18f015e8f8f7f4a8e29e98840f082fe7df935cc781c0f7d90cb939"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_model.py", "code_chunk": "UrlDocumentInput.BaseModel\nurl: str = Field(description='Url for generating documents')\ntype: str = Field(description='Type of loader used for this url')", "hash": "349cfc6da990f3af0f60f92c592ede83685f0b08254c688d1ec422a550dff473"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_model.py", "code_chunk": "Document.def __init__(self, **kwargs):\n    \"\"\"\n        Initializes a new Document object.\n\n        Args:\n            input (UploadFile): The uploaded file.\n        \"\"\"\n    super().__init__(**kwargs)", "hash": "112f285dfe0b04e7c8715e4ad577e3ba7bd39582e1a305937839aaf2f6251677"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_model.py", "code_chunk": "Document.@classmethod\ndef create_document_from_file(cls, input: UploadFile, properties: UserProperties):\n    \"\"\"\n        Creates a new Document object from an UploadFile input.\n\n        Args:\n            input (UploadFile): The uploaded file.\n\n        Returns:\n            Document: A new Document object.\n        \"\"\"\n    current_time = datetime.now().strftime(TIME_STRING_FORMAT)\n    file_name = f'{current_time}-{input.filename}'\n    file_path = DEFAULT_DOCUMENTS_FOLDER / properties.user_id / properties.session_id / file_name\n    file_path.parent.mkdir(parents=True, exist_ok=True)\n    with open(file_path, 'wb') as f:\n        f.write(input.file.read())\n    file_id = hashlib.sha256(f'{properties.user_id}-{properties.session_id}-{file_name}'.encode()).hexdigest()\n    file_extension = file_name.split('.')[-1].lower()\n    file_size = input.file._file.tell()\n    creation_time = current_time\n    return cls(user_properties=UserProperties(**properties.dict()), file_id=file_id, file_path=file_path, file_name=file_name, file_extension=file_extension, file_size=file_size, creation_time=creation_time)", "hash": "4ffdf902382159cd22b2d65ed47ea348fbb65d4f61ee2cfd798d619ffc406841"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_model.py", "code_chunk": "Document.@classmethod\ndef create_document_from_url(cls, input: UrlDocumentInput, properties: UserProperties):\n    current_time = datetime.now().strftime(TIME_STRING_FORMAT)\n    file_name = input.url\n    file_id = hashlib.sha256(f'{properties.user_id}-{properties.session_id}-{file_name}'.encode()).hexdigest()\n    file_path = None\n    file_extension = input.type\n    creation_time = current_time\n    if input.type == 'git':\n        file_path = DEFAULT_GIT_FOLDER / properties.user_id / properties.session_id / input.url.split('/')[-1]\n        file_path.parent.mkdir(parents=True, exist_ok=True)\n    return cls(user_properties=UserProperties(**properties.dict()), file_id=file_id, file_name=file_name, file_path=file_path, file_extension=file_extension, creation_time=creation_time)", "hash": "98d0a7472dfa012fff02d9fd36232c656d3a0694737a80a59fdd67adbd90d96d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_model.py", "code_chunk": "Document.BaseModel\nuser_properties: Optional[UserProperties] = Field(UserProperties(), description='User properties.')\nfile_id: Optional[str] = Field(None, description='The ID of the uploaded file, generated using the user ID, session ID, and file name.')\nfile_path: Optional[Path] = Field(None, description='The path to the uploaded file.')\nfile_name: Optional[str] = Field(None, description='The name of the uploaded file, including the timestamp of the upload.')\nfile_extension: Optional[str] = Field('', description='The extension of the uploaded file.')\nfile_size: Optional[int] = Field(None, description='The size of the uploaded file in bytes.')\ncreation_time: Optional[str] = Field(None, description=\"The timestamp of the upload in the format 'YYYY-MM-DD-HH:MM:SS'.\")\ndocuments: Optional[List[LangchainDocument]] = Field([], description='A list of LangchainDocument objects representing the uploaded file.')", "hash": "b25ab4f8125957031ad90fe5e486fbefec9591e30d7642f7f8ba81ad6487af04"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_model.py", "code_chunk": "SplitDocumentInput.BaseModel\nuser_properties: Optional[UserProperties] = UserProperties()\nfile_id: Optional[str] = None\nchunk_size: Optional[int] = 500\nchunk_overlap: Optional[int] = 0\ndocument: Optional[Document] = None", "hash": "8b2d5790efeefe8aa2b5df7cde1544b97f9d9b395556d9feb27ac6d6c975a7ac"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_model.py", "code_chunk": "SplitDocumentInput.def __init__(self, **kwargs):\n    \"\"\"\n        Initializes a new Document object.\n\n        Args:\n            input (UploadFile): The uploaded file.\n        \"\"\"\n    super().__init__(**kwargs)", "hash": "1651f439a7a5f13461dde71bff664b7d28b832217504c123782f3e45774c1b8a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_model.py", "code_chunk": "SplitDocumentInput.@classmethod\ndef create_document_from_file(cls, input: UploadFile, properties: UserProperties):\n    \"\"\"\n        Creates a new Document object from an UploadFile input.\n\n        Args:\n            input (UploadFile): The uploaded file.\n\n        Returns:\n            Document: A new Document object.\n        \"\"\"\n    current_time = datetime.now().strftime(TIME_STRING_FORMAT)\n    file_name = f'{current_time}-{input.filename}'\n    file_path = DEFAULT_DOCUMENTS_FOLDER / properties.user_id / properties.session_id / file_name\n    file_path.parent.mkdir(parents=True, exist_ok=True)\n    with open(file_path, 'wb') as f:\n        f.write(input.file.read())\n    file_id = hashlib.sha256(f'{properties.user_id}-{properties.session_id}-{file_name}'.encode()).hexdigest()\n    file_extension = file_name.split('.')[-1].lower()\n    file_size = input.file._file.tell()\n    creation_time = current_time\n    return cls(user_properties=UserProperties(**properties.dict()), file_id=file_id, file_path=file_path, file_name=file_name, file_extension=file_extension, file_size=file_size, creation_time=creation_time)", "hash": "2625283a56173c463063cfcab025c3b1568f8345564ad156626f6b6d676f1692"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_model.py", "code_chunk": "SplitDocumentInput.@classmethod\ndef create_document_from_url(cls, input: UrlDocumentInput, properties: UserProperties):\n    current_time = datetime.now().strftime(TIME_STRING_FORMAT)\n    file_name = input.url\n    file_id = hashlib.sha256(f'{properties.user_id}-{properties.session_id}-{file_name}'.encode()).hexdigest()\n    file_path = None\n    file_extension = input.type\n    creation_time = current_time\n    if input.type == 'git':\n        file_path = DEFAULT_GIT_FOLDER / properties.user_id / properties.session_id / input.url.split('/')[-1]\n        file_path.parent.mkdir(parents=True, exist_ok=True)\n    return cls(user_properties=UserProperties(**properties.dict()), file_id=file_id, file_name=file_name, file_path=file_path, file_extension=file_extension, creation_time=creation_time)", "hash": "05b8e89f888fc8cf01c7772d34e4b41f49eebefb687645470fa1fda93a2900cc"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\document_loader\\document_model.py", "code_chunk": "from pydantic import BaseModel, Field\nfrom fastapi import UploadFile, File\nfrom typing import List, Any, Optional\nfrom langchain.docstore.document import Document as LangchainDocument\nfrom pathlib import Path\nfrom datetime import datetime\nimport hashlib\nfrom ....utils.logger import get_logger\nfrom ...common_models import UserProperties, DEFAULT_DOCUMENTS_FOLDER, DEFAULT_GIT_FOLDER, TIME_STRING_FORMAT\nlogger = get_logger(__name__)", "hash": "75a8ba21cff72ef08dc9176386e416cb1adc9108207923751b53b0b1bb12a871"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io.py", "code_chunk": "FileIONode.def create_file(self, input: FileInput):\n    file_path = Path(input.path)\n    try:\n        file_path.parents[0].mkdir(parents=True, exist_ok=True)\n        Path(file_path).touch()\n        return {'status': f'File {str(file_path)} created successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "8f672665f77bfcbbd3d3aa649ac59287e57f6da4c3bce4a5024ae80349e550c3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io.py", "code_chunk": "FileIONode.def create_file_with_content(self, input: EditFileInput):\n    file_path = Path(input.path)\n    try:\n        file_path.parents[0].mkdir(parents=True, exist_ok=True)\n        Path(file_path).touch()\n        with file_path.open('w', encoding='utf-8') as f:\n            f.write(input.content)\n        return {'status': f'File {str(file_path)} created successfully with given content.'}\n    except Exception as e:\n        return str(e)", "hash": "3fd4a70d83b6a48f4a6c86cf2c1b9a602a54b77b24833ac0ee85a1fcb67205cb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io.py", "code_chunk": "FileIONode.def delete_file(self, input: FileInput):\n    file_path = Path(input.path)\n    try:\n        file_path.parents[0].mkdir(parents=True, exist_ok=True)\n        Path(file_path).unlink()\n        return {'status': f'File {str(file_path)} deleted successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "10e57505de01afd3667774c64da69d56502711ff7a19d839441949ae7f2abce5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io.py", "code_chunk": "FileIONode.def create_directory(self, input: DirectoryInput):\n    file_path = Path(input.path)\n    try:\n        file_path.mkdir(parents=True, exist_ok=True)\n        return {'status': f'Directory {str(file_path)} created successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "b9678b558b2c3c76af939c9e865859c8cf70e56e332f8b62698e1a9414cd657a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io.py", "code_chunk": "FileIONode.def edit_file_line(self, input: EditFileLineInput):\n    file_path = Path(input.path)\n    lines = []\n    changed = []\n    unchanged = []\n    try:\n        with open(file_path, 'r') as file:\n            lines = file.readlines()\n        for k, v in input.change_list.items():\n            if 0 <= k < len(lines):\n                lines[k] = v\n                changed.appned(k)\n            else:\n                unchanged.append(k)\n        with open(file_path, 'w') as file:\n            file.writelines(lines)\n        return {'status': f'File {str(file_path)} changed successfully, lines {str(changed)} changed, lines {str(unchanged)} unchanged.'}\n    except Exception as e:\n        return str(e)", "hash": "f59b97e3d7ca834a445121a62ebedca3a23a956fc42c31c40462bf17bf43e3ca"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io.py", "code_chunk": "FileIONode.GitBaseNode\nconfig: NodeConfig = NodeConfig(**file_io_node_config)\nedit_file = create_file_with_content", "hash": "9327a57ba6e299751005c30114ebb6ee7e2a9080c3d8bdbf83cb5277f1765964"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io.py", "code_chunk": "FileIONode.def create_file(self, input: FileInput):\n    file_path = Path(input.path)\n    try:\n        file_path.parents[0].mkdir(parents=True, exist_ok=True)\n        Path(file_path).touch()\n        return {'status': f'File {str(file_path)} created successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "8f672665f77bfcbbd3d3aa649ac59287e57f6da4c3bce4a5024ae80349e550c3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io.py", "code_chunk": "FileIONode.def create_file_with_content(self, input: EditFileInput):\n    file_path = Path(input.path)\n    try:\n        file_path.parents[0].mkdir(parents=True, exist_ok=True)\n        Path(file_path).touch()\n        with file_path.open('w', encoding='utf-8') as f:\n            f.write(input.content)\n        return {'status': f'File {str(file_path)} created successfully with given content.'}\n    except Exception as e:\n        return str(e)", "hash": "3fd4a70d83b6a48f4a6c86cf2c1b9a602a54b77b24833ac0ee85a1fcb67205cb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io.py", "code_chunk": "FileIONode.def delete_file(self, input: FileInput):\n    file_path = Path(input.path)\n    try:\n        file_path.parents[0].mkdir(parents=True, exist_ok=True)\n        Path(file_path).unlink()\n        return {'status': f'File {str(file_path)} deleted successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "10e57505de01afd3667774c64da69d56502711ff7a19d839441949ae7f2abce5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io.py", "code_chunk": "FileIONode.def create_directory(self, input: DirectoryInput):\n    file_path = Path(input.path)\n    try:\n        file_path.mkdir(parents=True, exist_ok=True)\n        return {'status': f'Directory {str(file_path)} created successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "b9678b558b2c3c76af939c9e865859c8cf70e56e332f8b62698e1a9414cd657a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io.py", "code_chunk": "FileIONode.def edit_file_line(self, input: EditFileLineInput):\n    file_path = Path(input.path)\n    lines = []\n    changed = []\n    unchanged = []\n    try:\n        with open(file_path, 'r') as file:\n            lines = file.readlines()\n        for k, v in input.change_list.items():\n            if 0 <= k < len(lines):\n                lines[k] = v\n                changed.appned(k)\n            else:\n                unchanged.append(k)\n        with open(file_path, 'w') as file:\n            file.writelines(lines)\n        return {'status': f'File {str(file_path)} changed successfully, lines {str(changed)} changed, lines {str(unchanged)} unchanged.'}\n    except Exception as e:\n        return str(e)", "hash": "f59b97e3d7ca834a445121a62ebedca3a23a956fc42c31c40462bf17bf43e3ca"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io.py", "code_chunk": "from pathlib import Path\nfrom ..base_node import BaseNode, NodeConfig\nfrom .git_base_node import GitBaseNode\nfrom .file_io_model import FileInput, DirectoryInput, EditFileInput, EditFileLineInput\nfile_io_node_config = {'name': 'file_io', 'description': 'A node that implements common file operations.', 'functions': {'create_file': 'Create a file.', 'create_file_with_content': 'Create a file with given content.', 'delete_file': 'Delete a file.', 'create_directory': 'Create a directory.', 'edit_file': 'Edit a file.', 'edit_file_line': 'Edit a line of a file.'}}", "hash": "826f391906486c3f0498e36512e9043b2a401b4a3a47519020d0c192b5a6141a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io_model.py", "code_chunk": "FileInput.BaseModel\npath: str", "hash": "a83e77324dfa1f5a91000b23cf7f57108d7a6c1fc2e37fc0de2ace3e866b3aff"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io_model.py", "code_chunk": "DirectoryInput.BaseModel\npath: str", "hash": "d7d7696500bf0e312dd3aaaeffb4008544bc2497de9ed55aaedc35fc79d0b95e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io_model.py", "code_chunk": "EditFileInput.FileInput\ncontent: str", "hash": "60bdaddd27766e6955f51bad58234f889a93f3496598c20cde38ff55c9fca7f1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io_model.py", "code_chunk": "EditFileLineInput.FileInput\nchange_list: list[int, str]", "hash": "f74f64a37678f232cf28c9ca89c96a21549af8d6404cc36a91e7c37285005496"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\file_io_model.py", "code_chunk": "from pydantic import BaseModel", "hash": "53e9ae3004adfb698e588da99de888895a8596f0d374190839a88872b80eae9d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_base_node.py", "code_chunk": "GitBaseNode.def __init__(self):\n    self.g = git\n    self.r = git.Repo\n    super().__init__()", "hash": "7276b325e1eb9282b635ff9543a46a67df5598cef800f5a096c96287a627daf9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_base_node.py", "code_chunk": "GitBaseNode.BaseNode", "hash": "89f63069dddd75b89275f51011282e1bb0c1dfb462a9c6d96dc48bc88619b842"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_base_node.py", "code_chunk": "GitBaseNode.def __init__(self):\n    self.g = git\n    self.r = git.Repo\n    super().__init__()", "hash": "7276b325e1eb9282b635ff9543a46a67df5598cef800f5a096c96287a627daf9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_base_node.py", "code_chunk": "import git\nfrom ..base_node import BaseNode", "hash": "9d899e71d1b03cac660a49eb109fad420de50eb4655bb2fd3d78e7ab0aedbd85"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "def formatGitCommit(commit: Commit):\n    return {'repo': str(commit.repo), 'hexsha': commit.hexsha, 'author': commit.author, 'message': commit.message, 'summary': commit.summary, 'datetime': commit.committed_datetime}", "hash": "070de7b8d1193c5cd962d0fc85601b8f0308815a0d743786f42faf7f0b1e9381"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def get_git_branch_list(self, input: GitRepositoryInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        repo_heads_names = [h.name for h in repo.heads]\n        return {'branch': repo_heads_names}\n    except Exception as e:\n        return str(e)", "hash": "d62663d7fd9e0a31c3d44f224df954b6a36246f54268127b7802813825aea4de"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_switch_branch(self, input: GitBranchInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        repo.git.checkout(input.branch_name)\n        return {'status': f'Successfully checkout git branch {input.branch_name}.'}\n    except Exception as e:\n        return str(e)", "hash": "3a6eeba6f33a6805fdebfdba9e410dc0cc20181e54b9ea4219c3695d9beeb2a2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_log_raw(self, input: GitRepositoryInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        log_content = repo.git.log()\n        return {'log': log_content}\n    except Exception as e:\n        return str(e)", "hash": "697990236afc26c7a7b5be3e4f2b7a4b4681a6e95075f593ddb562d1a34fae55"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_log(self, input: GitRepositoryInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        log_content = repo.git.log()\n        return {'log': log_content}\n    except Exception as e:\n        return str(e)", "hash": "cc22deb21100976e8a7f2c5ed3284fcb71b46d071bbc8ec0a2c62b35adfad6c1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_log_commit_topk(self, input: GitRepositoryInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        log_content = repo.git.log()\n        return {'log': log_content}\n    except Exception as e:\n        return str(e)", "hash": "50694db1a3715bca7722d208f1f7f6093123c210a231449f88dbdde975d5377f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_pull(self, input: GitPullInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        result = repo.git.pull()\n        return {'status': 'Git pull success', 'result': result}\n    except Exception as e:\n        return str(e)", "hash": "81461e8c8c0acfb82f7b224ad3b27ab661ca30ee969b7add12148a922dd15eb6"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_pull_remote(self, input: GitPullInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        result = repo.git.push(input.remote)\n        return {'status': 'Git pull success', 'result': result}\n    except Exception as e:\n        return str(e)", "hash": "494eb0ea3f7c752bbb37ec96fb3027c92c1d3941ff677d98cfe0c09ae79341b5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_push(self, input: GitPushInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        result = repo.git.push()\n        return {'status': 'Git pull success', 'result': result}\n    except Exception as e:\n        return str(e)", "hash": "0d3d283474cde5a5009a72ee7bf1ca63d162995b5f5f04003d7953f61563d7b5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_push_remote(self, input: GitPushInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        result = repo.git.push(input.remote)\n        return {'status': 'Git pull success', 'result': result}\n    except Exception as e:\n        return str(e)", "hash": "4a60aa122700fb2f5fa63d174fa4bf4dc95bdebe50d6f11e00e70474b0e772f6"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.GitBaseNode\nconfig: NodeConfig = NodeConfig(**repository_node_config)", "hash": "d156cc3ce347a9fea37db4364e800a681c0b5efecd02157957ebf807e78bc0a2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def get_git_branch_list(self, input: GitRepositoryInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        repo_heads_names = [h.name for h in repo.heads]\n        return {'branch': repo_heads_names}\n    except Exception as e:\n        return str(e)", "hash": "d62663d7fd9e0a31c3d44f224df954b6a36246f54268127b7802813825aea4de"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_switch_branch(self, input: GitBranchInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        repo.git.checkout(input.branch_name)\n        return {'status': f'Successfully checkout git branch {input.branch_name}.'}\n    except Exception as e:\n        return str(e)", "hash": "3a6eeba6f33a6805fdebfdba9e410dc0cc20181e54b9ea4219c3695d9beeb2a2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_log_raw(self, input: GitRepositoryInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        log_content = repo.git.log()\n        return {'log': log_content}\n    except Exception as e:\n        return str(e)", "hash": "697990236afc26c7a7b5be3e4f2b7a4b4681a6e95075f593ddb562d1a34fae55"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_log(self, input: GitRepositoryInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        log_content = repo.git.log()\n        return {'log': log_content}\n    except Exception as e:\n        return str(e)", "hash": "cc22deb21100976e8a7f2c5ed3284fcb71b46d071bbc8ec0a2c62b35adfad6c1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_log_commit_topk(self, input: GitRepositoryInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        log_content = repo.git.log()\n        return {'log': log_content}\n    except Exception as e:\n        return str(e)", "hash": "50694db1a3715bca7722d208f1f7f6093123c210a231449f88dbdde975d5377f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_pull(self, input: GitPullInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        result = repo.git.pull()\n        return {'status': 'Git pull success', 'result': result}\n    except Exception as e:\n        return str(e)", "hash": "81461e8c8c0acfb82f7b224ad3b27ab661ca30ee969b7add12148a922dd15eb6"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_pull_remote(self, input: GitPullInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        result = repo.git.push(input.remote)\n        return {'status': 'Git pull success', 'result': result}\n    except Exception as e:\n        return str(e)", "hash": "494eb0ea3f7c752bbb37ec96fb3027c92c1d3941ff677d98cfe0c09ae79341b5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_push(self, input: GitPushInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        result = repo.git.push()\n        return {'status': 'Git pull success', 'result': result}\n    except Exception as e:\n        return str(e)", "hash": "0d3d283474cde5a5009a72ee7bf1ca63d162995b5f5f04003d7953f61563d7b5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "GitBranchNode.def git_push_remote(self, input: GitPushInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        result = repo.git.push(input.remote)\n        return {'status': 'Git pull success', 'result': result}\n    except Exception as e:\n        return str(e)", "hash": "4a60aa122700fb2f5fa63d174fa4bf4dc95bdebe50d6f11e00e70474b0e772f6"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_branch.py", "code_chunk": "from git import Commit\nfrom ..base_node import BaseNode, NodeConfig\nfrom .git_base_node import GitBaseNode\nfrom .git_model import GitRepositoryInput, GitBranchInput, GitPullInput, GitPushInput\nrepository_node_config = {'name': 'git_branch_node', 'description': 'A node that implements common git branch operations.', 'functions': {'get_git_branch_list': 'Add specific file(s) to git index.', 'git_log_raw': 'Get raw output string of git log.', 'git_log': 'Get list of commit info.', 'git_log_commit_topk': 'Get list of commit info, max traceback topk.', 'git_switch_branch': 'Switch to another branch.', 'git_pull': 'Git pull.', 'git_push': 'Git push.', 'git_pull_remote': 'Git pull with specified remote', 'git_push_remote': 'Git push with specified remote'}}", "hash": "7562ccb3806aa57e07df68b50d70bf77019158e8df7c0f22815b96ffbb1f41c9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def git_add_files(self, input: GitAddFileInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        for path in input.paths:\n            repo.git.add(path)\n        return {'status': f'Files {input.paths} are added successfully to index of repo {input.path}.'}\n    except Exception as e:\n        return str(e)", "hash": "793754b44341555ff1a05a2924f2e22f28a360390aada513293e8c392ee12e98"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def git_add_all(self, input: GitRepositoryInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        repo.git.add(all=True)\n        return {'status': f'Files {input.paths} are added successfully to index of repo {input.path}.'}\n    except Exception as e:\n        return str(e)", "hash": "3d01ebf141687c390becce309f1f58cbfb54f398f12416652faf0417475c9a30"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def get_untracked_files(self, input: GitRepositoryInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        return {'untracked': repo.untracked_files}\n    except Exception as e:\n        return str(e)", "hash": "3b7b1524a7e7c76fd6914591ed725ad7baf6fffd95129a755c81a385b11ac380"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def git_commit(self, input: GitCommitInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        result = repo.git.commit('-m', input.message)\n        return {'status': 'Git commit success', 'message': result.message}\n    except Exception as e:\n        return str(e)", "hash": "5b77a17474a0078b8ac01c8599d66e40c65e689dd1bf93556f7d6786e7998e66"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def git_commit_with_author(self, input: GitCommitInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        result = repo.git.commit('-m', input.message, author=input.author)\n        return {'status': 'Git commit success', 'message': result.message}\n    except Exception as e:\n        return str(e)", "hash": "10d9f0d88da1ec7fb0f11af7b097bd3a1a4571b4018c7d79d89ee38f9261d3cf"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def git_add_commit(self, input: GitCommitInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        repo.git.add(all=True)\n        result = repo.git.commit('-m', input.message)\n        return {'status': 'Git commit success', 'message': result.message}\n    except Exception as e:\n        return str(e)", "hash": "2df4bce69b7870ad4058b38d709117640a5a4f65acba626836bb5a8e0ed5e1f2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def git_reset_all(self, input: GitRepositoryInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        repo.git.reset()\n        return {'status': f'Successfully reset git index'}\n    except Exception as e:\n        return str(e)", "hash": "970d4e7400547be679bdf9687002b66879bac8cac7194a7a811f67dcb189330a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def git_reset_files(self, input: GitRepositoryInput):\n    repo_path = input.path\n    done_reset = []\n    try:\n        repo = self.g.Repo(repo_path)\n        for path in input.paths:\n            repo.git.reset(path)\n            done_reset.append(path)\n        return {'status': f'Successfully reset git index', 'reset_files': done_reset}\n    except Exception as e:\n        return str(e)", "hash": "6ef05666ae7d1ea42f56a35e791238e45bbb485fa92764ae040e5ba56923d0dc"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.GitBaseNode\nconfig: NodeConfig = NodeConfig(**repository_node_config)", "hash": "cfe2deda96a367d6843bceae09deb6fe352b8d4aa8ed0a8f70875c708c19a474"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def git_add_files(self, input: GitAddFileInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        for path in input.paths:\n            repo.git.add(path)\n        return {'status': f'Files {input.paths} are added successfully to index of repo {input.path}.'}\n    except Exception as e:\n        return str(e)", "hash": "793754b44341555ff1a05a2924f2e22f28a360390aada513293e8c392ee12e98"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def git_add_all(self, input: GitRepositoryInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        repo.git.add(all=True)\n        return {'status': f'Files {input.paths} are added successfully to index of repo {input.path}.'}\n    except Exception as e:\n        return str(e)", "hash": "3d01ebf141687c390becce309f1f58cbfb54f398f12416652faf0417475c9a30"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def get_untracked_files(self, input: GitRepositoryInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        return {'untracked': repo.untracked_files}\n    except Exception as e:\n        return str(e)", "hash": "3b7b1524a7e7c76fd6914591ed725ad7baf6fffd95129a755c81a385b11ac380"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def git_commit(self, input: GitCommitInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        result = repo.git.commit('-m', input.message)\n        return {'status': 'Git commit success', 'message': result.message}\n    except Exception as e:\n        return str(e)", "hash": "5b77a17474a0078b8ac01c8599d66e40c65e689dd1bf93556f7d6786e7998e66"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def git_commit_with_author(self, input: GitCommitInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        result = repo.git.commit('-m', input.message, author=input.author)\n        return {'status': 'Git commit success', 'message': result.message}\n    except Exception as e:\n        return str(e)", "hash": "10d9f0d88da1ec7fb0f11af7b097bd3a1a4571b4018c7d79d89ee38f9261d3cf"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def git_add_commit(self, input: GitCommitInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        repo.git.add(all=True)\n        result = repo.git.commit('-m', input.message)\n        return {'status': 'Git commit success', 'message': result.message}\n    except Exception as e:\n        return str(e)", "hash": "2df4bce69b7870ad4058b38d709117640a5a4f65acba626836bb5a8e0ed5e1f2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def git_reset_all(self, input: GitRepositoryInput):\n    repo_path = input.path\n    try:\n        repo = self.g.Repo(repo_path)\n        repo.git.reset()\n        return {'status': f'Successfully reset git index'}\n    except Exception as e:\n        return str(e)", "hash": "970d4e7400547be679bdf9687002b66879bac8cac7194a7a811f67dcb189330a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "GitCommitNode.def git_reset_files(self, input: GitRepositoryInput):\n    repo_path = input.path\n    done_reset = []\n    try:\n        repo = self.g.Repo(repo_path)\n        for path in input.paths:\n            repo.git.reset(path)\n            done_reset.append(path)\n        return {'status': f'Successfully reset git index', 'reset_files': done_reset}\n    except Exception as e:\n        return str(e)", "hash": "6ef05666ae7d1ea42f56a35e791238e45bbb485fa92764ae040e5ba56923d0dc"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_commit.py", "code_chunk": "from pathlib import Path\nimport os\nfrom dotenv import load_dotenv\nfrom .git_base_node import GitBaseNode\nfrom .git_model import GitAddFileInput, GitRepositoryInput, GitCommitInput\nfrom ..base_node import BaseNode, NodeConfig\nload_dotenv()\nrepository_node_config = {'name': 'git_commit', 'description': 'A node that implements common git operations related to git commit.', 'functions': {'git_add_files': 'Add specific file(s) to git index.', 'git_add_all': 'Add all files in directory.', 'git_commit': 'Make a commit with message in the repository.', 'git_commit_with_author': 'Make a commit with message and given author in the repository.', 'git_add_commit': 'Add files and commit (shorthand of git add -A and git commit).', 'git_reset_all': 'Restore the index, undo git add.', 'get_untracked_files': 'Get list of untracked files of current repo'}}", "hash": "434a00ddd58dabe191d70643b2abbe12632268937d83ff8a66b79118d4772b24"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_model.py", "code_chunk": "GitRepositoryInput.BaseModel\npath: str", "hash": "a1a4bcd3f874542cb2d77c3ddc824e35bc772ec3c67be40c1a2224413c361e6b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_model.py", "code_chunk": "GitRemoteRepositoryInput.BaseModel\nurl: str\npath: Path", "hash": "ccd6508517b2f9c4bef404f714e7a6776f93b31e6bbac5ee02365c6f09083951"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_model.py", "code_chunk": "GitConfigInput.GitRepositoryInput\nconfig: dict[str, str]", "hash": "e117d38c029da5bbd0dab789f91417f328094f69c8aca61fcd384362c7e1d221"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_model.py", "code_chunk": "GitConfigReaderInput.GitRepositoryInput\nkeys: list[str]", "hash": "a7a38e50448dcf03d6b026b4c23a9ee08887d1d7b88d0ddcaa18090757aae258"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_model.py", "code_chunk": "GitFileInput.BaseModel\npath: str", "hash": "184cbb609f5aa5914f7209a3c870c81ba8715d91338d7f08f549b1e21d853b7b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_model.py", "code_chunk": "GitAddFileInput.GitRepositoryInput\npaths: list[str]", "hash": "330de4eb3d3870735b3240287fc473d19283f43d6ebd059d3d33e7ec87d43f32"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_model.py", "code_chunk": "GitCommitInput.GitRepositoryInput\nmessage: str\nauthor: str", "hash": "57bea76e0f96c71c0ac3214b5fb94ea5c4e900b36ece84c41fb3c87f851f6b8a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_model.py", "code_chunk": "GitResetInput.GitRepositoryInput\npaths: list[str]", "hash": "a66c93e7d64f07a3f3855746f2dd749c6fa15d9b50aea6d01932b6e34cad700e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_model.py", "code_chunk": "GitBranchInput.GitRepositoryInput\nbranch_name: str", "hash": "9e375c311cf483ebc55613149abdcadfe56ffc39792ebbb2f4005312d0fab955"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_model.py", "code_chunk": "GitLogInput.GitRepositoryInput\nformat_options: list[str]", "hash": "e2f10139a62c50acf51acb8d04df0559dd6e6880194ce8a512ab96b308653736"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_model.py", "code_chunk": "GitPullInput.GitRepositoryInput\nremote: str", "hash": "f4b37bd67fbc964c040753944b639f39b334ad7f5b4819b926a3cf957811a23f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_model.py", "code_chunk": "GitPushInput.GitRepositoryInput\nremote: str", "hash": "100b947cc8a3c62ffc0e97dfdda8b55d0565bde831c6c831f056735e699c0e49"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_model.py", "code_chunk": "from pydantic import BaseModel\nfrom pathlib import Path", "hash": "cb2143ae83aae8df82cc1b67f081638b1d7e4e237d8ea1860f7303619bf32455"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def __init__(self):\n    super().__init__()", "hash": "fd93831629f8a3ddd36eec7c987b5b73a897c1a85eb7402adf97c64db180cc32"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def git_init(self, input: GitRepositoryInput):\n    try:\n        repo_path = input.path\n        self.r.init(repo_path)\n        return {'status': 'Repo initialized successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "9526b86b41b69d7dedb58532420a41260ee38a65996a43c98618e7de675aec11"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def git_clone(self, input: GitRemoteRepositoryInput):\n    try:\n        repo_url = input.url\n        repo_path = input.path\n        self.r.clone_from(repo_url, repo_path)\n        return {'status': 'Repo cloned successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "f7e0eaad5421a91776eab263530c2e1ae5586249648f4ecdaf3186c6094db213"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def git_fetch(self, input: GitRepositoryInput):\n    try:\n        repo_path = input.path\n        repo = self.g.Repo(repo_path)\n        for remote in repo.remotes:\n            remote.fetch()\n    except Exception as e:\n        return str(e)", "hash": "5754c86a5fedbdf4aa81b971fdc5d1e8274ea65870bb4b7435e21be1eae20be9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def git_get_config(self, input: GitConfigReaderInput):\n    try:\n        repo_path = input.path\n        repo = self.g.Repo(repo_path)\n        keys = input.keys\n        reader = repo.config_reader(config_level='repository')\n        res = []\n        for k in keys:\n            kk = k.split('.')\n            if len(kk) < 2:\n                raise ValueError('Git config key should have section.option format')\n            section, option = k\n            res.append(reader.get_value(section, option))\n        return {'status': 'Git local config set successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "7d3d75ea3c06b21b36f363b838e80894044ddf8442d920d79252cde06e5f4f4d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def git_config(self, input: GitConfigInput):\n    try:\n        repo_path = input.path\n        repo = self.g.Repo(repo_path)\n        config = input.config\n        writer = repo.config_writer(config_level='repository')\n        for k, v in config.items():\n            kk = k.split('.')\n            if len(kk) < 2:\n                raise ValueError('Git config key should have section.option format')\n            section, option = kk\n            writer.set_value(section, option, v)\n        writer.release()\n        return {'status': 'Git local config set successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "048b9cffc57b63a73b399a6c60fdd39053136f9c5d65844afc7fafdf870128df"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def git_config_global(self, input: GitConfigInput):\n    try:\n        repo_path = '~'\n        repo = self.g.Repo(repo_path)\n        config = input.config\n        w = repo.config_writer(config_level='global')\n        for k, v in config.items():\n            kk = k.split('.')\n            if len(kk) < 2:\n                raise ValueError('Git config key should have section.option format')\n            section, option = kk\n            w.set_value(section, option, v)\n        w.release()\n        return {'status': 'Git local config set successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "2055f7e7e662af700f8cb86f29ce5a7ffa07bbdffd4ded2dc0f83a48f172b7ca"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def is_dirty(self, input: GitRepositoryInput):\n    try:\n        repo_path = input.path\n        repo = self.g.Repo(repo_path)\n        return {'dirty': repo.is_dirty(untracked_files=True)}\n    except Exception as e:\n        return str(e)", "hash": "d250639c6a41579eaef97992a7d8256b7224a5d52be64bb4f5b95c8e3f6ae812"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.GitBaseNode\nconfig: NodeConfig = NodeConfig(**repository_node_config)", "hash": "aa61666ce7aef5eed969e5a308e86358fb4a4522ef9e9f6a14f250f4928dcfc6"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def __init__(self):\n    super().__init__()", "hash": "fd93831629f8a3ddd36eec7c987b5b73a897c1a85eb7402adf97c64db180cc32"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def git_init(self, input: GitRepositoryInput):\n    try:\n        repo_path = input.path\n        self.r.init(repo_path)\n        return {'status': 'Repo initialized successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "9526b86b41b69d7dedb58532420a41260ee38a65996a43c98618e7de675aec11"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def git_clone(self, input: GitRemoteRepositoryInput):\n    try:\n        repo_url = input.url\n        repo_path = input.path\n        self.r.clone_from(repo_url, repo_path)\n        return {'status': 'Repo cloned successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "f7e0eaad5421a91776eab263530c2e1ae5586249648f4ecdaf3186c6094db213"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def git_fetch(self, input: GitRepositoryInput):\n    try:\n        repo_path = input.path\n        repo = self.g.Repo(repo_path)\n        for remote in repo.remotes:\n            remote.fetch()\n    except Exception as e:\n        return str(e)", "hash": "5754c86a5fedbdf4aa81b971fdc5d1e8274ea65870bb4b7435e21be1eae20be9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def git_get_config(self, input: GitConfigReaderInput):\n    try:\n        repo_path = input.path\n        repo = self.g.Repo(repo_path)\n        keys = input.keys\n        reader = repo.config_reader(config_level='repository')\n        res = []\n        for k in keys:\n            kk = k.split('.')\n            if len(kk) < 2:\n                raise ValueError('Git config key should have section.option format')\n            section, option = k\n            res.append(reader.get_value(section, option))\n        return {'status': 'Git local config set successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "7d3d75ea3c06b21b36f363b838e80894044ddf8442d920d79252cde06e5f4f4d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def git_config(self, input: GitConfigInput):\n    try:\n        repo_path = input.path\n        repo = self.g.Repo(repo_path)\n        config = input.config\n        writer = repo.config_writer(config_level='repository')\n        for k, v in config.items():\n            kk = k.split('.')\n            if len(kk) < 2:\n                raise ValueError('Git config key should have section.option format')\n            section, option = kk\n            writer.set_value(section, option, v)\n        writer.release()\n        return {'status': 'Git local config set successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "048b9cffc57b63a73b399a6c60fdd39053136f9c5d65844afc7fafdf870128df"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def git_config_global(self, input: GitConfigInput):\n    try:\n        repo_path = '~'\n        repo = self.g.Repo(repo_path)\n        config = input.config\n        w = repo.config_writer(config_level='global')\n        for k, v in config.items():\n            kk = k.split('.')\n            if len(kk) < 2:\n                raise ValueError('Git config key should have section.option format')\n            section, option = kk\n            w.set_value(section, option, v)\n        w.release()\n        return {'status': 'Git local config set successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "2055f7e7e662af700f8cb86f29ce5a7ffa07bbdffd4ded2dc0f83a48f172b7ca"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "GitRepoNode.def is_dirty(self, input: GitRepositoryInput):\n    try:\n        repo_path = input.path\n        repo = self.g.Repo(repo_path)\n        return {'dirty': repo.is_dirty(untracked_files=True)}\n    except Exception as e:\n        return str(e)", "hash": "d250639c6a41579eaef97992a7d8256b7224a5d52be64bb4f5b95c8e3f6ae812"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\git\\git_repo.py", "code_chunk": "from ..base_node import BaseNode, NodeConfig\nfrom .git_base_node import GitBaseNode\nfrom .git_model import GitRepositoryInput, GitRemoteRepositoryInput, GitConfigInput, GitConfigReaderInput\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\nGITHUB_TOKEN = os.environ.get('GITHUB_TOKEN')\nrepository_node_config = {'name': 'git_repo', 'description': 'A node that implements common repo-level git operations.', 'functions': {'git_init': 'Initialize a git repository at given dir path.', 'git_clone': 'Create a new file in the repository.', 'git_fetch': 'Delete a file in the repository.', 'git_get_config': 'Get repo config.', 'git_config': 'Set the config for repo.', 'git_config_global': 'Set global git config for repo', 'is_dirty': 'Return true if repo has untracked file or index has changed.'}}", "hash": "645bd78a70774789cc5ab162359cee3664ac817aa23059eb7fe51220b8d6ede6"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_branch.py", "code_chunk": "GithubBranchNode.def __init__(self):\n    super().__init__()", "hash": "def9b47e998024eed5ab67192a83ab247c9b38c90066e19107728560f60147f5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_branch.py", "code_chunk": "GithubBranchNode.def get_list_of_branches(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        branches = repo.get_branches()\n        return [branch.name for branch in branches]\n    except Exception as e:\n        return str(e)", "hash": "1374133f3b6e8e6629d1b6d1478e80449f91c73c8f066b21221fe9c291f1f90d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_branch.py", "code_chunk": "GithubBranchNode.def get_branch(self, input: GetBranchInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        branch = repo.get_branch(branch=input.branch_name)\n        return branch.name\n    except Exception as e:\n        return str(e)", "hash": "c8afa4f6f29fc86082bc2d27a8fed6df75c636b22b3e474da9e536ed621b47fb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_branch.py", "code_chunk": "GithubBranchNode.def get_head_commit_of_branch(self, input: GetBranchHeadCommitInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        branch = repo.get_branch(branch=input.branch_name)\n        return branch.commit.sha\n    except Exception as e:\n        return str(e)", "hash": "0a09099686062b45eedf616a5d5422030c95c52f162a01660c6d8d6c1178cfcd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_branch.py", "code_chunk": "GithubBranchNode.def get_protection_status_of_branch(self, input: GetBranchProtectionStatusInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        protection = repo.get_branch_protection(branch=input.branch_name)\n        return protection.url\n    except Exception as e:\n        return str(e)", "hash": "6a81e4df43dabe325d84e5b1bec067893918da3c9605f10eb6aa4bc77078226e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_branch.py", "code_chunk": "GithubBranchNode.def see_required_status_checks_of_branch(self, input: GetBranchRequiredStatusChecksInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        protection = repo.get_branch_protection(branch=input.branch_name)\n        return protection.required_status_checks\n    except Exception as e:\n        return str(e)", "hash": "9eeac3d18788b1fb8d233391b392c36116486e10c435f5319f1c72aa3934536e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_branch.py", "code_chunk": "GithubBranchNode.GithubNode\nconfig: NodeConfig = NodeConfig(**github_branch_node_config)", "hash": "50a7964a75cad22358b5ad141bc65142da6ed707e0274d1f255b170a6d14ce20"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_branch.py", "code_chunk": "GithubBranchNode.def __init__(self):\n    super().__init__()", "hash": "def9b47e998024eed5ab67192a83ab247c9b38c90066e19107728560f60147f5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_branch.py", "code_chunk": "GithubBranchNode.def get_list_of_branches(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        branches = repo.get_branches()\n        return [branch.name for branch in branches]\n    except Exception as e:\n        return str(e)", "hash": "1374133f3b6e8e6629d1b6d1478e80449f91c73c8f066b21221fe9c291f1f90d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_branch.py", "code_chunk": "GithubBranchNode.def get_branch(self, input: GetBranchInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        branch = repo.get_branch(branch=input.branch_name)\n        return branch.name\n    except Exception as e:\n        return str(e)", "hash": "c8afa4f6f29fc86082bc2d27a8fed6df75c636b22b3e474da9e536ed621b47fb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_branch.py", "code_chunk": "GithubBranchNode.def get_head_commit_of_branch(self, input: GetBranchHeadCommitInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        branch = repo.get_branch(branch=input.branch_name)\n        return branch.commit.sha\n    except Exception as e:\n        return str(e)", "hash": "0a09099686062b45eedf616a5d5422030c95c52f162a01660c6d8d6c1178cfcd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_branch.py", "code_chunk": "GithubBranchNode.def get_protection_status_of_branch(self, input: GetBranchProtectionStatusInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        protection = repo.get_branch_protection(branch=input.branch_name)\n        return protection.url\n    except Exception as e:\n        return str(e)", "hash": "6a81e4df43dabe325d84e5b1bec067893918da3c9605f10eb6aa4bc77078226e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_branch.py", "code_chunk": "GithubBranchNode.def see_required_status_checks_of_branch(self, input: GetBranchRequiredStatusChecksInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        protection = repo.get_branch_protection(branch=input.branch_name)\n        return protection.required_status_checks\n    except Exception as e:\n        return str(e)", "hash": "9eeac3d18788b1fb8d233391b392c36116486e10c435f5319f1c72aa3934536e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_branch.py", "code_chunk": "from ..base_node import BaseNode, NodeConfig\nfrom .github_node import GithubNode\nfrom .github_model import RepositoryInput, GetBranchInput, GetBranchHeadCommitInput, GetBranchProtectionStatusInput, GetBranchRequiredStatusChecksInput\ngithub_branch_node_config = {'name': 'github_branch', 'description': 'A node for interacting with GitHub branches.', 'functions': {'get_list_of_branches': 'Get a list of branches.', 'get_branch': 'Get a specific branch.', 'get_head_commit_of_branch': 'Get the HEAD commit of a branch.', 'get_protection_status_of_branch': 'Get the protection status of a branch.', 'see_required_status_checks_of_branch': 'See the required status checks of a branch.'}}", "hash": "ea2c0c3204ea56282561493e025d2d7d8eb04d66d6fce3ae1a91c050cfcbe1d8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_commit.py", "code_chunk": "GithubCommitNode.def __init__(self):\n    super().__init__()", "hash": "6937651faba8325275dca9a5081a4e3388674e0ffa6647ddfd03af253a305ca9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_commit.py", "code_chunk": "GithubCommitNode.def create_commit_status_check(self, input: CreateCommitStatusCheckInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        commit = repo.get_commit(sha=input.sha)\n        status = commit.create_status(state=input.state, target_url=input.target_url, description=input.description, context=input.context)\n        return {'status': 'Status check created successfully.', 'url': status.url}\n    except Exception as e:\n        return str(e)", "hash": "18147c89692902efe9d2c8de573b042d0b05899b01a66bb375a75aad00ac59ad"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_commit.py", "code_chunk": "GithubCommitNode.def get_commit_date(self, input: GetCommitDateInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        commit = repo.get_commit(sha=input.sha)\n        date = commit.commit.committer.date\n        return date.strftime('%Y-%m-%d %H:%M:%S')\n    except Exception as e:\n        return str(e)", "hash": "3db819d4989df09e6fbd49ed1599ffa2bd17575765e6b728dac89850650ce9a5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_commit.py", "code_chunk": "GithubCommitNode.GithubNode\nconfig: NodeConfig = NodeConfig(**github_commit_node_config)", "hash": "e9ae3be7e2744ce6537508b20d0d15d5e8f7391ca4f83a51e027a2023ba9c2c2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_commit.py", "code_chunk": "GithubCommitNode.def __init__(self):\n    super().__init__()", "hash": "6937651faba8325275dca9a5081a4e3388674e0ffa6647ddfd03af253a305ca9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_commit.py", "code_chunk": "GithubCommitNode.def create_commit_status_check(self, input: CreateCommitStatusCheckInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        commit = repo.get_commit(sha=input.sha)\n        status = commit.create_status(state=input.state, target_url=input.target_url, description=input.description, context=input.context)\n        return {'status': 'Status check created successfully.', 'url': status.url}\n    except Exception as e:\n        return str(e)", "hash": "18147c89692902efe9d2c8de573b042d0b05899b01a66bb375a75aad00ac59ad"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_commit.py", "code_chunk": "GithubCommitNode.def get_commit_date(self, input: GetCommitDateInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        commit = repo.get_commit(sha=input.sha)\n        date = commit.commit.committer.date\n        return date.strftime('%Y-%m-%d %H:%M:%S')\n    except Exception as e:\n        return str(e)", "hash": "3db819d4989df09e6fbd49ed1599ffa2bd17575765e6b728dac89850650ce9a5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_commit.py", "code_chunk": "from ..base_node import BaseNode, NodeConfig\nfrom .github_node import GithubNode\nfrom .github_model import CreateCommitStatusCheckInput, GetCommitDateInput\nfrom datetime import datetime\ngithub_commit_node_config = {'name': 'github_commit', 'description': 'A node for interacting with GitHub commits.', 'functions': {'create_commit_status_check': 'Create a status check for a commit.', 'get_commit_date': 'Get the date of a commit.'}}", "hash": "a1ef5b7c03ae71bd5802325bfbe812142c2a3144c776f7bf7219e1a8d24ed605"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def __init__(self):\n    super().__init__()", "hash": "6b561edb6f42c3f26fa2c9b9f3b1219ef5a028f09a9ca1aa71ad094b29f9aa35"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def get_issue(self, input: GetIssueInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        issue = repo.get_issue(number=input.issue_number)\n        return (issue.title, issue.body)\n    except Exception as e:\n        return str(e)", "hash": "122f9bcd3423828c20d4caa5addcc46475033471eb518566d3d17afac89a40a4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def create_issue_comment(self, input: CreateIssueCommentInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        issue = repo.get_issue(number=input.issue_number)\n        comment = issue.create_comment(input.comment_content)\n        return f'Comment created with ID: {comment.id}'\n    except Exception as e:\n        return str(e)", "hash": "a06829176d6f196067bdce1571a2d0f87815164fa21753f30f1b2d234aac28d3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def create_issue(self, input: CreateIssueInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        issue = repo.create_issue(title=input.title)\n        return f'Issue created with title: {issue.title} and ID: {issue.id}'\n    except Exception as e:\n        return str(e)", "hash": "24eb06273a6689b5e101303b750afe30e26dad1b129ce271dc193f8fb6d48d84"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def create_issue_with_body(self, input: CreateIssueWithBodyInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        issue = repo.create_issue(title=input.title, body=input.body)\n        return f'Issue created with title: {issue.title}, ID: {issue.id}, and body: {issue.body}'\n    except Exception as e:\n        return str(e)", "hash": "e06bff08684421eed5331467e436e5e28201c2fba7d1947bcf06e0973af8d162"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def create_issue_with_labels(self, input: CreateIssueWithLabelsInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        labels = [repo.get_label(label_name) for label_name in input.labels]\n        issue = repo.create_issue(title=input.title, labels=labels)\n        return f'Issue created with title: {issue.title}, ID: {issue.id}, and labels: {[label.name for label in issue.labels]}'\n    except Exception as e:\n        return str(e)", "hash": "a4018ad940aca7e4c71d10442280897a03c0cdc3d16fddf8888c24ed5fc88505"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def create_issue_with_assignee(self, input: CreateIssueWithAssigneeInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        issue = repo.create_issue(title=input.title, assignee=input.assignee)\n        return f\"Issue '{issue.title}' created with assignee '{input.assignee}' successfully.\"\n    except Exception as e:\n        return str(e)", "hash": "daf7dd71b6f97eea7e1653c5be1ac64ac14f1cd311df381fd2b27aeb3857c28f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def create_issue_with_milestone(self, input: CreateIssueWithMilestoneInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        milestone = repo.get_milestone(number=input.milestone_number)\n        issue = repo.create_issue(title=input.title, body=input.body, milestone=milestone)\n        return {'status': 'Issue created successfully with milestone.', 'issue_number': issue.number}\n    except Exception as e:\n        return str(e)", "hash": "59a42a81291342070b12d46d62d187eb15cfe6d72d940c0ff55329c0706ad2dc"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def close_all_issues(self, input: CloseAllIssuesInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        open_issues = repo.get_issues(state='open')\n        for issue in open_issues:\n            issue.edit(state='closed')\n        return 'All open issues closed successfully.'\n    except Exception as e:\n        return str(e)", "hash": "de1041efeda560250ea5428243386b7b3bfdac0bcb88c7243c2d27797f46fece"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.GithubNode\nconfig: NodeConfig = NodeConfig(**github_issues_node_config)", "hash": "478c46f1701129a06d92aa36b4d5b31221491051622b7e5a56c3819c56215e52"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def __init__(self):\n    super().__init__()", "hash": "6b561edb6f42c3f26fa2c9b9f3b1219ef5a028f09a9ca1aa71ad094b29f9aa35"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def get_issue(self, input: GetIssueInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        issue = repo.get_issue(number=input.issue_number)\n        return (issue.title, issue.body)\n    except Exception as e:\n        return str(e)", "hash": "122f9bcd3423828c20d4caa5addcc46475033471eb518566d3d17afac89a40a4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def create_issue_comment(self, input: CreateIssueCommentInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        issue = repo.get_issue(number=input.issue_number)\n        comment = issue.create_comment(input.comment_content)\n        return f'Comment created with ID: {comment.id}'\n    except Exception as e:\n        return str(e)", "hash": "a06829176d6f196067bdce1571a2d0f87815164fa21753f30f1b2d234aac28d3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def create_issue(self, input: CreateIssueInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        issue = repo.create_issue(title=input.title)\n        return f'Issue created with title: {issue.title} and ID: {issue.id}'\n    except Exception as e:\n        return str(e)", "hash": "24eb06273a6689b5e101303b750afe30e26dad1b129ce271dc193f8fb6d48d84"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def create_issue_with_body(self, input: CreateIssueWithBodyInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        issue = repo.create_issue(title=input.title, body=input.body)\n        return f'Issue created with title: {issue.title}, ID: {issue.id}, and body: {issue.body}'\n    except Exception as e:\n        return str(e)", "hash": "e06bff08684421eed5331467e436e5e28201c2fba7d1947bcf06e0973af8d162"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def create_issue_with_labels(self, input: CreateIssueWithLabelsInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        labels = [repo.get_label(label_name) for label_name in input.labels]\n        issue = repo.create_issue(title=input.title, labels=labels)\n        return f'Issue created with title: {issue.title}, ID: {issue.id}, and labels: {[label.name for label in issue.labels]}'\n    except Exception as e:\n        return str(e)", "hash": "a4018ad940aca7e4c71d10442280897a03c0cdc3d16fddf8888c24ed5fc88505"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def create_issue_with_assignee(self, input: CreateIssueWithAssigneeInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        issue = repo.create_issue(title=input.title, assignee=input.assignee)\n        return f\"Issue '{issue.title}' created with assignee '{input.assignee}' successfully.\"\n    except Exception as e:\n        return str(e)", "hash": "daf7dd71b6f97eea7e1653c5be1ac64ac14f1cd311df381fd2b27aeb3857c28f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def create_issue_with_milestone(self, input: CreateIssueWithMilestoneInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        milestone = repo.get_milestone(number=input.milestone_number)\n        issue = repo.create_issue(title=input.title, body=input.body, milestone=milestone)\n        return {'status': 'Issue created successfully with milestone.', 'issue_number': issue.number}\n    except Exception as e:\n        return str(e)", "hash": "59a42a81291342070b12d46d62d187eb15cfe6d72d940c0ff55329c0706ad2dc"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "GithubIssuesNode.def close_all_issues(self, input: CloseAllIssuesInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        open_issues = repo.get_issues(state='open')\n        for issue in open_issues:\n            issue.edit(state='closed')\n        return 'All open issues closed successfully.'\n    except Exception as e:\n        return str(e)", "hash": "de1041efeda560250ea5428243386b7b3bfdac0bcb88c7243c2d27797f46fece"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_issue.py", "code_chunk": "from ..base_node import BaseNode, NodeConfig\nfrom .github_node import GithubNode\nfrom .github_model import GetIssueInput, CreateIssueCommentInput, CreateIssueInput, CreateIssueWithBodyInput, CreateIssueWithLabelsInput, CreateIssueWithAssigneeInput, CreateIssueWithMilestoneInput, CloseAllIssuesInput\nfrom github import Github\ngithub_issues_node_config = {'name': 'github_issues', 'description': 'A node for interacting with GitHub issues.', 'functions': {'get_issue': 'Get issue details.', 'create_issue_comment': 'Create a comment on an issue.', 'create_issue': 'Create a new issue.', 'create_issue_with_body': 'Create a new issue with a body.', 'create_issue_with_labels': 'Create a new issue with labels.', 'create_issue_with_assignee': 'Create a new issue with an assignee.', 'create_issue_with_milestone': 'Create a new issue with a milestone.', 'close_all_issues': 'Close all open issues in a repository.'}}", "hash": "933f67cc4363d56db5f77a6f7a3aa4779d56c9c4a605cccd82c1a13db7a2a147"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_milestone.py", "code_chunk": "GithubMilestoneNode.def __init__(self):\n    super().__init__()", "hash": "3ce1dd501d40fe74c769bb9abdcb09746393e5ab4ce10f714b4d6cf0365a88a3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_milestone.py", "code_chunk": "GithubMilestoneNode.def get_milestone_list(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        milestones = repo.get_milestones()\n        return [{'number': m.number, 'title': m.title} for m in milestones]\n    except Exception as e:\n        return str(e)", "hash": "abd2df3b967111e80fedef27269bf86fd78ceafa63c8f04fb2c3e6db970f1615"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_milestone.py", "code_chunk": "GithubMilestoneNode.def get_milestone(self, input: GetMilestoneInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        milestone = repo.get_milestone(input.milestone_number)\n        return {'number': milestone.number, 'title': milestone.title, 'description': milestone.description, 'state': milestone.state}\n    except Exception as e:\n        return str(e)", "hash": "769fda1abdc5b06d96b5164354964524e6c7f0e9da9ab76977c324c91cc19a7c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_milestone.py", "code_chunk": "GithubMilestoneNode.def create_milestone(self, input: CreateMilestoneInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        milestone = repo.create_milestone(title=input.title)\n        return milestone.number\n    except Exception as e:\n        return str(e)", "hash": "79f97b7add29d290319df1294f95e559b78d6d963144047a5a60ea67308d75e2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_milestone.py", "code_chunk": "GithubMilestoneNode.def create_milestone_with_details(self, input: CreateMilestoneWithDetailsInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        milestone = repo.create_milestone(title=input.title, state=input.state, description=input.description)\n        return milestone.number\n    except Exception as e:\n        return str(e)", "hash": "3a3c7f1800cea7ae5f1d7c85b31e1c19acbc246ac13042885237e12d73ce718b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_milestone.py", "code_chunk": "GithubMilestoneNode.GithubNode\nconfig: NodeConfig = NodeConfig(**github_milestone_node_config)", "hash": "cd35fbe67002a24c82510d1a882485301addf77f2969085ca05b2c14b33e81b3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_milestone.py", "code_chunk": "GithubMilestoneNode.def __init__(self):\n    super().__init__()", "hash": "3ce1dd501d40fe74c769bb9abdcb09746393e5ab4ce10f714b4d6cf0365a88a3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_milestone.py", "code_chunk": "GithubMilestoneNode.def get_milestone_list(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        milestones = repo.get_milestones()\n        return [{'number': m.number, 'title': m.title} for m in milestones]\n    except Exception as e:\n        return str(e)", "hash": "abd2df3b967111e80fedef27269bf86fd78ceafa63c8f04fb2c3e6db970f1615"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_milestone.py", "code_chunk": "GithubMilestoneNode.def get_milestone(self, input: GetMilestoneInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        milestone = repo.get_milestone(input.milestone_number)\n        return {'number': milestone.number, 'title': milestone.title, 'description': milestone.description, 'state': milestone.state}\n    except Exception as e:\n        return str(e)", "hash": "769fda1abdc5b06d96b5164354964524e6c7f0e9da9ab76977c324c91cc19a7c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_milestone.py", "code_chunk": "GithubMilestoneNode.def create_milestone(self, input: CreateMilestoneInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        milestone = repo.create_milestone(title=input.title)\n        return milestone.number\n    except Exception as e:\n        return str(e)", "hash": "79f97b7add29d290319df1294f95e559b78d6d963144047a5a60ea67308d75e2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_milestone.py", "code_chunk": "GithubMilestoneNode.def create_milestone_with_details(self, input: CreateMilestoneWithDetailsInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        milestone = repo.create_milestone(title=input.title, state=input.state, description=input.description)\n        return milestone.number\n    except Exception as e:\n        return str(e)", "hash": "3a3c7f1800cea7ae5f1d7c85b31e1c19acbc246ac13042885237e12d73ce718b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_milestone.py", "code_chunk": "from src.core.nodes.base_node import BaseNode, NodeConfig\nfrom .github_node import GithubNode\nfrom .github_model import RepositoryInput, GetMilestoneInput, CreateMilestoneInput, CreateMilestoneWithDetailsInput\ngithub_milestone_node_config = {'name': 'github_milestone', 'description': 'A node for interacting with GitHub milestones.', 'functions': {'get_milestone_list': 'Get list of milestones.', 'get_milestone': 'Get a specific milestone.', 'create_milestone': 'Create a new milestone.', 'create_milestone_with_details': 'Create a milestone with state and description.'}}", "hash": "ec27ed8a138ed195d907c84dca48f6b53d408f852a70dd3be6cab43187c8de91"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "RepositoryInput.BaseModel\nowner: str\nrepo_name: str", "hash": "74d7f31928af9e4650847ff6c2c2682af408514ebd79a6883b8349a3b2850086"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "GetSpecificContentFileInput.RepositoryInput\npath: str", "hash": "9e4aaa6d9d0841b0f3bcd38aff5b3065269df96585d8d1c4a7d7bb0b8a3e1d5d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "CreateFileInput.RepositoryInput\npath: str\nmessage: str\ncontent: str", "hash": "9b47c91503b578ff2f87b66535babee99f5fff07d44cd47e9049506c67d1c216"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "EditFileInput.CreateFileInput\nsha: str", "hash": "970d11eefb4dce39e7ee09292fac6371d588ce7352c131fba989cbf77cf4ce49"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "DeleteFileInput.RepositoryInput\npath: str\nmessage: str\nsha: str", "hash": "a3309bd4a7636b1c62e0050722ce6f30e8bb74c6eaa3f3b7a867e6bc1cd6720e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "GetIssueInput.BaseModel\nowner: str\nrepo_name: str\nissue_number: int", "hash": "73c340a0cb716bd490024a69323ae87f4f0cfb8cb551b377181d7ec10982fd14"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "CreateIssueCommentInput.BaseModel\nowner: str\nrepo_name: str\nissue_number: int\ncomment_content: str", "hash": "80bfde9775a8b582d42b54d32de1e29574ea94b76b27f330699ebe2baf53419b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "CreateIssueInput.BaseModel\nowner: str\nrepo_name: str\ntitle: str", "hash": "a00fa207a6089dce7ef24bc76be16a40512ad3ef86f4184afc85514aa51f46cd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "CreateIssueWithBodyInput.CreateIssueInput\nbody: str", "hash": "4946952415b66dbb472e30153ccae6d79db2fac64575ec82e0c08f4002cc465c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "CreateIssueWithLabelsInput.CreateIssueInput\nlabels: list[str]", "hash": "8b021b8e91d5a56f7f5931feffbea5512caa55f7ac6e6b04e2da2268868ad2e9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "CreateIssueWithAssigneeInput.CreateIssueInput\nassignee: str", "hash": "2447573bf0c5e1cf5472e47934b4b81933d86bf535899bc87339fb0ea09ee831"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "CreateIssueWithMilestoneInput.CreateIssueInput\nmilestone_number: int", "hash": "a022c597d7ac09d213e097bb59e8de0c352ada0b69dbb4d66f4395322551ca94"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "CloseAllIssuesInput.BaseModel\nowner: str\nrepo_name: str", "hash": "7e12d2f6ccea907201b81d136fee4b37f0970a68315eeae5ca74c253b32b684b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "CreateCommitStatusCheckInput.BaseModel\nowner: str\nrepo_name: str\nsha: str\nstate: str\ntarget_url: str\ndescription: str\ncontext: str", "hash": "8d9fb835c940acc42accc48d116dbd39b1b608a75e73f2d34fcaf2b1f8ff0f40"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "GetCommitDateInput.BaseModel\nowner: str\nrepo_name: str\nsha: str", "hash": "a95b5d012fc25db0972cc4e1df05315dbd78d3c83fb576f09e3c48ccaed1e0b8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "RepositoryInput.BaseModel\nowner: str\nrepo_name: str", "hash": "74d7f31928af9e4650847ff6c2c2682af408514ebd79a6883b8349a3b2850086"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "GetBranchInput.RepositoryInput\nbranch_name: str", "hash": "16a521d63faaf892d68741461284541835d84af73697b599f627b51d67dbb883"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "GetBranchHeadCommitInput.GetBranchInput\npass", "hash": "f4425ef1a30fee4f73d190f91c685308568a55f7f5424a72036604dafb957dd1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "GetBranchProtectionStatusInput.GetBranchInput\npass", "hash": "49878ea845c57ef395ec641d4174be10b69265dac6f10c660c7ef377e906a1e0"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "GetBranchRequiredStatusChecksInput.GetBranchInput\npass", "hash": "6fac22e2183820cf54feb97222a421577764635dba874f7c3902fb3130c8c3c4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "RepositoryInput.BaseModel\nowner: str\nrepo_name: str", "hash": "74d7f31928af9e4650847ff6c2c2682af408514ebd79a6883b8349a3b2850086"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "CreatePullRequestInput.RepositoryInput\ntitle: str\nbody: str\nhead: str\nbase: str", "hash": "6e0d1b903e37f744399c0646618be75ba4366ec7db2d7ff13206b93a443c2c93"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "GetPullRequestByNumberInput.RepositoryInput\npr_number: int", "hash": "d1395c4af21ce37c295792c9659d939ec5671b83a12da44fbe10a0f5103779e9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "GetPullRequestsByQueryInput.RepositoryInput\nquery: str", "hash": "50dfeea49f98e283a9a85de706584a2b5f8808f3871ecaca1b3d972b08a44dc4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "ModifyPRCommentInput.RepositoryInput\npr_number: int\ncomment_id: int\nbody: str", "hash": "926ca38061de2a5c60d6ff89153eb124a0ce82fee4d692eb86be13103be5ab4d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "RepositoryInput.BaseModel\nowner: str\nrepo_name: str", "hash": "74d7f31928af9e4650847ff6c2c2682af408514ebd79a6883b8349a3b2850086"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "GetMilestoneInput.RepositoryInput\nmilestone_number: int", "hash": "f824a7fa42c1bb4cda24d5886d080d27530fef312d3003f6340057aae2454638"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "CreateMilestoneInput.RepositoryInput\ntitle: str", "hash": "900c68a40d4e90f2135ec79e542b78c7e963560cdf8741ce4b4b870acf6906d5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "CreateMilestoneWithDetailsInput.CreateMilestoneInput\nstate: str\ndescription: str", "hash": "ab23c4c4017b857ce3d103b352bc542e7e8fb7f2787e144f28b2be8c1113272c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "GetUserRepositoriesInput.BaseModel\nusername: str", "hash": "622add6c169bbb9cb21c01baaa76a5eadaf496b75955aa52a105578502743353"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "InviteUserToOrgInput.BaseModel\norg_name: str\nusername: str", "hash": "dd2d991175926eaf89e5a458c621cc6d8a9bbca2d2ab5ce140e6fd2553f8010a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "BaseSearchInput.BaseModel\nquery: str", "hash": "7d876406949cbc082e3bb7ff0a0b5a1331a2a7235cb563db55fb639de719a9fc"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "SearchCodeInput.BaseSearchInput\nsort: str = None\norder: str = None", "hash": "01d7277883945a266912425205e2068f239a1c900d8b7460138223b7e6d9491a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "SearchCommitsInput.BaseSearchInput\nsort: str = None\norder: str = None", "hash": "a969f53ea83e47346d271a91c1965eaf821a6e9193e0c63a1dae1484ef71cb0e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "SearchIssuesAndPRsInput.BaseSearchInput\nsort: str = None\norder: str = None", "hash": "57ab800715d973f54961feca79e252ca098ff98bbc43e15ea4806e19cba14f42"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "SearchLabelsInput.BaseSearchInput\nrepository_id: int\nsort: str = None\norder: str = None", "hash": "68734f11626c3e81b309aeb4f7a0868a765b27c0499f80f3c4ef6e7c979d9969"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "SearchRepositoriesInput.BaseSearchInput\nsort: str = None\norder: str = None", "hash": "6cf7718bf36be7a9ece7c9423faf77c6f633144a4f92898cd57ed853e255fa26"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "SearchTopicsInput.BaseSearchInput\nsort: str = None\norder: str = None", "hash": "34c6df0a031124c3a52f2739e9efd8f87e0fa9767532dd95905c27ae7964878d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "SearchUsersInput.BaseSearchInput\nsort: str = None\norder: str = None", "hash": "8e64b0196a5836e47a9c3594a7b2dbc67f7a85ffca62fae8478bdea2dd361c5f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_model.py", "code_chunk": "from pydantic import BaseModel", "hash": "ff0b0b2539c1e2adb9e151452d80d64aeb3881514bbea07756ff6d1bc13e207a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_node.py", "code_chunk": "GithubNode.def __init__(self):\n    self.token = os.environ.get('GITHUB_TOKEN')\n    if not self.token:\n        raise ValueError('GITHUB_TOKEN is not set in the environment.')\n    self.g = Github(self.token)\n    super().__init__()", "hash": "6f03f2b74d54d8aed4b233bc5f0f65c3c0bcbf4ee2c2f0d5a32f3cb2b4bb32d9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_node.py", "code_chunk": "GithubNode.BaseNode", "hash": "930b487d206e3838b1fd7747bd2e607ef3e2715faa6def8be248be9275993cf4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_node.py", "code_chunk": "GithubNode.def __init__(self):\n    self.token = os.environ.get('GITHUB_TOKEN')\n    if not self.token:\n        raise ValueError('GITHUB_TOKEN is not set in the environment.')\n    self.g = Github(self.token)\n    super().__init__()", "hash": "6f03f2b74d54d8aed4b233bc5f0f65c3c0bcbf4ee2c2f0d5a32f3cb2b4bb32d9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_node.py", "code_chunk": "from github import Github\nfrom ..base_node import BaseNode\nimport os", "hash": "847a42d0e3a3b23e9e8272b5c87450efcf419b9766b3a7b7a14ea70f0eef2325"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_pullrequest.py", "code_chunk": "GithubPullRequestNode.def __init__(self):\n    super().__init__()", "hash": "acf439f4a37bab74b112365d55bc2cf26f92db68fbaf07c5f55759b1e2652dc0"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_pullrequest.py", "code_chunk": "GithubPullRequestNode.def create_new_pull_request(self, input: CreatePullRequestInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        pr = repo.create_pull(title=input.title, body=input.body, head=input.head, base=input.base)\n        return pr.number\n    except Exception as e:\n        return str(e)", "hash": "6a21c5d32657c52ee871c66c2ad0682fec3dce612b35452033167f6c439c4d05"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_pullrequest.py", "code_chunk": "GithubPullRequestNode.def get_pull_request_by_number(self, input: GetPullRequestByNumberInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        pr = repo.get_pull(input.pr_number)\n        return {'title': pr.title, 'body': pr.body, 'state': pr.state, 'merged': pr.merged}\n    except Exception as e:\n        return str(e)", "hash": "9c02a1c27a9cada80915ce563540fcb60c5bc164d2269821531f78aa8b16ef91"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_pullrequest.py", "code_chunk": "GithubPullRequestNode.def get_pull_requests_by_query(self, input: GetPullRequestsByQueryInput):\n    try:\n        search_result = self.g.search_issues(input.query, type='pr')\n        prs = [{'number': pr.number, 'title': pr.title} for pr in search_result]\n        return prs\n    except Exception as e:\n        return str(e)", "hash": "377d7329b16b4232a5255c53e13590d0a37c2cd9ed0d62539d4651c4886afc3e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_pullrequest.py", "code_chunk": "GithubPullRequestNode.def modify_pr_comment(self, input: ModifyPRCommentInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        pr = repo.get_pull(input.pr_number)\n        comment = pr.get_comment(input.comment_id)\n        comment.edit(body=input.body)\n        return 'Comment modified successfully.'\n    except Exception as e:\n        return str(e)", "hash": "f4757c86829ee89e63de6fb2fddcc5d408323e380f508f4a18e07f29e30d0d8c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_pullrequest.py", "code_chunk": "GithubPullRequestNode.GithubNode\nconfig: NodeConfig = NodeConfig(**github_pullrequest_node_config)", "hash": "17bf070f8f6735193521fe24f0f2b58aa195ffb8b863554a3db6d4f848730708"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_pullrequest.py", "code_chunk": "GithubPullRequestNode.def __init__(self):\n    super().__init__()", "hash": "acf439f4a37bab74b112365d55bc2cf26f92db68fbaf07c5f55759b1e2652dc0"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_pullrequest.py", "code_chunk": "GithubPullRequestNode.def create_new_pull_request(self, input: CreatePullRequestInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        pr = repo.create_pull(title=input.title, body=input.body, head=input.head, base=input.base)\n        return pr.number\n    except Exception as e:\n        return str(e)", "hash": "6a21c5d32657c52ee871c66c2ad0682fec3dce612b35452033167f6c439c4d05"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_pullrequest.py", "code_chunk": "GithubPullRequestNode.def get_pull_request_by_number(self, input: GetPullRequestByNumberInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        pr = repo.get_pull(input.pr_number)\n        return {'title': pr.title, 'body': pr.body, 'state': pr.state, 'merged': pr.merged}\n    except Exception as e:\n        return str(e)", "hash": "9c02a1c27a9cada80915ce563540fcb60c5bc164d2269821531f78aa8b16ef91"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_pullrequest.py", "code_chunk": "GithubPullRequestNode.def get_pull_requests_by_query(self, input: GetPullRequestsByQueryInput):\n    try:\n        search_result = self.g.search_issues(input.query, type='pr')\n        prs = [{'number': pr.number, 'title': pr.title} for pr in search_result]\n        return prs\n    except Exception as e:\n        return str(e)", "hash": "377d7329b16b4232a5255c53e13590d0a37c2cd9ed0d62539d4651c4886afc3e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_pullrequest.py", "code_chunk": "GithubPullRequestNode.def modify_pr_comment(self, input: ModifyPRCommentInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        pr = repo.get_pull(input.pr_number)\n        comment = pr.get_comment(input.comment_id)\n        comment.edit(body=input.body)\n        return 'Comment modified successfully.'\n    except Exception as e:\n        return str(e)", "hash": "f4757c86829ee89e63de6fb2fddcc5d408323e380f508f4a18e07f29e30d0d8c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_pullrequest.py", "code_chunk": "from ..base_node import BaseNode, NodeConfig\nfrom .github_node import GithubNode\nfrom .github_model import RepositoryInput, CreatePullRequestInput, GetPullRequestByNumberInput, GetPullRequestsByQueryInput, ModifyPRCommentInput\ngithub_pullrequest_node_config = {'name': 'github_pullrequest', 'description': 'A node for interacting with GitHub pull requests.', 'functions': {'create_new_pull_request': 'Create a new pull request.', 'get_pull_request_by_number': 'Get pull request by number.', 'get_pull_requests_by_query': 'Get pull requests by query.', 'modify_pr_comment': 'Add and modify pull request comment.'}}", "hash": "db87ece4323143b40480c9ee066d1c04fabe28de6957ef89d3a30cf1a3575237"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "GithubNode.def __init__(self, token: str):\n    self.token = token\n    self.g = Github(self.token)\n    super().__init__()", "hash": "c0365286349879908ab8e51bf5bf4ea425f63c085a9852afbad9241fd97c61a8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "GithubNode.BaseNode", "hash": "faba2e14964803878cc38c6778629415f562dc12ca374a77948e51c697444109"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def __init__(self):\n    token = os.environ.get('GITHUB_TOKEN')\n    if not token:\n        raise ValueError('GITHUB_TOKEN is not set in the environment.')\n    super().__init__(token)", "hash": "ad75379a0040e84a402def3a2eb44676e658a8f950e99c1fd48cddac0876b18f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_repository_topics(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        topics = repo.get_topics()\n        return topics\n    except Exception as e:\n        return str(e)", "hash": "db0a1bdaa26d2e7624f23fc50c19fcbe9e24a2acdcd1d9584f4f782ac7bf7f16"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_count_of_stars(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        stars_count = repo.stargazers_count\n        return stars_count\n    except Exception as e:\n        return str(e)", "hash": "a4831dfc138ebeb3f721d0ef65e49204412b8237bd9d23ab214b2af0c3452163"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_specific_content_file(self, input: GetSpecificContentFileInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        content_file = repo.get_contents(input.path)\n        return content_file.decoded_content.decode()\n    except Exception as e:\n        return str(e)", "hash": "f6eae4693e1e9e7df2a7c7b881fb6dbe935b5a5b529f7f2fc73a8027955358a5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def create_file(self, input: CreateFileInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        repo.create_file(input.path, input.message, input.content)\n        return {'status': 'File created successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "abd933f8f5e6b314c399c551eb5b4ea04152291ed3155931ef284ea5dc81cbc3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def edit_file(self, input: EditFileInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        content_file = repo.get_contents(input.path)\n        repo.update_file(input.path, input.message, input.content, content_file.sha)\n        return {'status': 'File updated successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "95465f4ae443243f5fdef42a933a60a394a6039ef7af72d14d0e50a89eec587e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def delete_file(self, input: DeleteFileInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        content_file = repo.get_contents(input.path)\n        repo.delete_file(input.path, input.message, content_file.sha)\n        return {'status': 'File deleted successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "9697b476fcae564748d44c9569eebde72d59ca10b434582b10fa74f9e0e649d4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_list_of_open_issues(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        issues = repo.get_issues(state='open')\n        return [issue.title for issue in issues]\n    except Exception as e:\n        return str(e)", "hash": "df2bf43b974300610be544b4e847a481008165c41a5290d7b72982bfbb3d4475"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_list_of_code_scanning_alerts(self, input: RepositoryInput):\n    try:\n        headers = {'Authorization': f'token {self.g.get_user().get_access_token().token}', 'Accept': 'application/vnd.github.v3+json'}\n        url = f'https://api.github.com/repos/{input.owner}/{input.repo_name}/code-scanning/alerts'\n        response = requests.get(url, headers=headers)\n        response.raise_for_status()\n        return response.json()\n    except requests.RequestException as e:\n        return {'error': str(e)}", "hash": "7e3274f5f0af548c494d338dbd2f7ec69aa411c6987f52bdb98eb552f0098130"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_all_labels_of_repository(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        labels = repo.get_labels()\n        return [label.name for label in labels]\n    except Exception as e:\n        return str(e)", "hash": "16451395689f075a3252c20d8f9e0538a189917a11ccdc6b44a547e64efde324"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_contents_of_root_directory(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        contents = repo.get_contents('')\n        return [content.name for content in contents]\n    except Exception as e:\n        return str(e)", "hash": "e4a443075428f2042a150ca96fcc042d058e739b7cc56051ed9132e2c5fe1d04"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_all_contents_recursively(self, input: RepositoryInput):\n    raise NotImplementedError('This function is not implemented yet.')", "hash": "1580176f488faffd3fdc360255dc6f4753a6610abf8cba305eb70081d9847f03"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_top_10_referrers(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        referrers = repo.get_top_referrers()[:10]\n        return [{'referrer': referrer.referrer, 'count': referrer.count, 'uniques': referrer.uniques} for referrer in referrers]\n    except Exception as e:\n        return str(e)", "hash": "dbbdd28e0aeabb2ca0e3b8f913722f23cead240698cb3ee1e892a6bdf47ab413"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_top_10_popular_contents(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        popular_contents = repo.get_top_paths()[:10]\n        return [{'path': content.path, 'count': content.count, 'uniques': content.uniques} for content in popular_contents]\n    except Exception as e:\n        return str(e)", "hash": "b09f1fe8c1c33b529ce741d1beeca6570ae0b7d348aa5c1f5b4efa5463eb14f2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_clone_and_view_data(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        clones = repo.get_clones_traffic()\n        views = repo.get_views_traffic()\n        return {'clones': clones, 'views': views}\n    except Exception as e:\n        return str(e)", "hash": "1a99d41d840ee3d3e75b5cab9cd1dddba59df1476620cffb431664aaa34454e1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def mark_notifications_as_read(self, input: RepositoryInput):\n    try:\n        notifications = self.g.get_user().get_notifications()\n        for notification in notifications:\n            if notification.repository.full_name == f'{input.owner}/{input.repo_name}':\n                notification.mark_as_read()\n        return {'status': 'Notifications marked as read.'}\n    except Exception as e:\n        return str(e)", "hash": "09a1b74d35f9a42128db22f39adcd35b781448b6a6b1546a091574ba568df8d4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.GithubNode\nconfig: NodeConfig = NodeConfig(**repository_node_config)", "hash": "e4186328b0c6d50eb79b3f53f405605c7aca8797593f2fcf7fe496e95b483135"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def __init__(self, token: str):\n    self.token = token\n    self.g = Github(self.token)\n    super().__init__()", "hash": "5a6bb2e5e4a64cd35d18a9bcc8b734050d55e0fcf5916ff84c23ce12e0913cec"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def __init__(self):\n    token = os.environ.get('GITHUB_TOKEN')\n    if not token:\n        raise ValueError('GITHUB_TOKEN is not set in the environment.')\n    super().__init__(token)", "hash": "ad75379a0040e84a402def3a2eb44676e658a8f950e99c1fd48cddac0876b18f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_repository_topics(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        topics = repo.get_topics()\n        return topics\n    except Exception as e:\n        return str(e)", "hash": "db0a1bdaa26d2e7624f23fc50c19fcbe9e24a2acdcd1d9584f4f782ac7bf7f16"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_count_of_stars(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        stars_count = repo.stargazers_count\n        return stars_count\n    except Exception as e:\n        return str(e)", "hash": "a4831dfc138ebeb3f721d0ef65e49204412b8237bd9d23ab214b2af0c3452163"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_specific_content_file(self, input: GetSpecificContentFileInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        content_file = repo.get_contents(input.path)\n        return content_file.decoded_content.decode()\n    except Exception as e:\n        return str(e)", "hash": "f6eae4693e1e9e7df2a7c7b881fb6dbe935b5a5b529f7f2fc73a8027955358a5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def create_file(self, input: CreateFileInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        repo.create_file(input.path, input.message, input.content)\n        return {'status': 'File created successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "abd933f8f5e6b314c399c551eb5b4ea04152291ed3155931ef284ea5dc81cbc3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def edit_file(self, input: EditFileInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        content_file = repo.get_contents(input.path)\n        repo.update_file(input.path, input.message, input.content, content_file.sha)\n        return {'status': 'File updated successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "95465f4ae443243f5fdef42a933a60a394a6039ef7af72d14d0e50a89eec587e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def delete_file(self, input: DeleteFileInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        content_file = repo.get_contents(input.path)\n        repo.delete_file(input.path, input.message, content_file.sha)\n        return {'status': 'File deleted successfully.'}\n    except Exception as e:\n        return str(e)", "hash": "9697b476fcae564748d44c9569eebde72d59ca10b434582b10fa74f9e0e649d4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_list_of_open_issues(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        issues = repo.get_issues(state='open')\n        return [issue.title for issue in issues]\n    except Exception as e:\n        return str(e)", "hash": "df2bf43b974300610be544b4e847a481008165c41a5290d7b72982bfbb3d4475"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_list_of_code_scanning_alerts(self, input: RepositoryInput):\n    try:\n        headers = {'Authorization': f'token {self.g.get_user().get_access_token().token}', 'Accept': 'application/vnd.github.v3+json'}\n        url = f'https://api.github.com/repos/{input.owner}/{input.repo_name}/code-scanning/alerts'\n        response = requests.get(url, headers=headers)\n        response.raise_for_status()\n        return response.json()\n    except requests.RequestException as e:\n        return {'error': str(e)}", "hash": "7e3274f5f0af548c494d338dbd2f7ec69aa411c6987f52bdb98eb552f0098130"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_all_labels_of_repository(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        labels = repo.get_labels()\n        return [label.name for label in labels]\n    except Exception as e:\n        return str(e)", "hash": "16451395689f075a3252c20d8f9e0538a189917a11ccdc6b44a547e64efde324"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_contents_of_root_directory(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        contents = repo.get_contents('')\n        return [content.name for content in contents]\n    except Exception as e:\n        return str(e)", "hash": "e4a443075428f2042a150ca96fcc042d058e739b7cc56051ed9132e2c5fe1d04"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_all_contents_recursively(self, input: RepositoryInput):\n    raise NotImplementedError('This function is not implemented yet.')", "hash": "1580176f488faffd3fdc360255dc6f4753a6610abf8cba305eb70081d9847f03"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_top_10_referrers(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        referrers = repo.get_top_referrers()[:10]\n        return [{'referrer': referrer.referrer, 'count': referrer.count, 'uniques': referrer.uniques} for referrer in referrers]\n    except Exception as e:\n        return str(e)", "hash": "dbbdd28e0aeabb2ca0e3b8f913722f23cead240698cb3ee1e892a6bdf47ab413"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_top_10_popular_contents(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        popular_contents = repo.get_top_paths()[:10]\n        return [{'path': content.path, 'count': content.count, 'uniques': content.uniques} for content in popular_contents]\n    except Exception as e:\n        return str(e)", "hash": "b09f1fe8c1c33b529ce741d1beeca6570ae0b7d348aa5c1f5b4efa5463eb14f2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def get_clone_and_view_data(self, input: RepositoryInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        clones = repo.get_clones_traffic()\n        views = repo.get_views_traffic()\n        return {'clones': clones, 'views': views}\n    except Exception as e:\n        return str(e)", "hash": "1a99d41d840ee3d3e75b5cab9cd1dddba59df1476620cffb431664aaa34454e1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "RepositoryNode.def mark_notifications_as_read(self, input: RepositoryInput):\n    try:\n        notifications = self.g.get_user().get_notifications()\n        for notification in notifications:\n            if notification.repository.full_name == f'{input.owner}/{input.repo_name}':\n                notification.mark_as_read()\n        return {'status': 'Notifications marked as read.'}\n    except Exception as e:\n        return str(e)", "hash": "09a1b74d35f9a42128db22f39adcd35b781448b6a6b1546a091574ba568df8d4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_repo_files.py", "code_chunk": "import requests\nfrom github import Github\nfrom ..base_node import BaseNode, NodeConfig\nfrom .github_model import RepositoryInput, GetSpecificContentFileInput, CreateFileInput, EditFileInput, DeleteFileInput\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\nGITHUB_TOKEN = os.environ.get('GITHUB_TOKEN')\nrepository_node_config = {'name': 'repository', 'description': 'A node for interacting with GitHub repositories and files.', 'functions': {'get_repository_topics': 'Get repository topics.', 'get_count_of_stars': 'Get count of stars.', 'get_specific_content_file': 'Get a specific content file.', 'create_file': 'Create a new file in the repository.', 'edit_file': 'Edit a file in the repository.', 'delete_file': 'Delete a file in the repository.', 'get_list_of_open_issues': 'Get a list of open issues.', 'get_list_of_code_scanning_alerts': 'Get a list of code scanning alerts.', 'get_all_labels_of_repository': 'Get all labels of the repository.', 'get_contents_of_root_directory': 'Get contents of the root directory.', 'get_all_contents_recursively': 'Get all contents recursively.', 'get_top_10_referrers': 'Get top 10 referrers.', 'get_top_10_popular_contents': 'Get top 10 popular contents.', 'get_clone_and_view_data': 'Get clone and view data.', 'mark_notifications_as_read': 'Mark notifications as read.'}}", "hash": "9732a8532e64f6c209aadafe4adeb6b90b14e365b8b909d62b4a3d7d17ce6d47"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def __init__(self):\n    super().__init__()", "hash": "0aceb3d9427da005bd9ca664b2b2269217e4c1b75f88825e734fcf252b1402f5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def search_code(self, input: SearchCodeInput):\n    try:\n        result = self.g.search_code(query=input.query, sort=input.sort, order=input.order)\n        return [{'name': item.name, 'path': item.path} for item in result]\n    except Exception as e:\n        return str(e)", "hash": "16332ecea8c591c4d00e938e0ebcdc675f95a0b1defdbd8c6f4e4cc02e8f68fa"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def search_commits(self, input: SearchCommitsInput):\n    try:\n        result = self.g.search_commits(query=input.query, sort=input.sort, order=input.order)\n        return [{'sha': item.sha, 'message': item.commit.message} for item in result]\n    except Exception as e:\n        return str(e)", "hash": "b8db5aaf89eca9f3934f77de45c949fe1e2f33c28e1cb265bb88d3dda1a89036"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def search_issues_and_prs(self, input: SearchIssuesAndPRsInput):\n    try:\n        result = self.g.search_issues(query=input.query, sort=input.sort, order=input.order)\n        return [{'number': item.number, 'title': item.title} for item in result]\n    except Exception as e:\n        return str(e)", "hash": "e12cad27e417baa8ae3800aa3f3a6db5cebf80d6c026ceee0dd4732b7d1483bf"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def search_labels(self, input: SearchLabelsInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        labels = repo.get_labels()\n        return [{'id': label.id, 'name': label.name} for label in labels if input.query.lower() in label.name.lower()]\n    except Exception as e:\n        return str(e)", "hash": "90c62f5574ee9016f38714cf521504ed61360a0d623c30afb27e05bda09b3398"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def search_repositories(self, input: SearchRepositoriesInput):\n    try:\n        result = self.g.search_repositories(query=input.query, sort=input.sort, order=input.order)\n        return [{'full_name': repo.full_name} for repo in result]\n    except Exception as e:\n        return str(e)", "hash": "1745ca28ee18cfe7a332e6af7f41960fd887b141d5bbac20d9573531eda40566"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def search_topics(self, input: SearchTopicsInput):\n    try:\n        result = self.g.search_topics(query=input.query, sort=input.sort, order=input.order)\n        return [{'name': topic.name} for topic in result]\n    except Exception as e:\n        return str(e)", "hash": "f45e2d4b92659b181dfb6d9394746508953c74802d4173912f5d3c4c62c97c4c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def search_users(self, input: SearchUsersInput):\n    try:\n        result = self.g.search_users(query=input.query, sort=input.sort, order=input.order)\n        return [{'login': user.login, 'name': user.name} for user in result]\n    except Exception as e:\n        return str(e)", "hash": "362847d74918f22ed35db89969b4742f376386748e2c23902d64edd3f23cacb1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.GithubNode\nconfig: NodeConfig = NodeConfig(**github_search_node_config)", "hash": "73eca1009d6c7475978bc16f207e6a6cd0d91323efdb2e991e6ca13600de6260"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def __init__(self):\n    super().__init__()", "hash": "0aceb3d9427da005bd9ca664b2b2269217e4c1b75f88825e734fcf252b1402f5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def search_code(self, input: SearchCodeInput):\n    try:\n        result = self.g.search_code(query=input.query, sort=input.sort, order=input.order)\n        return [{'name': item.name, 'path': item.path} for item in result]\n    except Exception as e:\n        return str(e)", "hash": "16332ecea8c591c4d00e938e0ebcdc675f95a0b1defdbd8c6f4e4cc02e8f68fa"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def search_commits(self, input: SearchCommitsInput):\n    try:\n        result = self.g.search_commits(query=input.query, sort=input.sort, order=input.order)\n        return [{'sha': item.sha, 'message': item.commit.message} for item in result]\n    except Exception as e:\n        return str(e)", "hash": "b8db5aaf89eca9f3934f77de45c949fe1e2f33c28e1cb265bb88d3dda1a89036"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def search_issues_and_prs(self, input: SearchIssuesAndPRsInput):\n    try:\n        result = self.g.search_issues(query=input.query, sort=input.sort, order=input.order)\n        return [{'number': item.number, 'title': item.title} for item in result]\n    except Exception as e:\n        return str(e)", "hash": "e12cad27e417baa8ae3800aa3f3a6db5cebf80d6c026ceee0dd4732b7d1483bf"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def search_labels(self, input: SearchLabelsInput):\n    try:\n        repo = self.g.get_repo(f'{input.owner}/{input.repo_name}')\n        labels = repo.get_labels()\n        return [{'id': label.id, 'name': label.name} for label in labels if input.query.lower() in label.name.lower()]\n    except Exception as e:\n        return str(e)", "hash": "90c62f5574ee9016f38714cf521504ed61360a0d623c30afb27e05bda09b3398"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def search_repositories(self, input: SearchRepositoriesInput):\n    try:\n        result = self.g.search_repositories(query=input.query, sort=input.sort, order=input.order)\n        return [{'full_name': repo.full_name} for repo in result]\n    except Exception as e:\n        return str(e)", "hash": "1745ca28ee18cfe7a332e6af7f41960fd887b141d5bbac20d9573531eda40566"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def search_topics(self, input: SearchTopicsInput):\n    try:\n        result = self.g.search_topics(query=input.query, sort=input.sort, order=input.order)\n        return [{'name': topic.name} for topic in result]\n    except Exception as e:\n        return str(e)", "hash": "f45e2d4b92659b181dfb6d9394746508953c74802d4173912f5d3c4c62c97c4c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "GithubSearchNode.def search_users(self, input: SearchUsersInput):\n    try:\n        result = self.g.search_users(query=input.query, sort=input.sort, order=input.order)\n        return [{'login': user.login, 'name': user.name} for user in result]\n    except Exception as e:\n        return str(e)", "hash": "362847d74918f22ed35db89969b4742f376386748e2c23902d64edd3f23cacb1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_search.py", "code_chunk": "from ..base_node import BaseNode, NodeConfig\nfrom .github_node import GithubNode\nfrom .github_model import SearchCodeInput, SearchCommitsInput, SearchIssuesAndPRsInput, SearchLabelsInput, SearchRepositoriesInput, SearchTopicsInput, SearchUsersInput\ngithub_search_node_config = {'name': 'github_search', 'description': 'A node for searching various entities on GitHub.', 'functions': {'search_code': 'Search code.', 'search_commits': 'Search commits.', 'search_issues_and_prs': 'Search issues and pull requests.', 'search_labels': 'Search labels.', 'search_repositories': 'Search repositories.', 'search_topics': 'Search topics.', 'search_users': 'Search users.'}}", "hash": "96fae857f31de38a0ac5c06e7f79831f960bf87aee242e35732db38e325beea6"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_user.py", "code_chunk": "GithubUserNode.def __init__(self):\n    super().__init__()", "hash": "6f569ccf57072763de86f698200a43188e67d13dce3f0e47a23cb4c42a5aa929"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_user.py", "code_chunk": "GithubUserNode.def get_user_repositories(self, input: GetUserRepositoriesInput):\n    try:\n        user = self.g.get_user(input.username)\n        repos = user.get_repos()\n        return [{'id': repo.id, 'name': repo.name} for repo in repos]\n    except Exception as e:\n        return str(e)", "hash": "982b1b79172f11467de071bf36d899d5edc7600f079596c69ec3c083182e6afb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_user.py", "code_chunk": "GithubUserNode.def invite_user_to_org(self, input: InviteUserToOrgInput):\n    try:\n        org = self.g.get_organization(input.org_name)\n        org.invite_user(user=input.username)\n        return f'User {input.username} invited to organization {input.org_name}.'\n    except Exception as e:\n        return str(e)", "hash": "8147eed4720e06e7379efdaaec87241ad99da0a3768d02675691d583565b69ae"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_user.py", "code_chunk": "GithubUserNode.GithubNode\nconfig: NodeConfig = NodeConfig(**github_user_node_config)", "hash": "abc12ab236fb20980f2f18d6445ceefcb8eb0c75a958377318186e948645830a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_user.py", "code_chunk": "GithubUserNode.def __init__(self):\n    super().__init__()", "hash": "6f569ccf57072763de86f698200a43188e67d13dce3f0e47a23cb4c42a5aa929"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_user.py", "code_chunk": "GithubUserNode.def get_user_repositories(self, input: GetUserRepositoriesInput):\n    try:\n        user = self.g.get_user(input.username)\n        repos = user.get_repos()\n        return [{'id': repo.id, 'name': repo.name} for repo in repos]\n    except Exception as e:\n        return str(e)", "hash": "982b1b79172f11467de071bf36d899d5edc7600f079596c69ec3c083182e6afb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_user.py", "code_chunk": "GithubUserNode.def invite_user_to_org(self, input: InviteUserToOrgInput):\n    try:\n        org = self.g.get_organization(input.org_name)\n        org.invite_user(user=input.username)\n        return f'User {input.username} invited to organization {input.org_name}.'\n    except Exception as e:\n        return str(e)", "hash": "8147eed4720e06e7379efdaaec87241ad99da0a3768d02675691d583565b69ae"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\github\\github_user.py", "code_chunk": "from ..base_node import BaseNode, NodeConfig\nfrom .github_node import GithubNode\nfrom .github_model import GetUserRepositoriesInput, InviteUserToOrgInput\ngithub_user_node_config = {'name': 'github_user', 'description': 'A node for interacting with GitHub users.', 'functions': {'get_user_repositories': 'Returns the repositories of a user.', 'invite_user_to_org': 'Invites a user to an organization.'}}", "hash": "d05c618439a2812b4a942a4efcadbe6ab825894640a700c5a8c5cd9152a0ee35"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "OpenAINode.def __init__(self):\n    super().__init__()\n    self.history = []\n    self.functions = []\n    self.cur_role = None\n    self.cur_content = None", "hash": "c0446749e760409ab8b8e11c381a63f38487e7a56d9d26b862d2d7affe6ec59c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "OpenAINode.def complete(self, input: CompleteInput):\n    \"\"\"\n        Complete with only current history. No extra messages.\n        \"\"\"\n    return self._make_completion([], input)", "hash": "97145458dc92352ff5a589dd8a06586af035b72fd1ff4e4bdd12ade325a1bd94"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "OpenAINode.def chat(self, input: ChatInput):\n    \"\"\"\n        Chat with OpenAI's model with simple text.\n        \"\"\"\n    return self._make_completion([Message(role='user', content=input.message_text)], input)", "hash": "95541df109ffee31617bb0ccf87f9aa3ac19fa9a10e5455c50829def46ba39b5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "OpenAINode.def chat_with_prompt_template(self, input: ChatWithPromptTemplateInput):\n    \"\"\"\n        Chat with OpenAI's model with a specific prompt template.\n        \"\"\"\n    return self._make_completion([Message(role='user', content=input.prompt_template.format(**input.params))], input)", "hash": "7749cbd0efedb38e560fc65a21067e6e3bdeee57a74d2e92d4b50264d2891f6c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "OpenAINode.def chat_with_message(self, input: ChatWithMessageInput):\n    \"\"\"\n        Chat with OpenAI's model with a specific message dict.\n        \"\"\"\n    return self._make_completion([input.message], input)", "hash": "1276bed9b6413784a85befd0e6c429e7472747f7b757709458c0027b4e733404"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "OpenAINode.def chat_with_messages(self, input: ChatWithMessagesInput):\n    \"\"\"\n        Chat with OpenAI's model with a specific message dict.\n        \"\"\"\n    return self._make_completion(input.messages, input)", "hash": "5bb6c884e9a5267fe048b3ff30e249559a7bb532c2b65244c46dd894099f30f0"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "OpenAINode.def use_old_openai_with_prompt(self, input: OldCompleteInput):\n    return self._make_old_completion(input.prompt, input)", "hash": "640b67f0ee86c9a77d5abc790e4c95b6432246a2cc9c34f2311f027120c073ec"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "OpenAINode.def _make_old_completion(self, prompt: str, input: OldCompleteConfig) -> OpenAIOldResp:\n    \"\"\"\n        Make a completion with the given messages.\n        \"\"\"\n    kwargs = {'model': input.model, 'max_tokens': 1096}\n    kwargs['prompt'] = prompt\n    if input.use_streaming:\n        kwargs['stream'] = True\n    try:\n        client = OpenAI(api_key=os.getenv('OPENAI_CHAT_API_KEY'))\n        response = client.completions.create(**kwargs)\n    except Exception as e:\n        logging.warn(f'openai_node._make_completion: error occurred: {e}')\n        return OpenAIOldResp(text=f'Error occurred: {e}', finish_reason='error')\n    if input.use_streaming:\n        resp = OpenAIOldResp(text='', finish_reason='')\n        for completion in response:\n            resp.text += completion['choices'][0]['text']\n            if choice.finish_reason:\n                resp.finish_reason = completion['choices'][0]['finish_reason']\n                break\n        return resp\n    resp = OpenAIOldResp(**response.choices[0].model_dump())\n    return resp", "hash": "6665553abc9779d4eb61781b311722dff6421fab6688cbcf0622cae67bde9646"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "OpenAINode.def _make_completion(self, messages: list[Message], input: ChatConfig) -> OpenAIResp | OpenAIStreamingResp:\n    \"\"\"\n        Make a completion with the given messages.\n        \"\"\"\n    kwargs = {'model': input.model}\n    cur_messages = []\n    if len(self.history) == 0:\n        cur_messages.append(Message(role='system', content=\"You are a helpful AI assistant. You should answer the user's questions and help them with their tasks.\").dict(exclude_none=True))\n    else:\n        cur_messages += self.history\n    if input.append_history:\n        for message in messages:\n            self.add_single_message(message)\n    for message in messages:\n        cur_messages.append(message.dict(exclude_none=True))\n    kwargs['messages'] = tt.trim(cur_messages, input.model, max_tokens=9999)\n    if len(self.functions) > 0:\n        kwargs['functions'] = self.functions\n        kwargs['function_call'] = 'auto'\n    if input.use_streaming:\n        kwargs['stream'] = True\n    try:\n        client = OpenAI(api_key=os.getenv('OPENAI_CHAT_API_KEY'))\n        response = client.chat.completions.create(**kwargs)\n    except Exception as e:\n        logging.warn(f'openai_node._make_completion: error occurred: {e}')\n        return OpenAIResp(message=Message(role='system', content=f'Error occurred: {e}'), finish_reason='error')\n    if input.use_streaming:\n        resp = OpenAIStreamingResp(**response.choices[0].dict())\n        if input.append_history:\n            self.history.append(resp.delta.dict(exclude_none=True))\n        return resp\n    resp = OpenAIResp(**response.choices[0].dict())\n    if input.append_history:\n        self.history.append(resp.message.dict(exclude_none=True))\n    return resp", "hash": "2dc32235142896a366c70dc09239de6225e752a28c4367fbd0e4f793bbd4d9ae"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "OpenAINode.def add_function(self, func_def: FunctionDefinition):\n    self.functions.append(func_def.dict())", "hash": "74140d85ae82265a9da8e60c447ed0cd3cda0cea6a42379c84b35ea59c1984bb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "OpenAINode.def add_single_message(self, msg: Message):\n    if self.cur_role is not None and self.cur_content is not None:\n        self.history.append(Message(role=self.cur_role, content=self.cur_content).dict(exclude_none=True))\n        self.cur_role = None\n        self.cur_content = None\n    self.history.append(msg.dict(exclude_none=True))", "hash": "0e98d7c4dc1c2c868a2b63490527d37089f6ddd594e77397374b9bebd279bf5a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "OpenAINode.def add_system_message(self, content: str):\n    self.add_single_message(Message(role='system', content=content))", "hash": "50a0fcd278a598ec3c87d19c62557ef7c99466ce875f78b9e1a8210c1c6963a3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "OpenAINode.def add_role(self, role: str):\n    if self.cur_role is not None and self.cur_content is not None:\n        self.add_single_message(Message(role=self.cur_role, content=self.cur_content))\n    self.cur_role = role", "hash": "c7952c087d69af96e951391241e9c87b1c033aa2c84429a7fd16c066867f834b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "OpenAINode.def add_content(self, content: str):\n    if self.cur_content is not None:\n        self.cur_content += content\n    else:\n        self.cur_content = content", "hash": "0a05689eeddfabfdb1c36306b0a936d89920f260f1bde0c1e22a09faa04b961a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "OpenAINode.BaseNode\nconfig: NodeConfig = NodeConfig(**openai_node_config)\nhistory: list[dict[str, any]]\nfunctions: list[dict[str, any]]\ncur_role: Optional[str]\ncur_content: Optional[str]", "hash": "2228587e3fa4e9088a548092bc06f2fad970bf4998aac917b4a59f24199eb3a8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def __init__(self):\n    super().__init__()\n    self.history = []\n    self.functions = []\n    self.cur_role = None\n    self.cur_content = None\n    openai.api_key = os.getenv('OPENAI_CHAT_API_KEY')\n    openai.api_base = os.getenv('OPENAI_CHAT_API_BASE')", "hash": "c3763211123f8cb5d6d8db353f70c3b602f703abd9c3817f5608e02491f5e7f3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def add_function(self, func_def: FunctionDefinition):\n    self.functions.append(func_def.dict())", "hash": "935133afc71de6a9fd194abd5699e298e5a16e07b620b5a554492a36450432c2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def add_single_message(self, msg: Message):\n    if self.cur_role is not None and self.cur_content is not None:\n        self.history.append(Message(role=self.cur_role, content=self.cur_content).dict(exclude_none=True))\n        self.cur_role = None\n        self.cur_content = None\n    self.history.append(msg.dict(exclude_none=True))", "hash": "b70e91e58ce2ece713adbcc528abd37eaea03cb72ee2b952407712584ec3c2c2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def add_system_message(self, content: str):\n    self.add_single_message(Message(role='system', content=content))", "hash": "2cacc3ffa38e01529e9df2f06e66718583141560bd2e21e1d0130ac0330ce12a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def add_role(self, role: str):\n    if self.cur_role is not None and self.cur_content is not None:\n        self.add_single_message(Message(role=self.cur_role, content=self.cur_content))\n    self.cur_role = role", "hash": "8ca68f4c9e37e04576c837b66706db2602325898daf442d541fda22397cbc551"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def add_content(self, content: str):\n    if self.cur_content is not None:\n        self.cur_content += content\n    else:\n        self.cur_content = content", "hash": "d9eae548ecadc03b7d85a4483c5e53d2b3a65f37a44f645e58f6132c02b7faf3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.BaseNode\nconfig: NodeConfig = NodeConfig(**openai_node_config)\nhistory: list[dict[str, any]]\nfunctions: list[dict[str, any]]\ncur_role: Optional[str]\ncur_content: Optional[str]\nasync def complete(self, input: CompleteInput):\n    \"\"\"\n        Complete with only current history. No extra messages.\n        \"\"\"\n    return await self._make_completion([], input)\nasync def chat(self, input: ChatInput):\n    \"\"\"\n        Chat with OpenAI's model with simple text.\n        \"\"\"\n    return await self._make_completion([Message(role='user', content=input.message_text)], input)\nasync def chat_with_prompt_template(self, input: ChatWithPromptTemplateInput):\n    \"\"\"\n        Chat with OpenAI's model with a specific prompt template.\n        \"\"\"\n    return await self._make_completion([Message(role='user', content=input.prompt_template.format(**input.params))], input)\nasync def chat_with_message(self, input: ChatWithMessageInput):\n    \"\"\"\n        Chat with OpenAI's model with a specific message dict.\n        \"\"\"\n    return await self._make_completion([input.message], input)\nasync def chat_with_messages(self, input: ChatWithMessagesInput):\n    \"\"\"\n        Chat with OpenAI's model with a specific message dict.\n        \"\"\"\n    return await self._make_completion(input.messages, input)\nasync def use_old_openai_with_prompt(self, input: OldCompleteInput):\n    return await self._make_old_completion(input.prompt, input)\nasync def _make_old_completion(self, prompt: str, input: OldCompleteConfig) -> OpenAIOldResp:\n    \"\"\"\n        Make a completion with the given messages.\n        \"\"\"\n    kwargs = {'model': input.model, 'max_tokens': 1096}\n    kwargs['prompt'] = prompt\n    if input.use_streaming:\n        kwargs['stream'] = True\n    try:\n        client = OpenAI(api_key=os.getenv('OPENAI_CHAT_API_KEY'))\n        response = client.completions.create(**kwargs)\n    except Exception as e:\n        logging.warn(f'openai_node._make_completion: error occurred: {e}')\n        return OpenAIOldResp(text=f'Error occurred: {e}', finish_reason='error')\n    if input.use_streaming:\n        resp = OpenAIOldResp(text='', finish_reason='')\n        for completion in response:\n            resp.text += completion['choices'][0]['text']\n            if choice.finish_reason:\n                resp.finish_reason = completion['choices'][0]['finish_reason']\n                break\n        return resp\n    resp = OpenAIOldResp(**response.choices[0].model_dump())\n    return resp\nasync def _make_completion(self, messages: list[Message], input: ChatConfig) -> OpenAIResp | OpenAIStreamingResp:\n    \"\"\"\n        Make a completion with the given messages.\n        \"\"\"\n    kwargs = {'model': input.model}\n    cur_messages = []\n    if len(self.history) == 0:\n        cur_messages.append(Message(role='system', content=\"You are a helpful AI assistant. You should answer the user's questions and help them with their tasks.\").dict(exclude_none=True))\n    else:\n        cur_messages += self.history\n    if input.append_history:\n        for message in messages:\n            self.add_single_message(message)\n    for message in messages:\n        cur_messages.append(message.dict(exclude_none=True))\n    kwargs['messages'] = tt.trim(cur_messages, input.model, max_tokens=9999)\n    if len(self.functions) > 0:\n        kwargs['functions'] = self.functions\n        kwargs['function_call'] = 'auto'\n    if input.use_streaming:\n        kwargs['stream'] = True\n    try:\n        client = AsyncOpenAI(api_key=os.getenv('OPENAI_CHAT_API_KEY'))\n        response = await client.chat.completions.create(**kwargs)\n    except Exception as e:\n        return OpenAIResp(message=Message(role='system', content=f'Error occurred: {e}'), finish_reason='error')\n    if input.use_streaming:\n        resp = OpenAIStreamingResp(**response.choices[0].dict())\n        if input.append_history:\n            self.history.append(resp.delta.dict(exclude_none=True))\n        return resp\n    resp = OpenAIResp(**response.choices[0].dict())\n    if input.append_history:\n        self.history.append(resp.message.dict(exclude_none=True))\n    return resp", "hash": "20978faed006a7af0c88a76051abebfe3fbddcf79136b0a705bc361b847d1c53"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def __init__(self):\n    super().__init__()\n    self.history = []\n    self.functions = []\n    self.cur_role = None\n    self.cur_content = None", "hash": "0ee6d14fb94248673f0c044b9d2454bede1446285fbbcfe7109083c795cff625"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def complete(self, input: CompleteInput):\n    \"\"\"\n        Complete with only current history. No extra messages.\n        \"\"\"\n    return self._make_completion([], input)", "hash": "48653c777c84416d7470467f42923ed69ad11d6832cdde0d4e00dc97c36036a6"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def chat(self, input: ChatInput):\n    \"\"\"\n        Chat with OpenAI's model with simple text.\n        \"\"\"\n    return self._make_completion([Message(role='user', content=input.message_text)], input)", "hash": "f59cab2c7ec5571e4681f85ec77495ca50ee2daa75c70e75397f52ef1d5e8965"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def chat_with_prompt_template(self, input: ChatWithPromptTemplateInput):\n    \"\"\"\n        Chat with OpenAI's model with a specific prompt template.\n        \"\"\"\n    return self._make_completion([Message(role='user', content=input.prompt_template.format(**input.params))], input)", "hash": "5d2708823a732195603d667734f5b71ecab9765ffaeaf75c6e4004d9c756126d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def chat_with_message(self, input: ChatWithMessageInput):\n    \"\"\"\n        Chat with OpenAI's model with a specific message dict.\n        \"\"\"\n    return self._make_completion([input.message], input)", "hash": "32e1bd67f09f4e1a86c20a586580353166fe0d66568e3a08fcfcca2e294282de"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def chat_with_messages(self, input: ChatWithMessagesInput):\n    \"\"\"\n        Chat with OpenAI's model with a specific message dict.\n        \"\"\"\n    return self._make_completion(input.messages, input)", "hash": "c54ba4a48a93b71b81565e4b4688e942d1b11e1dd41008c235a59ed1ca120ece"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def use_old_openai_with_prompt(self, input: OldCompleteInput):\n    return self._make_old_completion(input.prompt, input)", "hash": "1a70879c6cb5908db5cff848ba802ee8ba98efd7122783fae9786927e7e99410"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def _make_old_completion(self, prompt: str, input: OldCompleteConfig) -> OpenAIOldResp:\n    \"\"\"\n        Make a completion with the given messages.\n        \"\"\"\n    kwargs = {'model': input.model, 'max_tokens': 1096}\n    kwargs['prompt'] = prompt\n    if input.use_streaming:\n        kwargs['stream'] = True\n    try:\n        client = OpenAI(api_key=os.getenv('OPENAI_CHAT_API_KEY'))\n        response = client.completions.create(**kwargs)\n    except Exception as e:\n        logging.warn(f'openai_node._make_completion: error occurred: {e}')\n        return OpenAIOldResp(text=f'Error occurred: {e}', finish_reason='error')\n    if input.use_streaming:\n        resp = OpenAIOldResp(text='', finish_reason='')\n        for completion in response:\n            resp.text += completion['choices'][0]['text']\n            if choice.finish_reason:\n                resp.finish_reason = completion['choices'][0]['finish_reason']\n                break\n        return resp\n    resp = OpenAIOldResp(**response.choices[0].model_dump())\n    return resp", "hash": "e1ca2be132a15c7bcc54a8a24cdae5687f1b066392c17c60e67a4f83be93c12d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def _make_completion(self, messages: list[Message], input: ChatConfig) -> OpenAIResp | OpenAIStreamingResp:\n    \"\"\"\n        Make a completion with the given messages.\n        \"\"\"\n    kwargs = {'model': input.model}\n    cur_messages = []\n    if len(self.history) == 0:\n        cur_messages.append(Message(role='system', content=\"You are a helpful AI assistant. You should answer the user's questions and help them with their tasks.\").dict(exclude_none=True))\n    else:\n        cur_messages += self.history\n    if input.append_history:\n        for message in messages:\n            self.add_single_message(message)\n    for message in messages:\n        cur_messages.append(message.dict(exclude_none=True))\n    kwargs['messages'] = tt.trim(cur_messages, input.model, max_tokens=9999)\n    if len(self.functions) > 0:\n        kwargs['functions'] = self.functions\n        kwargs['function_call'] = 'auto'\n    if input.use_streaming:\n        kwargs['stream'] = True\n    try:\n        client = OpenAI(api_key=os.getenv('OPENAI_CHAT_API_KEY'))\n        response = client.chat.completions.create(**kwargs)\n    except Exception as e:\n        logging.warn(f'openai_node._make_completion: error occurred: {e}')\n        return OpenAIResp(message=Message(role='system', content=f'Error occurred: {e}'), finish_reason='error')\n    if input.use_streaming:\n        resp = OpenAIStreamingResp(**response.choices[0].dict())\n        if input.append_history:\n            self.history.append(resp.delta.dict(exclude_none=True))\n        return resp\n    resp = OpenAIResp(**response.choices[0].dict())\n    if input.append_history:\n        self.history.append(resp.message.dict(exclude_none=True))\n    return resp", "hash": "69e13c4bd6d7227f17421ee61e3adb38298caecf3cb35af959a64ee89f2eac58"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def add_function(self, func_def: FunctionDefinition):\n    self.functions.append(func_def.dict())", "hash": "935133afc71de6a9fd194abd5699e298e5a16e07b620b5a554492a36450432c2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def add_single_message(self, msg: Message):\n    if self.cur_role is not None and self.cur_content is not None:\n        self.history.append(Message(role=self.cur_role, content=self.cur_content).dict(exclude_none=True))\n        self.cur_role = None\n        self.cur_content = None\n    self.history.append(msg.dict(exclude_none=True))", "hash": "b70e91e58ce2ece713adbcc528abd37eaea03cb72ee2b952407712584ec3c2c2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def add_system_message(self, content: str):\n    self.add_single_message(Message(role='system', content=content))", "hash": "2cacc3ffa38e01529e9df2f06e66718583141560bd2e21e1d0130ac0330ce12a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def add_role(self, role: str):\n    if self.cur_role is not None and self.cur_content is not None:\n        self.add_single_message(Message(role=self.cur_role, content=self.cur_content))\n    self.cur_role = role", "hash": "8ca68f4c9e37e04576c837b66706db2602325898daf442d541fda22397cbc551"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def add_content(self, content: str):\n    if self.cur_content is not None:\n        self.cur_content += content\n    else:\n        self.cur_content = content", "hash": "d9eae548ecadc03b7d85a4483c5e53d2b3a65f37a44f645e58f6132c02b7faf3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def __init__(self):\n    super().__init__()\n    self.history = []\n    self.functions = []\n    self.cur_role = None\n    self.cur_content = None\n    openai.api_key = os.getenv('OPENAI_CHAT_API_KEY')\n    openai.api_base = os.getenv('OPENAI_CHAT_API_BASE')", "hash": "c3763211123f8cb5d6d8db353f70c3b602f703abd9c3817f5608e02491f5e7f3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def add_function(self, func_def: FunctionDefinition):\n    self.functions.append(func_def.dict())", "hash": "935133afc71de6a9fd194abd5699e298e5a16e07b620b5a554492a36450432c2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def add_single_message(self, msg: Message):\n    if self.cur_role is not None and self.cur_content is not None:\n        self.history.append(Message(role=self.cur_role, content=self.cur_content).dict(exclude_none=True))\n        self.cur_role = None\n        self.cur_content = None\n    self.history.append(msg.dict(exclude_none=True))", "hash": "b70e91e58ce2ece713adbcc528abd37eaea03cb72ee2b952407712584ec3c2c2"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def add_system_message(self, content: str):\n    self.add_single_message(Message(role='system', content=content))", "hash": "2cacc3ffa38e01529e9df2f06e66718583141560bd2e21e1d0130ac0330ce12a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def add_role(self, role: str):\n    if self.cur_role is not None and self.cur_content is not None:\n        self.add_single_message(Message(role=self.cur_role, content=self.cur_content))\n    self.cur_role = role", "hash": "8ca68f4c9e37e04576c837b66706db2602325898daf442d541fda22397cbc551"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "AsyncOpenAINode.def add_content(self, content: str):\n    if self.cur_content is not None:\n        self.cur_content += content\n    else:\n        self.cur_content = content", "hash": "d9eae548ecadc03b7d85a4483c5e53d2b3a65f37a44f645e58f6132c02b7faf3"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai.py", "code_chunk": "import openai\nfrom openai import OpenAI, AsyncOpenAI\nimport os\nfrom typing import Optional\nimport tokentrim as tt\nfrom ..base_node import BaseNode, NodeConfig\nfrom .openai_model import *\nimport logging\nopenai_node_config = {'name': 'openai', 'description': \"A node that interacts with OpenAI's GPT-3 model.\", 'functions': {'chat': \"Chat with OpenAI's LLM model.\", 'chat_with_prompt_template': \"Chat with OpenAI's LLM model with a specific prompt template.\", 'chat_with_message': \"Chat with OpenAI's LLM model with a specific message dict.\"}}", "hash": "3de7d9df529da35e44769727e8fae4b71880a74aa1b203c4f2dc72c2b336b3e8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "OpenAIModel.str\nEnum\nGPT_4 = 'gpt-4'\nGPT_4_0613 = 'gpt-4-0613'\nGPT_4_32K = 'gpt-4-32k'\nGPT_4_32K_0613 = 'gpt-4-32k-0613'\nGPT_4_1106_PREVIEW = 'gpt-4-1106-preview'\nGPT_3_5_TURBO = 'gpt-3.5-turbo'\nGPT_3_5_TURBO_16K = 'gpt-3.5-turbo-16k'\nGPT_3_5_TURBO_INSTRUCT = 'gpt-3.5-turbo-instruct'\nGPT_3_5_TURBO_0613 = 'gpt-3.5-turbo-0613'\nGPT_3_5_TURBO_16K_0613 = 'gpt-3.5-turbo-16k-0613'\nTEXT_MODERATION_LATEST = 'text-moderation-latest'\nTEXT_MODERATION_STABLE = 'text-moderation-stable'", "hash": "59081e02f528df561f79e8a947fdc934954c13d9742693f35bba8de6e3b6d377"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "Message.BaseModel\n'\\n    Message for OpenAI chat.\\n    '\nclass FunctionCall(BaseModel):\n    \"\"\"\n        The name and arguments of a function that should be called, as generated by the model.\n        \"\"\"\n    name: str = Field(description='Name of the function to call.')\n    arguments: str = Field(description='Arguments to call the function with, as generated by the model in JSON format.')\nrole: Optional[str] = Field(description='Role of the message.')\nname: Optional[str] = Field(description='Name of the message.')\ncontent: Optional[str] = Field(description='Content of the message.')\nfunction_call: Optional[FunctionCall] = Field(description='Function call of the message.')", "hash": "07d7c8e660acc480aba6baad5eac1006cffee3436d682def8f9ce80634310d08"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "FunctionDefinition.def dict(self) -> dict[str, any]:\n    return {'name': self.name, 'description': self.description, 'parameters': {'type': 'object', 'properties': {param.name: {'type': 'string', 'description': param.description} for param in self.parameters}, 'required': [param.name for param in self.parameters if param.required]}}", "hash": "5eaf0623dbec1991662aafc01562e8dc0e626bc5a6465b6e10b912255fc0a67f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "FunctionDefinition.BaseModel\n'\\n    Function definition for OpenAI function call.\\n    '\nclass FunctionParameter(BaseModel):\n    \"\"\"\n        Parameter for OpenAI function call.\n        \"\"\"\n    name: str = Field(description='Name of the parameter.')\n    description: str = Field(description='Description of the parameter.')\n    required: bool = Field(default=True, description='Whether the parameter is required or not.')\nname: str = Field('Name of the function.')\ndescription: str = Field('Description of the function.')\nparameters: list[FunctionParameter] = Field('Parameters of the function.')", "hash": "791fdddc2b9c0e29e3dc2abf9647ee3b8676f00933cd84c92f3d9e8b63d9417d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "ChatConfig.BaseModel\nmodel: OpenAIModel = Field(description='Model to use for chat.')\nuse_streaming: bool = Field(default=False, description='Whether to use streaming output or not.')\nappend_history: bool = Field(default=False, description='Whether to append this message to history.')", "hash": "74e022c429cde2e952564788a2dbaabb469e16bbde419f73bcffa71abb759a52"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "OldCompleteConfig.BaseModel\nmodel: OpenAIModel = Field(description='Model to use for chat.')\nuse_streaming: bool = Field(default=False, description='Whether to use streaming output or not.')", "hash": "ab54c2b21f5761650d618bb6f57c7fcc9facd96957eeadeb61376c094d6a5a65"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "OldCompleteInput.OldCompleteConfig\nprompt: str = Field(description='prompt to use for model.')", "hash": "6bcb622e6844dfd1a9f6c660f3379bd785b5ba720d4aa85975795ed24af34ca5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "CompleteInput.ChatConfig\npass", "hash": "f3ead6d573aec5c2c916c2842b482746af33dd8914610ad64f1ab8cc591f7df9"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "ChatInput.ChatConfig\nmessage_text: str = Field(description='Message to chat.')", "hash": "b6dd80316f4629d50be3dd439dbf1c20d542c684f96ba0d88f219494bdef05a5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "ChatWithPromptTemplateInput.ChatConfig\nprompt_template: str = Field(description='Prompt template for chat.')\nparams: dict[str, str] = Field(description='Parameters for prompt template.')", "hash": "c0fce0c3bd1420958802b105b8f8385d8245ff12a65baa1c28e787339b700b8b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "ChatWithMessageInput.ChatConfig\nmessage: Message = Field(description='Message to chat.')", "hash": "56aa4995dafbe5eb4edc1336f0143de5840ce8e90f56c05bebc7f07f00dc0beb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "ChatWithMessagesInput.ChatConfig\nmessages: list[Message] = Field(description='Messages to chat.')", "hash": "714164aa3f67a8f37cbc5e6841890ceea8a55c6209b96ad874bbb881cf31edaf"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "OpenAIResp.BaseModel\n\"\\n    Response from OpenAI with no streaming. It's a chat completion object.\\n    \"\nmessage: Message = Field(description='Response message')\nfinish_reason: str = Field(description='Finish reason.')", "hash": "744505e8e3f79d1b2853efab7138c16af003968d26b07f75a2fa9ddd28067e24"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "OpenAIStreamingResp.BaseModel\n'\\n    Response from OpenAI with streaming.\\n    '\ndelta: Message = Field(description='Delta message')\nfinish_reason: str = Field(description='Finish reason.')", "hash": "4d82ef5b9a46aea71d8d64601e24e8639393dd21ae08b0083bc7b221695a3d41"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "OpenAIOldResp.BaseModel\n\"\\n    Response from OpenAI with no streaming. It's a chat completion object.\\n    \"\ntext: str = Field(description='Response message')\nfinish_reason: str = Field(description='Finish reason.')", "hash": "5f11a9846d52e164ef1b2627e2dd6559d04447fc9367bfddb6f43f52451b6341"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "FunctionCall.BaseModel\n'\\n        The name and arguments of a function that should be called, as generated by the model.\\n        '\nname: str = Field(description='Name of the function to call.')\narguments: str = Field(description='Arguments to call the function with, as generated by the model in JSON format.')", "hash": "e0b960779357b4c0b058a03c5373cfb492e1c88f8a2af0f75593dabd8b55ba5c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "FunctionParameter.BaseModel\n'\\n        Parameter for OpenAI function call.\\n        '\nname: str = Field(description='Name of the parameter.')\ndescription: str = Field(description='Description of the parameter.')\nrequired: bool = Field(default=True, description='Whether the parameter is required or not.')", "hash": "c95c8e9b8b2fc36b44b737bae0bac18e2413ccdb26a319c605585276462b8133"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "FunctionParameter.def dict(self) -> dict[str, any]:\n    return {'name': self.name, 'description': self.description, 'parameters': {'type': 'object', 'properties': {param.name: {'type': 'string', 'description': param.description} for param in self.parameters}, 'required': [param.name for param in self.parameters if param.required]}}", "hash": "899393ff96c8c91315f0f971d8565171f1e914b9abb93adc081e557830041ca1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\nodes\\openai\\openai_model.py", "code_chunk": "from enum import Enum\nfrom typing import Optional\nfrom pydantic import BaseModel, Field", "hash": "e4721f5b6ea2cdd8b9632971b841f1b0cddeef4888ef528674d33462efda7c3c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def __init__(self):\n    \"\"\"\n        Initialize a Redis client instance.\n        \"\"\"\n    self.redis = redis.Redis(host='redis', port=6379, decode_responses=True)", "hash": "385f3c489ddb56c1a8cd5ce8f2e838d575f010b4ec6941ee81be1ce1dcff6c92"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def get(self, key: str) -> str:\n    \"\"\"\n        Get the value of a key from Redis.\n\n        Args:\n            key (str): The key to retrieve the value for.\n\n        Returns:\n            str: The value of the key.\n        \"\"\"\n    return self.redis.get(key)", "hash": "32c1823a6c9fe9b240f1f47aa7396fa00d0b7d38135db7b0f04eb4445e6ead27"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def set(self, key: str, value: str, save: bool=True) -> str:\n    \"\"\"\n        Set the value of a key in Redis.\n\n        Args:\n            key (str): The key to set the value for.\n            value (str): The value to set for the key.\n            save (bool, optional): Whether to save the changes to disk, by default True.\n\n        Returns:\n            Optional[str]: If `save` is True, returns the Redis response to the SAVE command.\n        \"\"\"\n    self.redis.set(key, value)\n    if save:\n        return self.redis.save()", "hash": "e484b2a160767ea6011471a510ab3e4261e148275743c3b6dda75da792301178"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def exists(self, key: str) -> bool:\n    \"\"\"\n        Check if a key exists in Redis.\n\n        Args:\n            key (str): The key to check for existence.\n\n        Returns:\n            bool: True if the key exists, False otherwise.\n        \"\"\"\n    return self.redis.exists(key)", "hash": "65788ee85a61709da2bd051454182bc5932ec749471b0cbca396f283abcf8afb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def save(self) -> str:\n    \"\"\"\n        Export all key-value pairs to an RDB file.\n\n        Returns:\n            Optional[str]: The Redis response to the SAVE command.\n        \"\"\"\n    return self.redis.save()", "hash": "0e4a4037cd1604d70cefb049e85ed788c0c732d0c1fdd67ac501991740b21458"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def safe_get(self, key: str) -> str:\n    \"\"\"\n        Get the value of a key from Redis and json loads the value.\n\n        Args:\n            key (str): The key to retrieve the value for.\n\n        Returns:\n            str: The value of the key.\n        \"\"\"\n    return json.loads(self.redis.get(key))", "hash": "1ea4046814da33416a8181ca5047e63f7493e034bccaf5bacc972238adc870dc"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def safe_set(self, key: str, value, save: bool=True):\n    \"\"\"\n        Set the value of a key in Redis and dumps into json before setting.\n\n        Args:\n            key (str): The key to set the value for.\n            value (str): The value to set for the key.\n            save (bool, optional): Whether to save the changes to disk, by default True.\n\n        Returns:\n            Optional[str]: If `save` is True, returns the Redis response to the SAVE command.\n        \"\"\"\n    self.redis.set(key, json.dumps(value))\n    if save:\n        return self.redis.save()", "hash": "0779e976f6f02f319d74e1b4c4a6fcf92f321d904531d116a5413a40e080856c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def print_all(self):\n    \"\"\"\n        Print all keys and their corresponding values in Redis.\n        \"\"\"\n    for key in self.redis.keys():\n        print(f'{key}: {self.redis.get(key)}')", "hash": "1ffa5787018bea1b672f7b697d637bd2eeaaab8a68bb1f64f0057a988d99e84a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def exists_with_key_type(self, user_properties: UserProperties, type: RedisKeyType):\n    \"\"\"\n        Check if a key exists in Redis with a specific key type.\n\n        Args:\n            user_properties (UserProperties): The user properties.\n            type (RedisKeyType): The Redis key type.\n\n        Returns:\n            bool: True if the key exists, False otherwise.\n        \"\"\"\n    return self.redis.exists(user_properties.generate_redis_key_with_type(type))", "hash": "4e607911c006ce34c917b82a7a401f131bf072ad33567278a969aae90e1568ab"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def safe_get_with_key_type(self, user_properties: UserProperties, type: RedisKeyType):\n    \"\"\"\n        Get the value of a key from Redis with a specific key type and json loads the value.\n\n        Args:\n            user_properties (UserProperties): The user properties.\n            type (RedisKeyType): The Redis key type.\n\n        Returns:\n            str: The value of the key.\n        \"\"\"\n    return json.loads(self.redis.get(user_properties.generate_redis_key_with_type(type)))", "hash": "fd5c620b2b498f63c94c4986dad2da424306dbd8af1697304126274102e57f64"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def safe_set_with_key_type(self, user_properties: UserProperties, type: RedisKeyType, value, save: bool=True):\n    \"\"\"\n        Set the value of a key in Redis with a specific key type and dumps into json before setting.\n\n        Args:\n            user_properties (UserProperties): The user properties.\n            type (RedisKeyType): The Redis key type.\n            value (str): The value to set for the key.\n            save (bool, optional): Whether to save the changes to disk, by default True.\n\n        Returns:\n            Optional[str]: If `save` is True, returns the Redis response to the SAVE command.\n        \"\"\"\n    self.redis.set(user_properties.generate_redis_key_with_type(type), json.dumps(value))\n    if save:\n        return self.redis.save()", "hash": "2db72456d00d43b1ecaeb471c173a5695b84457c157b38317ce6be56071e08c7"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.'\\n    A class for interacting with Redis database.\\n    '\nSingleton", "hash": "1cfb16f9cd5a65acb7b8fb1adbaa0a52bd9cee91934b2535261617e3f23a6956"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def __init__(self):\n    \"\"\"\n        Initialize a Redis client instance.\n        \"\"\"\n    self.redis = redis.Redis(host='redis', port=6379, decode_responses=True)", "hash": "385f3c489ddb56c1a8cd5ce8f2e838d575f010b4ec6941ee81be1ce1dcff6c92"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def get(self, key: str) -> str:\n    \"\"\"\n        Get the value of a key from Redis.\n\n        Args:\n            key (str): The key to retrieve the value for.\n\n        Returns:\n            str: The value of the key.\n        \"\"\"\n    return self.redis.get(key)", "hash": "32c1823a6c9fe9b240f1f47aa7396fa00d0b7d38135db7b0f04eb4445e6ead27"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def set(self, key: str, value: str, save: bool=True) -> str:\n    \"\"\"\n        Set the value of a key in Redis.\n\n        Args:\n            key (str): The key to set the value for.\n            value (str): The value to set for the key.\n            save (bool, optional): Whether to save the changes to disk, by default True.\n\n        Returns:\n            Optional[str]: If `save` is True, returns the Redis response to the SAVE command.\n        \"\"\"\n    self.redis.set(key, value)\n    if save:\n        return self.redis.save()", "hash": "e484b2a160767ea6011471a510ab3e4261e148275743c3b6dda75da792301178"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def exists(self, key: str) -> bool:\n    \"\"\"\n        Check if a key exists in Redis.\n\n        Args:\n            key (str): The key to check for existence.\n\n        Returns:\n            bool: True if the key exists, False otherwise.\n        \"\"\"\n    return self.redis.exists(key)", "hash": "65788ee85a61709da2bd051454182bc5932ec749471b0cbca396f283abcf8afb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def save(self) -> str:\n    \"\"\"\n        Export all key-value pairs to an RDB file.\n\n        Returns:\n            Optional[str]: The Redis response to the SAVE command.\n        \"\"\"\n    return self.redis.save()", "hash": "0e4a4037cd1604d70cefb049e85ed788c0c732d0c1fdd67ac501991740b21458"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def safe_get(self, key: str) -> str:\n    \"\"\"\n        Get the value of a key from Redis and json loads the value.\n\n        Args:\n            key (str): The key to retrieve the value for.\n\n        Returns:\n            str: The value of the key.\n        \"\"\"\n    return json.loads(self.redis.get(key))", "hash": "1ea4046814da33416a8181ca5047e63f7493e034bccaf5bacc972238adc870dc"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def safe_set(self, key: str, value, save: bool=True):\n    \"\"\"\n        Set the value of a key in Redis and dumps into json before setting.\n\n        Args:\n            key (str): The key to set the value for.\n            value (str): The value to set for the key.\n            save (bool, optional): Whether to save the changes to disk, by default True.\n\n        Returns:\n            Optional[str]: If `save` is True, returns the Redis response to the SAVE command.\n        \"\"\"\n    self.redis.set(key, json.dumps(value))\n    if save:\n        return self.redis.save()", "hash": "0779e976f6f02f319d74e1b4c4a6fcf92f321d904531d116a5413a40e080856c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def print_all(self):\n    \"\"\"\n        Print all keys and their corresponding values in Redis.\n        \"\"\"\n    for key in self.redis.keys():\n        print(f'{key}: {self.redis.get(key)}')", "hash": "1ffa5787018bea1b672f7b697d637bd2eeaaab8a68bb1f64f0057a988d99e84a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def exists_with_key_type(self, user_properties: UserProperties, type: RedisKeyType):\n    \"\"\"\n        Check if a key exists in Redis with a specific key type.\n\n        Args:\n            user_properties (UserProperties): The user properties.\n            type (RedisKeyType): The Redis key type.\n\n        Returns:\n            bool: True if the key exists, False otherwise.\n        \"\"\"\n    return self.redis.exists(user_properties.generate_redis_key_with_type(type))", "hash": "4e607911c006ce34c917b82a7a401f131bf072ad33567278a969aae90e1568ab"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def safe_get_with_key_type(self, user_properties: UserProperties, type: RedisKeyType):\n    \"\"\"\n        Get the value of a key from Redis with a specific key type and json loads the value.\n\n        Args:\n            user_properties (UserProperties): The user properties.\n            type (RedisKeyType): The Redis key type.\n\n        Returns:\n            str: The value of the key.\n        \"\"\"\n    return json.loads(self.redis.get(user_properties.generate_redis_key_with_type(type)))", "hash": "fd5c620b2b498f63c94c4986dad2da424306dbd8af1697304126274102e57f64"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "Redis.def safe_set_with_key_type(self, user_properties: UserProperties, type: RedisKeyType, value, save: bool=True):\n    \"\"\"\n        Set the value of a key in Redis with a specific key type and dumps into json before setting.\n\n        Args:\n            user_properties (UserProperties): The user properties.\n            type (RedisKeyType): The Redis key type.\n            value (str): The value to set for the key.\n            save (bool, optional): Whether to save the changes to disk, by default True.\n\n        Returns:\n            Optional[str]: If `save` is True, returns the Redis response to the SAVE command.\n        \"\"\"\n    self.redis.set(user_properties.generate_redis_key_with_type(type), json.dumps(value))\n    if save:\n        return self.redis.save()", "hash": "2db72456d00d43b1ecaeb471c173a5695b84457c157b38317ce6be56071e08c7"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\core\\service\\redis.py", "code_chunk": "from ...utils.singleton import Singleton\nfrom ..common_models import UserProperties, RedisKeyType\nimport redis\nfrom pathlib import Path\nimport json\nfrom enum import Enum", "hash": "e1ad0364e9edb6e269313b92e85a2fdcf59edcb0efe9a18c9d7f3ac9b2601359"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\interaction.py", "code_chunk": "def user_input(message: str, prefix='>>> ', arg_type=str):\n    questions = inquirer.Text('_arg', message=prefix + message)\n    return arg_type(inquirer.prompt([questions])['_arg'])", "hash": "ca1166bbdc03456ce420fe567a8cefce52da7ea422feaf34b7c0d119f2643b49"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\interaction.py", "code_chunk": "def user_confirm(message: str, prefix='>>> ', default=False) -> bool:\n    questions = inquirer.Confirm('_arg', message=prefix + message, default=default)\n    return inquirer.prompt([questions])['_arg']", "hash": "06dbe533f6c9a1036aef8ec5f685548254afdd46a004a834696f909196e352c6"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\interaction.py", "code_chunk": "def user_checkbox(message: str, choices: list, prefix='>>> ') -> list:\n    questions = inquirer.Checkbox('_arg', message=prefix + message, choices=choices)\n    return inquirer.prompt([questions])['_arg']", "hash": "798a9f2b3a91b7d9946ba4f2a0b80ec48406fa0d0585dcf6f53d9d9980946ab7"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\interaction.py", "code_chunk": "def user_list(message: str, choices: list, prefix='>>> '):\n    questions = inquirer.List('_arg', message=prefix + message, choices=choices)\n    return inquirer.prompt([questions])['_arg']", "hash": "b02ef6c7248f99ff5fd5bee5a814c555a0dedc579b24b3958290715fd5a7c78c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\interaction.py", "code_chunk": "import inquirer", "hash": "72afa46110319ba702978cb64f8ad41e73edf31723b28509902984ddd672eaeb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\logger.py", "code_chunk": "def get_logger(logger_name, log_level=logging.INFO):\n    logger = logging.getLogger(logger_name)\n    logger.setLevel(log_level)\n    logger.propagate = False\n    formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(name)s: %(message)s')\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)\n    if not logger.handlers:\n        logger.addHandler(console_handler)\n    return logger", "hash": "600a5a836686ba9201a8ab9238fac3b5ad2402d611335defedd5db7bb3ac9522"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\logger.py", "code_chunk": "import logging", "hash": "94bd1e3d2e185eb9968506e4215f39c40a17790d3c5d7fa283450f61b921573b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "Block.def __init__(self, text: str, title: str):\n    self.raw_text = text\n    self.title = title", "hash": "9a92076161a2dc346456817c9a7c10830cff555b9ac83a5d3411216d759fdf0f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "Block.@abstractmethod\ndef parse(self):\n    pass", "hash": "122440c09cd1007e94be8020babcda3115abebe4a96876f29f28a275e1b7a83f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "Block.@abstractmethod\ndef content(self):\n    pass", "hash": "5666ebd483b138dc90fa152161638554dbda92c3201d4abe247b71d6fa5b7c2c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "Block.ABC", "hash": "8d0144cdac247cee112409a3f21602a6e90d0511e5b1673f1e5e5bb73de0e3ac"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "CodeBlock.def __init__(self, text: str, title: str, lang: str=''):\n    super().__init__(text, title)\n    self.lang = lang\n    self.code = ''", "hash": "993db7ee936e291b0894d74cb0a9ae700f10c375a1b80d7a75310ebf501456af"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "CodeBlock.def parse(self):\n    pattern = self.CODE_BLOCK_PATTERN.format(lang=self.lang)\n    match = re.search(pattern, self.raw_text, re.DOTALL)\n    if match:\n        self.code = match.group(1)\n    else:\n        raise Exception(f'Cannot parse {self.lang} code block in text: \\n{self.raw_text}')", "hash": "ad923b951d3705cfbd971b7e44e4b5fb0ead568f1dcf6391b83528f17ab5ca9a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "CodeBlock.def content(self):\n    return self.code", "hash": "4c14ee62453f3e2637767a4dbccd930b1af5844187c540d438a6590a6c3ec0fb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "CodeBlock.Block\nCODE_BLOCK_PATTERN = '```{lang}.*?\\\\s+(.*?)\\\\s+```'", "hash": "db17070eaf4f07fb76fc0eda9307430ff1f17edb2549151b7e8eb289fbd2d2d8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "PythonCodeBlock.def __init__(self, text: str, title: str):\n    super().__init__(text, title, lang='python')\n    self.pyobj = None", "hash": "9e7002bd74d8128e043700ec1b33032bf9d5f37a279cc857aaa6f62684464a56"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "PythonCodeBlock.def parse(self):\n    super().parse()\n    if not self._is_valid_python(self.code):\n        raise Exception(f'Code block is not valid python: {self.code}')\n    else:\n        try:\n            self.pyobj = ast.literal_eval(self.code)\n        except Exception as e:\n            raise Exception(f'Cannot parse python code block: {self.code}, error: {e}')", "hash": "3d56d986d6d42fcd7037204605be235eb56f15c00b6dec0ed7adabe30642056f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "PythonCodeBlock.def content(self):\n    return self.pyobj", "hash": "053f39f7605296dd1c7bb11a2ce91826778f73d9ec57acbc6195e76c86004525"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "PythonCodeBlock.def _is_valid_python(self, code: str) -> bool:\n    try:\n        ast.parse(code)\n        return True\n    except SyntaxError:\n        return False", "hash": "d0a877d27f42f9419ebd9fdbca24dfec651656054f3ad9684b4a908f73939298"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "PythonCodeBlock.CodeBlock", "hash": "e0b95c22e6155f53c1e7db1e150d5b9c8b69ee96bfdbf9d06cbf3d417155b91a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "StringBlock.def __init__(self, text: str, title: str):\n    super().__init__(text, title)\n    self.text = ''", "hash": "bfedf929cafac2b8de32109ffaeca812335c4b3b915fe5ca12b788b5a86054ca"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "StringBlock.def parse(self):\n    self.text = self.raw_text", "hash": "5924396e7fb9df820f8fef62752fb2c0a9dce7eecf31785f4caef3260e792769"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "StringBlock.def content(self):\n    return self.text", "hash": "5861403764d48d0f0a4bd523cbc02f7f4fac79d87b97188e0c3e9f9926e1cdfc"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "StringBlock.Block", "hash": "0f5e3c484e3fd84feb4f5db4e4859fada310aed4482383a277a10731a7afea7b"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "OuptutParser.@classmethod\n@abstractclassmethod\ndef parse_output(cls, input):\n    pass", "hash": "f511722e7f7da27696c28dd9b90549e769d8155dcb27ac43306ff4c2eadcb151"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "OuptutParser.@classmethod\n@abstractclassmethod\ndef parse_output_with_schema(cls, input, schema):\n    pass", "hash": "c72de295508be9504c7f2666d82d19e112e04a115f99bb3db76a4196446bcf3c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "OuptutParser.ABC", "hash": "d343df1bb96a71e063e170fce71e93c026299181376332d3bc54fae5e2c3df9a"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "LLMOutputParser.@classmethod\ndef parse_output(cls, input: str) -> dict[str, any]:\n    block_dict = {}\n    block_texts = cls._split_block_text(input)\n    for block_text in block_texts:\n        block_title, block_content = block_text\n        block = cls._parse_block(block_content, block_title)\n        block.parse()\n        content = block.content()\n        block_dict[block_title] = content\n    return block_dict", "hash": "824f9539022822dc1703cfbb1a685fc12911d60c4d588b41ddd87a07b7f85eed"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "LLMOutputParser.@classmethod\ndef parse_output_with_schema(cls, input: str, schema: dict[str, type]) -> dict[str, any]:\n    block_dict = {}\n    block_texts = cls._split_block_text(input)\n    for block_text in block_texts:\n        block_title, block_content = block_text\n        if block_title in schema.keys():\n            block = cls._parse_block(block_content, block_title)\n            block.parse()\n            content = block.content()\n            try:\n                content = typeguard.check_type(content, schema[block_title][0])\n                block_dict[block_title] = content\n            except Exception as e:\n                raise Exception(f'Parse {block_title} error: {e}')\n    return block_dict", "hash": "156f3a1a15eb0656f1e09aec115c6915a92db4e174ec1a914910955931b62a44"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "LLMOutputParser.@classmethod\ndef _split_block_text(cls, text: str) -> list[tuple[str, str]]:\n    block_texts = text.split('##')\n    block_list = []\n    for block_text in block_texts:\n        block_text = block_text.strip()\n        if block_text != '':\n            try:\n                block_title, block_content = block_text.split('\\n', 1)\n            except Exception as e:\n                raise Exception(f'Cannot split block text: {block_text}, error: {e}')\n            block_title.strip()\n            block_content.strip()\n            block_list.append((block_title, block_content))\n    return block_list", "hash": "d0c5f8afa3bbe595323858e90e0d8092c31179b30c8e46bc1cdc424f3ad17e54"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "LLMOutputParser.@classmethod\ndef _parse_block(cls, block_content: str, block_title: str) -> Block:\n    if block_content.startswith('```python'):\n        return PythonCodeBlock(block_content, block_title)\n    else:\n        return Block(block_content, block_title)", "hash": "8603d61ebb588f66d227d3f1ecd62503c2d464dd73d66eba347b740e44b25946"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "LLMOutputParser.OuptutParser\n'\\n    input: str -> output: dict[str, any]\\n    '", "hash": "baddcefa57f610e74621ce568382aae22013194701ea80bc8967161740febacf"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "RawOutputParser.@classmethod\ndef parse_output(cls, input: any) -> any:\n    return input", "hash": "8f5b37d30404039b0394d0ee21af9663da0b1da2395dadfc01518ff99f06e8e8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "RawOutputParser.@classmethod\ndef parse_output_with_schema(cls, input: any, _: any) -> any:\n    return input", "hash": "83c6fa26a98c59df836598fea37b7f072a608711a7c09194c903c50ae81ce54d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "RawOutputParser.OuptutParser\n'\\n    input: any -> output: any\\n    '", "hash": "a01934995a483d782f933a4e821be608679811b6dcac4ea82af70f599606fa26"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.@classmethod\ndef parse_output_with_schema(cls, text: str, schema: dict[str, type]) -> dict[str, any]:\n    code_content = PythonCodeBlock(text, 'code').parse()\n    return {'Code Content': code_content}", "hash": "e6f73ae39f4dab009073e37867e78fcd82a834492973e537ea1432d4d20fe69d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.OuptutParser", "hash": "979809b1aa6f71ac23d2afe01c2953e1cf56ec447c6f7579a41cab1b6cfe2ed5"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.def __init__(self, text: str, title: str):\n    self.raw_text = text\n    self.title = title", "hash": "6437275b6aa2ccaedb1b6cd08c8b7c77f82b65df0f1d083695f0c7b8a045b615"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.@abstractmethod\ndef parse(self):\n    pass", "hash": "6408160c3430693e1a8998dc6544be09b0b3dbb882a4c26aae3da86c4442b073"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.@abstractmethod\ndef content(self):\n    pass", "hash": "77c64e123f7896c6899147fb6fdc74dd6600bbc00f2fa97bfe9a770f8c9b5b34"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.def __init__(self, text: str, title: str, lang: str=''):\n    super().__init__(text, title)\n    self.lang = lang\n    self.code = ''", "hash": "147f826da34f5eaa0d65b3696a43348e6cb54d29541fc0fa821c71307f195d16"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.def parse(self):\n    pattern = self.CODE_BLOCK_PATTERN.format(lang=self.lang)\n    match = re.search(pattern, self.raw_text, re.DOTALL)\n    if match:\n        self.code = match.group(1)\n    else:\n        raise Exception(f'Cannot parse {self.lang} code block in text: \\n{self.raw_text}')", "hash": "546dc0b4647fa2fd4858be5634289caca3046c34a0d223192802267157a355eb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.def content(self):\n    return self.code", "hash": "88563d25ce0d4a39a7ec1983072122f49d157aa3797ea154d68e5e043f0a74e8"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.def __init__(self, text: str, title: str):\n    super().__init__(text, title, lang='python')\n    self.pyobj = None", "hash": "f15a4c5a9af310de4a4501c4c84a93e61b1d33f1a89bcb8a9b2a299cf627101d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.def parse(self):\n    super().parse()\n    if not self._is_valid_python(self.code):\n        raise Exception(f'Code block is not valid python: {self.code}')\n    else:\n        try:\n            self.pyobj = ast.literal_eval(self.code)\n        except Exception as e:\n            raise Exception(f'Cannot parse python code block: {self.code}, error: {e}')", "hash": "cefd0ef9ea7f323f970c83bf5edb9028bbf5b4135738d62bb735038d2e75962f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.def content(self):\n    return self.pyobj", "hash": "d71b5e0c7e8d437e047e104730013a68c57e53c38f94810f82039747a3474710"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.def _is_valid_python(self, code: str) -> bool:\n    try:\n        ast.parse(code)\n        return True\n    except SyntaxError:\n        return False", "hash": "78a83ea0430e4a0eb0dd20ffebe14a1fe2707cdcd6af299dba09038ae379cfbe"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.def __init__(self, text: str, title: str):\n    super().__init__(text, title)\n    self.text = ''", "hash": "4991e29e5ae7cb76685059461a9de10948d60557f161a6c55a3c6cbd9aa334ef"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.def parse(self):\n    self.text = self.raw_text", "hash": "518f46403555589f4570243e5ee25da838d3547f37ef497658250c0fd1b50db1"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.def content(self):\n    return self.text", "hash": "3ea08ee0cde0f8a7a278aaaf8c71bed39cac520b9e5eb10c689a85413d1794ca"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.@classmethod\n@abstractclassmethod\ndef parse_output(cls, input):\n    pass", "hash": "06cb87020193a1e7781b70526f1de0cfb64d51e786510cf5217bc5cf6eb9db2c"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.@classmethod\n@abstractclassmethod\ndef parse_output_with_schema(cls, input, schema):\n    pass", "hash": "75d5f755c18e433160ca88ecc0cce1adf61538ad9872be1a0248071632987edb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.@classmethod\ndef parse_output(cls, input: str) -> dict[str, any]:\n    block_dict = {}\n    block_texts = cls._split_block_text(input)\n    for block_text in block_texts:\n        block_title, block_content = block_text\n        block = cls._parse_block(block_content, block_title)\n        block.parse()\n        content = block.content()\n        block_dict[block_title] = content\n    return block_dict", "hash": "a9688ae22f4a527e144d2d74f0922d8647709e4b5444e7edb752ee39e287f806"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.@classmethod\ndef parse_output_with_schema(cls, input: str, schema: dict[str, type]) -> dict[str, any]:\n    block_dict = {}\n    block_texts = cls._split_block_text(input)\n    for block_text in block_texts:\n        block_title, block_content = block_text\n        if block_title in schema.keys():\n            block = cls._parse_block(block_content, block_title)\n            block.parse()\n            content = block.content()\n            try:\n                content = typeguard.check_type(content, schema[block_title][0])\n                block_dict[block_title] = content\n            except Exception as e:\n                raise Exception(f'Parse {block_title} error: {e}')\n    return block_dict", "hash": "2cf5418bdcb8337ed13f809cd8b092d56a54064ec60daed3f1137e8419c2e484"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.@classmethod\ndef _split_block_text(cls, text: str) -> list[tuple[str, str]]:\n    block_texts = text.split('##')\n    block_list = []\n    for block_text in block_texts:\n        block_text = block_text.strip()\n        if block_text != '':\n            try:\n                block_title, block_content = block_text.split('\\n', 1)\n            except Exception as e:\n                raise Exception(f'Cannot split block text: {block_text}, error: {e}')\n            block_title.strip()\n            block_content.strip()\n            block_list.append((block_title, block_content))\n    return block_list", "hash": "4f5ab686e0d1e622ba8b3a499cd51951693bc734c290e29c767beb5b496a1d3e"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.@classmethod\ndef _parse_block(cls, block_content: str, block_title: str) -> Block:\n    if block_content.startswith('```python'):\n        return PythonCodeBlock(block_content, block_title)\n    else:\n        return Block(block_content, block_title)", "hash": "cbe333741b66d23ef90b7ec725e616e4fe1b21f837aa7b677bdf1e10ac1eab21"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.@classmethod\ndef parse_output(cls, input: any) -> any:\n    return input", "hash": "cc5c8d549652c6e11dca97bbead4cbb2ad060a95d4833a5f379f6af27576b7ec"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.@classmethod\ndef parse_output_with_schema(cls, input: any, _: any) -> any:\n    return input", "hash": "29038e254bddc5a782080b2c95641bef760a19dbf5bff9d61a5c7f7c87fc3441"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "GitLoaderOutputParser.@classmethod\ndef parse_output_with_schema(cls, text: str, schema: dict[str, type]) -> dict[str, any]:\n    code_content = PythonCodeBlock(text, 'code').parse()\n    return {'Code Content': code_content}", "hash": "e6f73ae39f4dab009073e37867e78fcd82a834492973e537ea1432d4d20fe69d"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\output_parser.py", "code_chunk": "import re\nimport ast\nimport typeguard\nfrom abc import ABC, abstractmethod, abstractclassmethod\nfrom subprocess import CompletedProcess", "hash": "825224d0f2693c32f7fc44f49830c2ad58896f373712a9f50c552a0336c27944"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\singleton.py", "code_chunk": "Singleton.def __init__(self, cls):\n    self._cls = cls\n    self._instance = {}", "hash": "4c06fea9d18cb9d4089a257826220f47cd64022c91594b9344b5a8756374951f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\singleton.py", "code_chunk": "Singleton.def __call__(self):\n    if self._cls not in self._instance:\n        self._instance[self._cls] = self._cls()\n    return self._instance[self._cls]", "hash": "8f05511e87014661574df7ff527a36e2fc36e08e5b8109dedf17db933db36630"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\singleton.py", "code_chunk": "Singleton.object", "hash": "233943846f4b5a70c6650e22da198d35c6f22f18bb56cfe7fb51f936fdd35211"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\singleton.py", "code_chunk": "Singleton.def __init__(self, cls):\n    self._cls = cls\n    self._instance = {}", "hash": "4c06fea9d18cb9d4089a257826220f47cd64022c91594b9344b5a8756374951f"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\singleton.py", "code_chunk": "Singleton.def __call__(self):\n    if self._cls not in self._instance:\n        self._instance[self._cls] = self._cls()\n    return self._instance[self._cls]", "hash": "8f05511e87014661574df7ff527a36e2fc36e08e5b8109dedf17db933db36630"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\temp_file_operation.py", "code_chunk": "def get_file_ext(file_path_or_name: str | Path) -> str:\n    _, extension = os.path.splitext(file_path_or_name)\n    return extension", "hash": "4d21ade89531063982f86cf36bf0e98deee13a847627336850101b86e8a0feab"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\temp_file_operation.py", "code_chunk": "def check_file_ext_is_valid(ext: str) -> bool:\n    return ext in _VALID_FILE_EXTENSIONS", "hash": "a702afce5a8e9548cfc389f39f7112748b6632a15e59aa4a0737083a65384675"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\temp_file_operation.py", "code_chunk": "def write_temp_files(user_id: str, files: list[tuple[str, IO[Any]]], base_path: Path | str=FILE_CONNECTOR_TMP_STORAGE_PATH) -> list[str]:\n    \"\"\"Writes temporary files to disk and returns their paths\n\n    NOTE: need to pass in (file_name, File) tuples since FastAPI's `UploadFile` class\n    exposed SpooledTemporaryFile does not include a name.\n    \"\"\"\n    file_location = Path(base_path) / user_id / str(uuid.uuid4())\n    os.makedirs(file_location, exist_ok=True)\n    file_paths: list[str] = []\n    for file_name, file in files:\n        extension = get_file_ext(file_name)\n        if not check_file_ext_is_valid(extension):\n            raise ValueError(f\"Invalid file extension for file: '{file_name}'. Must be one of {_VALID_FILE_EXTENSIONS}\")\n        file_path = file_location / file_name\n        with open(file_path, 'wb') as buffer:\n            shutil.copyfileobj(file, buffer)\n        file_paths.append(str(file_path.absolute()))\n    return file_paths", "hash": "e925567402356c198d4d93bee8b7d905564fae37d832011d3e5be16cd6473f25"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\temp_file_operation.py", "code_chunk": "def file_age_in_hours(filepath: str | Path) -> float:\n    return (time.time() - os.path.getmtime(filepath)) / (60 * 60)", "hash": "b166602d20c488f36ebb2cd0073b05d318e2af87e82576469febbce7792e2693"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\temp_file_operation.py", "code_chunk": "def clean_old_temp_files(files_path: List[str]) -> None:\n    for file in files_path:\n        os.remove(file)", "hash": "75b3b40237088518a4692a4d32ea0a2c52348ad6cee3c335ef81ad350da78005"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\temp_file_operation.py", "code_chunk": "import os\nimport shutil\nimport time\nimport uuid\nfrom pathlib import Path\nfrom typing import Any, List\nfrom typing import IO\nFILE_CONNECTOR_TMP_STORAGE_PATH = os.environ.get('FILE_CONNECTOR_TMP_STORAGE_PATH', '/knowledge_base')\n_FILE_AGE_CLEANUP_THRESHOLD_HOURS = 24 * 7\n_VALID_FILE_EXTENSIONS = ['.txt', '.zip', '.pdf']", "hash": "fa661de5b9e3ad3292279d2dbe0e1d60fd02baa783e39370ddbe72f4116bb716"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\code_executor\\python_process.py", "code_chunk": "PythonProcess.def run(self):\n    cmd = [self.python_exec] + self.args + [self.python_file_path]\n    return subprocess.run([\"bash -c 'cd {dir} && {real_cmd}'\".format(dir=self.working_dir, real_cmd=' '.join(cmd))], shell=True, stderr=subprocess.PIPE)", "hash": "adacf42c7839f81b1298397065dded48e6d8e5c7b4a316b853654077f7d10eba"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\code_executor\\python_process.py", "code_chunk": "PythonProcess.BaseModel\nworking_dir: str = Field(default='/tmp', description='Working directory.')\nargs: list[str] = Field(default=[], description='Arguments for python process.')\npython_exec: str = Field(default='python3', description='Python executable path.')\npython_file_path: str = Field(default='main.py', description='Python file path.')", "hash": "6ecd0383d6af3a5e6eadb4f29762d9a34ed401d60206c64045ed1649f85f4b77"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\code_executor\\python_process.py", "code_chunk": "PythonProcess.def run(self):\n    cmd = [self.python_exec] + self.args + [self.python_file_path]\n    return subprocess.run([\"bash -c 'cd {dir} && {real_cmd}'\".format(dir=self.working_dir, real_cmd=' '.join(cmd))], shell=True, stderr=subprocess.PIPE)", "hash": "adacf42c7839f81b1298397065dded48e6d8e5c7b4a316b853654077f7d10eba"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\code_executor\\python_process.py", "code_chunk": "import subprocess\nimport queue\nimport threading\nimport time\nfrom typing import Optional\nfrom pydantic import BaseModel, Field", "hash": "1c3fb6cac87b4b0e3fa2158a98eb939790b3a8c393a8ea91520673fae5ac70ff"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\code_executor\\python_repl.py", "code_chunk": "PythonREPL.def __init__(self, _globals: Optional[dict]=None, _locals: Optional[dict]=None):\n    self._globals = _globals if _globals is not None else {}\n    self._locals = _locals if _locals is not None else {}", "hash": "338c3b2895cc5f709d694c046311cd23e904e5d5789e596bbe0f0e42461a39fd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\code_executor\\python_repl.py", "code_chunk": "PythonREPL.def run(self, command: str) -> str:\n    old_stdout = sys.stdout\n    sys.stdout = mystdout = StringIO()\n    try:\n        exec(command, self._globals, self._locals)\n        sys.stdout = old_stdout\n        output = mystdout.getvalue()\n    except Exception as e:\n        sys.stdout = old_stdout\n        output = str(e)\n    return output", "hash": "11738fb588d059d38fb0841f980b1ab5633944307f5a29abd53f4047d162f8fb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\code_executor\\python_repl.py", "code_chunk": "PythonREPL.'\\n    Simple python REPL.\\n    '\n_globals: dict[str, any]\n_locals: dict[str, any]", "hash": "e58a4800d36584fd8dbbd20a6f02df573fd5837fddcd219b20aa4924966f18c4"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\code_executor\\python_repl.py", "code_chunk": "PythonREPL.def __init__(self, _globals: Optional[dict]=None, _locals: Optional[dict]=None):\n    self._globals = _globals if _globals is not None else {}\n    self._locals = _locals if _locals is not None else {}", "hash": "338c3b2895cc5f709d694c046311cd23e904e5d5789e596bbe0f0e42461a39fd"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\code_executor\\python_repl.py", "code_chunk": "PythonREPL.def run(self, command: str) -> str:\n    old_stdout = sys.stdout\n    sys.stdout = mystdout = StringIO()\n    try:\n        exec(command, self._globals, self._locals)\n        sys.stdout = old_stdout\n        output = mystdout.getvalue()\n    except Exception as e:\n        sys.stdout = old_stdout\n        output = str(e)\n    return output", "hash": "11738fb588d059d38fb0841f980b1ab5633944307f5a29abd53f4047d162f8fb"}
{"file_path": "open-assistant\\package\\src\\yorgassistant\\utils\\code_executor\\python_repl.py", "code_chunk": "import sys\nfrom io import StringIO\nfrom typing import Optional", "hash": "86d2d013d4178b29489f12052b4b267e7494fdcdc33e08d4250d8c3f29a914ca"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "SessionState.def init_state(self):\n    \"\"\"Initialize session state variables.\"\"\"\n    st.session_state['assistant'] = []\n    st.session_state['user'] = []\n    st.session_state['selected_page_common'] = False\n    st.session_state['selected_create_assistant'] = False\n    st.session_state['selected_history'] = None\n    st.session_state['thread_obj'] = None", "hash": "fe5d0e15631652e67e6ce9fed88fd3eb2a4448a937de6f7d4378a92a23310fca"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "SessionState.def clear_state(self):\n    \"\"\"Clear the existing session state.\"\"\"\n    st.session_state['assistant'] = []\n    st.session_state['user'] = []\n    st.session_state['selected_page_common'] = False\n    st.session_state['selected_create_assistant'] = False\n    st.session_state['selected_history'] = None\n    st.session_state['thread_obj'] = None", "hash": "023b7027f499190441814df4330f5fb0767da08d0e0368dcd2b2d00a7b2f9432"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "SessionState.", "hash": "0ea63546c2cbe5ef2ac43ccebd7f354c7da0417dbfafe245ee62a1925286eea5"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitUI.def __init__(self, session_state: SessionState):\n    self.init_streamlit()\n    self.session_state = session_state", "hash": "62c523328351a4ac986f20ed81df548104dc3c53799b434fd156b9c7e08a6fa1"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitUI.def init_streamlit(self):\n    \"\"\"Initialize Streamlit's UI settings.\"\"\"\n    st.set_page_config(page_title='yorgassistant-web', page_icon='yorg.png')\n    col1, col2, col3 = st.columns(3)\n    with col2:\n        st.image('yorg.png', width=200)\n    st.header(':robot_face: :blue[Open-assistants] Web Demo ', divider='rainbow')\n    with open('README.md', 'r') as readme_file:\n        readme_content = readme_file.read()\n    st.markdown(readme_content, unsafe_allow_html=True)\n    st.sidebar.title('setup')", "hash": "acb7f6746947fcf5234654145688386272f24fdaf45d39fa28082c3094bcc0d2"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitUI.def setup_sidebar(self):\n    yorgassistant.Threads.set_threads_yaml_path('data/threads.yaml')\n    yorgassistant.Assistants.set_assistants_yaml_path('data/assistants.yaml')\n    yorgassistant.Tools.set_tools_yaml_path('tools.yaml')\n    with st.sidebar:\n        st.subheader('gobal setup', divider='gray')\n        proxy_agree = st.checkbox('set proxy', value=False)\n        if proxy_agree:\n            proxy = st.number_input(label='Proxy port', value=10809)\n        else:\n            proxy = 0\n        api_key = st.text_input('openai api key(required):', '', type='password')\n        if not api_key:\n            st.warning('please provide OpenAI API key.')\n        if proxy_agree:\n            os.environ['http_proxy'] = f'http://127.0.0.1:{proxy}'\n            os.environ['https_proxy'] = f'http://127.0.0.1:{proxy}'\n        os.environ['OPENAI_CHAT_API_KEY'] = api_key\n        st.subheader('chatbox setup', divider='gray')\n        col1, col2, col3 = st.columns([1, 2, 1])\n        with col2:\n            if st.button('create assistant'):\n                st.session_state['selected_create_assistant'] = True\n                st.session_state['selected_page_common'] = False\n                st.session_state['selected_history'] = None\n        assistants_list = yorgassistant.Assistants.get_all_assistants()\n        assistants_list = list(reversed(assistants_list))\n        if len(assistants_list) == 0:\n            st.warning('please create assistant.')\n        else:\n            choose_assistant = st.selectbox('choose assistant:', [assistant.name for assistant in assistants_list])\n            for assistant in assistants_list:\n                if choose_assistant == assistant.name:\n                    assistant_id = assistant.id\n            st.session_state['page_common_assistant_id'] = assistant_id\n            if len(choose_assistant) == 0:\n                st.warning('please create assistant.')\n            col1, col2, col3 = st.columns([1, 2, 1])\n            with col2:\n                if st.button('New   Chat  Box'):\n                    st.session_state['selected_create_assistant'] = False\n                    st.session_state['selected_page_common'] = True\n                    st.session_state['selected_history'] = None\n                    st.session_state['thread_obj'] = yorgassistant.Threads.create()\n            st.subheader('chat history', divider='gray')\n            history_nums = st.slider(label='history nums:', min_value=1, max_value=20, step=1, value=5)\n            col1, col2, col3 = st.columns([1, 4, 1])\n            with col2:\n                threads_list = yorgassistant.Threads.get_all_threads()\n                threads_list = list(reversed(threads_list))\n                history_nums = min(len(threads_list), history_nums)\n                last_threads = threads_list[:history_nums]\n                for i, thread in enumerate(last_threads):\n                    btn_name = datetime.fromtimestamp(thread.created_at).strftime('%Y-%m-%d %H:%M:%S')\n                    if st.button(btn_name, key=f'button_{i}'):\n                        st.session_state['selected_history'] = thread.id\n                        st.session_state['selected_create_assistant'] = False\n                        st.session_state['selected_page_common'] = False\n        st.write('---')\n        st.caption('\u00a9 Made by yorg 2023. All rights reserved.')\n        st.caption('By using this chatbot, you agree that the chatbot is provided on \\n                    an \"as is\" basis and that we do not assume any liability for any \\n                    errors, omissions or other issues that may arise from your use of \\n                    the chatbot.')\n    if st.session_state['selected_history']:\n        st.session_state['thread_obj'] = yorgassistant.Threads.from_id(st.session_state['selected_history'])\n        st.session_state['page_common_assistant_id'] = st.session_state['thread_obj'].config.assistant_id if st.session_state['thread_obj'].config.assistant_id else assistant_id\n        StreamlitPage().page_commen(st.session_state['page_common_assistant_id'])\n    if st.session_state['selected_create_assistant'] and (not st.session_state['selected_page_common']):\n        StreamlitPage().create_assistants()\n    elif st.session_state['selected_page_common'] and (not st.session_state['selected_create_assistant']):\n        st.session_state['assistant'] = []\n        st.session_state['user'] = []\n        StreamlitPage().page_commen(st.session_state['page_common_assistant_id'])", "hash": "06afc7122371e395b2b1ccbaed9207cd6075105f01228832a215d48bf50c3804"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitUI.def render_user(self, prompt: str):\n    with st.chat_message('user'):\n        st.markdown(prompt)", "hash": "a75ef0a628ce6a56bf7b5831cfdff6f4c2e469abfa2f89ecbe1543adb4e80091"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitUI.def render_assistant(self, action):\n    with st.chat_message('assistant'):\n        self.render_action(action)", "hash": "8cdd0de4c78320db9ed260d76c761135ab30f15d3cc96bcb1e71b522d96a9b30"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitUI.def render_action(self, action):\n    action_content = action['content']\n    if action['type'] == 'success':\n        if action_content['tool'] == '':\n            action_content['tool'] = 'No use tool'\n        with st.expander(action_content['tool'], expanded=False):\n            st.markdown(\"<p style='text-align: left;display:flex;'> <span style='font-size:14px;font-weight:600;width:170px;text-align-last: justify;'>tool</span><span style='width:14px;text-align:left;display:block;'>:</span><span style='flex:1;'>\" + action_content['tool'] + '</span></p>', unsafe_allow_html=True)\n            st.markdown(\"<p style='text-align: left;display:flex;'> <span style='font-size:14px;font-weight:600;width:170px;text-align-last: justify;'>tool_type</span><span style='width:14px;text-align:left;display:block;'>:</span><span style='flex:1;'>\" + action_content['tool_type'] + '</span></p>', unsafe_allow_html=True)\n            st.markdown(\"<p style='text-align: left;display:flex;'><span style='font-size:14px;font-weight:600;width:170px;text-align-last: justify;'>tool_response</span><span style='width:14px;text-align:left;display:block;'>:</span></p>\", unsafe_allow_html=True)\n            st.markdown(action_content['tool_response'])\n        st.markdown(action['assistant']['message'])\n    else:\n        with st.expander(action['type'], expanded=False):\n            st.markdown('error information:' + action_content['message'])\n        st.markdown('chat error you must input correct openai api key')", "hash": "d77942d8fe8e287cfe0fce3128bb450923950550647b9588e41a25c6d3a4846b"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitUI.", "hash": "c506a4f758349f7364ebd05e6e3501868db9cdd948949ad208a43146636ddafc"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitPage.def page_commen(self, assistant_id: str):\n    if st.session_state['thread_obj'] == None:\n        thread = yorgassistant.Threads.create()\n        st.session_state['thread_obj'] = thread\n        st.session_state['assistant'] = []\n        st.session_state['user'] = []\n    else:\n        st.session_state['assistant'] = []\n        st.session_state['user'] = []\n        for history in st.session_state['thread_obj'].config.message_history:\n            st.session_state['user'].append(history[0]['user'])\n            st.session_state['assistant'].append(history[1]['assistant'])\n    assistants_list = yorgassistant.Assistants.get_all_assistants()\n    name = ''\n    for assistant in assistants_list:\n        if assistant.id == assistant_id:\n            name = assistant.name\n    title = f'current assistant name : {name}'\n    st.subheader(title)\n    for prompt, agent_return in zip(st.session_state['user'], st.session_state['assistant']):\n        st.session_state['ui'].render_user(prompt)\n        st.session_state['ui'].render_assistant(agent_return)\n    if (user_input := st.chat_input('')):\n        st.session_state['ui'].render_user(user_input)\n        st.session_state['user'].append(user_input)\n        with st.spinner('Wait for it...'):\n            if st.session_state['assistant']:\n                last_assistant_message = st.session_state['assistant'][-1]\n                if 'next_stages_info' in last_assistant_message['content']['tool_response']:\n                    tool_response = last_assistant_message['content']['tool_response']\n                    tool_response = eval(tool_response)\n                    next_stages_info = tool_response['next_stages_info']\n                    keys = list(next_stages_info.keys())\n                    agent_return = st.session_state['thread_obj'].run(assistant_id, user_input, goto=keys[0])\n                else:\n                    agent_return = st.session_state['thread_obj'].run(assistant_id, user_input)\n            else:\n                agent_return = st.session_state['thread_obj'].run(assistant_id, user_input)\n        print(f'agent_return:{agent_return}')\n        st.session_state['assistant'].append(copy.deepcopy(agent_return))\n        st.session_state['ui'].render_assistant(agent_return)", "hash": "783aa83d379e1268d4866fdce6296552d4caa08dafd8bb0c79caab35ec55249f"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitPage.def create_assistants(self):\n    st.subheader('create assistant setting')\n    name = st.text_input('assistant name:', '')\n    model = st.selectbox('model name:', ['gpt-4-1106-preview', 'gpt-4'])\n    instructions = st.text_area('assistant instructions :', '')\n    tools_options = st.multiselect('sselect assistant tools:', ['swe_tool', 'code_interpreter'])\n    tools = [{'type': tool} for tool in tools_options]\n    if st.button('Submit'):\n        assistant = yorgassistant.Assistants.create(name=name, model=model, instructions=instructions, tools=tools)\n        st.session_state['selected_create_assistant'] = False\n        st.session_state['selected_page_common'] = True\n        st.session_state['page_common_assistant_id'] = assistant.id", "hash": "49e24ec6dd30d88dd818915f4c6fee38e7f7af8f879f302df5d39e63c2c836fc"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitPage.", "hash": "3e3619d49546c695184bc81ad6d6d320455e54d2c35bd48410d4a6b4fad244c0"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitPage.def main():\n    logger = get_logger(__name__)\n    if 'ui' not in st.session_state:\n        session_state = SessionState()\n        session_state.init_state()\n        st.session_state['ui'] = StreamlitUI(session_state)\n    else:\n        st.set_page_config(page_title='yorgassistant-web', page_icon='yorg.png')\n        st.header(':robot_face: :blue[Open-assistants] Web Demo ', divider='rainbow')\n    st.session_state['ui'].setup_sidebar()", "hash": "0f239bf8cb861e6c9270aab02568a6e2d9b8732eaea4d7f730a0f6507ea4741e"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitPage.def init_state(self):\n    \"\"\"Initialize session state variables.\"\"\"\n    st.session_state['assistant'] = []\n    st.session_state['user'] = []\n    st.session_state['selected_page_common'] = False\n    st.session_state['selected_create_assistant'] = False\n    st.session_state['selected_history'] = None\n    st.session_state['thread_obj'] = None", "hash": "c0b420eaade7b7e3197aa0bba7e48a9558f5d71212b1b6e966348514cf664b61"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitPage.def clear_state(self):\n    \"\"\"Clear the existing session state.\"\"\"\n    st.session_state['assistant'] = []\n    st.session_state['user'] = []\n    st.session_state['selected_page_common'] = False\n    st.session_state['selected_create_assistant'] = False\n    st.session_state['selected_history'] = None\n    st.session_state['thread_obj'] = None", "hash": "59d9fc02fc94681dff8883427baa3a0d8eb87bf65827e723aaef9b2780337b61"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitPage.def __init__(self, session_state: SessionState):\n    self.init_streamlit()\n    self.session_state = session_state", "hash": "24b7b29f72d2e63a9a0d579bcc8442226159d401563d1b57ec5f312056c6bd52"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitPage.def init_streamlit(self):\n    \"\"\"Initialize Streamlit's UI settings.\"\"\"\n    st.set_page_config(page_title='yorgassistant-web', page_icon='yorg.png')\n    col1, col2, col3 = st.columns(3)\n    with col2:\n        st.image('yorg.png', width=200)\n    st.header(':robot_face: :blue[Open-assistants] Web Demo ', divider='rainbow')\n    with open('README.md', 'r') as readme_file:\n        readme_content = readme_file.read()\n    st.markdown(readme_content, unsafe_allow_html=True)\n    st.sidebar.title('setup')", "hash": "00a2403005affa7471d3877553946a0fa483bc79d7f0e30b74718c9149f75037"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitPage.def setup_sidebar(self):\n    yorgassistant.Threads.set_threads_yaml_path('data/threads.yaml')\n    yorgassistant.Assistants.set_assistants_yaml_path('data/assistants.yaml')\n    yorgassistant.Tools.set_tools_yaml_path('tools.yaml')\n    with st.sidebar:\n        st.subheader('gobal setup', divider='gray')\n        proxy_agree = st.checkbox('set proxy', value=False)\n        if proxy_agree:\n            proxy = st.number_input(label='Proxy port', value=10809)\n        else:\n            proxy = 0\n        api_key = st.text_input('openai api key(required):', '', type='password')\n        if not api_key:\n            st.warning('please provide OpenAI API key.')\n        if proxy_agree:\n            os.environ['http_proxy'] = f'http://127.0.0.1:{proxy}'\n            os.environ['https_proxy'] = f'http://127.0.0.1:{proxy}'\n        os.environ['OPENAI_CHAT_API_KEY'] = api_key\n        st.subheader('chatbox setup', divider='gray')\n        col1, col2, col3 = st.columns([1, 2, 1])\n        with col2:\n            if st.button('create assistant'):\n                st.session_state['selected_create_assistant'] = True\n                st.session_state['selected_page_common'] = False\n                st.session_state['selected_history'] = None\n        assistants_list = yorgassistant.Assistants.get_all_assistants()\n        assistants_list = list(reversed(assistants_list))\n        if len(assistants_list) == 0:\n            st.warning('please create assistant.')\n        else:\n            choose_assistant = st.selectbox('choose assistant:', [assistant.name for assistant in assistants_list])\n            for assistant in assistants_list:\n                if choose_assistant == assistant.name:\n                    assistant_id = assistant.id\n            st.session_state['page_common_assistant_id'] = assistant_id\n            if len(choose_assistant) == 0:\n                st.warning('please create assistant.')\n            col1, col2, col3 = st.columns([1, 2, 1])\n            with col2:\n                if st.button('New   Chat  Box'):\n                    st.session_state['selected_create_assistant'] = False\n                    st.session_state['selected_page_common'] = True\n                    st.session_state['selected_history'] = None\n                    st.session_state['thread_obj'] = yorgassistant.Threads.create()\n            st.subheader('chat history', divider='gray')\n            history_nums = st.slider(label='history nums:', min_value=1, max_value=20, step=1, value=5)\n            col1, col2, col3 = st.columns([1, 4, 1])\n            with col2:\n                threads_list = yorgassistant.Threads.get_all_threads()\n                threads_list = list(reversed(threads_list))\n                history_nums = min(len(threads_list), history_nums)\n                last_threads = threads_list[:history_nums]\n                for i, thread in enumerate(last_threads):\n                    btn_name = datetime.fromtimestamp(thread.created_at).strftime('%Y-%m-%d %H:%M:%S')\n                    if st.button(btn_name, key=f'button_{i}'):\n                        st.session_state['selected_history'] = thread.id\n                        st.session_state['selected_create_assistant'] = False\n                        st.session_state['selected_page_common'] = False\n        st.write('---')\n        st.caption('\u00a9 Made by yorg 2023. All rights reserved.')\n        st.caption('By using this chatbot, you agree that the chatbot is provided on \\n                    an \"as is\" basis and that we do not assume any liability for any \\n                    errors, omissions or other issues that may arise from your use of \\n                    the chatbot.')\n    if st.session_state['selected_history']:\n        st.session_state['thread_obj'] = yorgassistant.Threads.from_id(st.session_state['selected_history'])\n        st.session_state['page_common_assistant_id'] = st.session_state['thread_obj'].config.assistant_id if st.session_state['thread_obj'].config.assistant_id else assistant_id\n        StreamlitPage().page_commen(st.session_state['page_common_assistant_id'])\n    if st.session_state['selected_create_assistant'] and (not st.session_state['selected_page_common']):\n        StreamlitPage().create_assistants()\n    elif st.session_state['selected_page_common'] and (not st.session_state['selected_create_assistant']):\n        st.session_state['assistant'] = []\n        st.session_state['user'] = []\n        StreamlitPage().page_commen(st.session_state['page_common_assistant_id'])", "hash": "ebe8e91b03f717578fbcbaebec22ea11fe997ae6fb8ba7219dbc5c11e536d0f2"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitPage.def render_user(self, prompt: str):\n    with st.chat_message('user'):\n        st.markdown(prompt)", "hash": "d7166d13285bb671851215ba931bec24d74f4a9caf84064abb50ac73a305b17b"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitPage.def render_assistant(self, action):\n    with st.chat_message('assistant'):\n        self.render_action(action)", "hash": "22b80c737ec70da56689618c551a1cd424d9573533ad5f75edc7e2a1e38d1d7d"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitPage.def render_action(self, action):\n    action_content = action['content']\n    if action['type'] == 'success':\n        if action_content['tool'] == '':\n            action_content['tool'] = 'No use tool'\n        with st.expander(action_content['tool'], expanded=False):\n            st.markdown(\"<p style='text-align: left;display:flex;'> <span style='font-size:14px;font-weight:600;width:170px;text-align-last: justify;'>tool</span><span style='width:14px;text-align:left;display:block;'>:</span><span style='flex:1;'>\" + action_content['tool'] + '</span></p>', unsafe_allow_html=True)\n            st.markdown(\"<p style='text-align: left;display:flex;'> <span style='font-size:14px;font-weight:600;width:170px;text-align-last: justify;'>tool_type</span><span style='width:14px;text-align:left;display:block;'>:</span><span style='flex:1;'>\" + action_content['tool_type'] + '</span></p>', unsafe_allow_html=True)\n            st.markdown(\"<p style='text-align: left;display:flex;'><span style='font-size:14px;font-weight:600;width:170px;text-align-last: justify;'>tool_response</span><span style='width:14px;text-align:left;display:block;'>:</span></p>\", unsafe_allow_html=True)\n            st.markdown(action_content['tool_response'])\n        st.markdown(action['assistant']['message'])\n    else:\n        with st.expander(action['type'], expanded=False):\n            st.markdown('error information:' + action_content['message'])\n        st.markdown('chat error you must input correct openai api key')", "hash": "04cbb3e53c5338bd04566484092063030ac50fe0f7a38486de40dc1c50033a6d"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitPage.def page_commen(self, assistant_id: str):\n    if st.session_state['thread_obj'] == None:\n        thread = yorgassistant.Threads.create()\n        st.session_state['thread_obj'] = thread\n        st.session_state['assistant'] = []\n        st.session_state['user'] = []\n    else:\n        st.session_state['assistant'] = []\n        st.session_state['user'] = []\n        for history in st.session_state['thread_obj'].config.message_history:\n            st.session_state['user'].append(history[0]['user'])\n            st.session_state['assistant'].append(history[1]['assistant'])\n    assistants_list = yorgassistant.Assistants.get_all_assistants()\n    name = ''\n    for assistant in assistants_list:\n        if assistant.id == assistant_id:\n            name = assistant.name\n    title = f'current assistant name : {name}'\n    st.subheader(title)\n    for prompt, agent_return in zip(st.session_state['user'], st.session_state['assistant']):\n        st.session_state['ui'].render_user(prompt)\n        st.session_state['ui'].render_assistant(agent_return)\n    if (user_input := st.chat_input('')):\n        st.session_state['ui'].render_user(user_input)\n        st.session_state['user'].append(user_input)\n        with st.spinner('Wait for it...'):\n            if st.session_state['assistant']:\n                last_assistant_message = st.session_state['assistant'][-1]\n                if 'next_stages_info' in last_assistant_message['content']['tool_response']:\n                    tool_response = last_assistant_message['content']['tool_response']\n                    tool_response = eval(tool_response)\n                    next_stages_info = tool_response['next_stages_info']\n                    keys = list(next_stages_info.keys())\n                    agent_return = st.session_state['thread_obj'].run(assistant_id, user_input, goto=keys[0])\n                else:\n                    agent_return = st.session_state['thread_obj'].run(assistant_id, user_input)\n            else:\n                agent_return = st.session_state['thread_obj'].run(assistant_id, user_input)\n        print(f'agent_return:{agent_return}')\n        st.session_state['assistant'].append(copy.deepcopy(agent_return))\n        st.session_state['ui'].render_assistant(agent_return)", "hash": "783aa83d379e1268d4866fdce6296552d4caa08dafd8bb0c79caab35ec55249f"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "StreamlitPage.def create_assistants(self):\n    st.subheader('create assistant setting')\n    name = st.text_input('assistant name:', '')\n    model = st.selectbox('model name:', ['gpt-4-1106-preview', 'gpt-4'])\n    instructions = st.text_area('assistant instructions :', '')\n    tools_options = st.multiselect('sselect assistant tools:', ['swe_tool', 'code_interpreter'])\n    tools = [{'type': tool} for tool in tools_options]\n    if st.button('Submit'):\n        assistant = yorgassistant.Assistants.create(name=name, model=model, instructions=instructions, tools=tools)\n        st.session_state['selected_create_assistant'] = False\n        st.session_state['selected_page_common'] = True\n        st.session_state['page_common_assistant_id'] = assistant.id", "hash": "49e24ec6dd30d88dd818915f4c6fee38e7f7af8f879f302df5d39e63c2c836fc"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "import copy\nimport os\nimport streamlit as st\nfrom streamlit.logger import get_logger\nfrom datetime import datetime\nimport yorgassistant", "hash": "ebcd0fa27902c298370c5974885c4bd44e165e32fb362a20c2285142b13e631c"}
{"file_path": "open-assistant\\webui\\streamlitdome.py", "code_chunk": "if __name__ == '__main__':\n    main()", "hash": "f6681347f87c560fcc8b205345de674c15d65df6749cb75669f9d3024441e027"}
